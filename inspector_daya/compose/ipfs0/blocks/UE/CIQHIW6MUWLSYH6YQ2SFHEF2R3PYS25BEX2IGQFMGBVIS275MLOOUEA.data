' + tokens[0] + '. Expected \";\"')\n\n  tokens.shift()\n  return file\n}\n\nvar onservice = function (tokens) {\n  tokens.shift()\n\n  var service = {\n    name: tokens.shift(),\n    methods: [],\n    options: {}\n  }\n\n  if (tokens[0] !== '{') throw new Error('Expected { but found ' + tokens[0])\n  tokens.shift()\n\n  while (tokens.length) {\n    if (tokens[0] === '}') {\n      tokens.shift()\n      // there goes optional semicolon after the enclosing \"}\"\n      if (tokens[0] === ';') tokens.shift()\n      return service\n    }\n\n    switch (tokens[0]) {\n      case 'option':\n        var opt = onoption(tokens)\n        if (service.options[opt.name] !== undefined) throw new Error('Duplicate option ' + opt.name)\n        service.options[opt.name] = opt.value\n        break\n      case 'rpc':\n        service.methods.push(onrpc(tokens))\n        break\n      default:\n        throw new Error('Unexpected token in service: ' + tokens[0])\n    }\n  }\n\n  throw new Error('No closing tag for service')\n}\n\nvar onrpc = function (tokens) {\n  tokens.shift()\n\n  var rpc = {\n    name: tokens.shift(),\n    input_type: null,\n    output_type: null,\n    client_streaming: false,\n    server_streaming: false,\n    options: {}\n  }\n\n  if (tokens[0] !== '(') throw new Error('Expected ( but found ' + tokens[0])\n  tokens.shift()\n\n  if (tokens[0] === 'stream') {\n    tokens.shift()\n    rpc.client_streaming = true\n  }\n\n  rpc.input_type = tokens.shift()\n\n  if (tokens[0] !== ')') throw new Error('Expected ) but found ' + tokens[0])\n  tokens.shift()\n\n  if (tokens[0] !== 'returns') throw new Error('Expected returns but found ' + tokens[0])\n  tokens.shift()\n\n  if (tokens[0] !== '(') throw new Error('Expected ( but found ' + tokens[0])\n  tokens.shift()\n\n  if (tokens[0] === 'stream') {\n    tokens.shift()\n    rpc.server_streaming = true\n  }\n\n  rpc.output_type = tokens.shift()\n\n  if (tokens[0] !== ')') throw new Error('Expected ) but found ' + tokens[0])\n  tokens.shift()\n\n  if (tokens[0] === ';') {\n    tokens.shift()\n    return rpc\n  }\n\n  if (tokens[0] !== '{') throw new Error('Expected { but found ' + tokens[0])\n  tokens.shift()\n\n  while (tokens.length) {\n    if (tokens[0] === '}') {\n      tokens.shift()\n      // there goes optional semicolon after the enclosing \"}\"\n      if (tokens[0] === ';') tokens.shift()\n      return rpc\n    }\n\n    if (tokens[0] === 'option') {\n      var opt = onoption(tokens)\n      if (rpc.options[opt.name] !== undefined) throw new Error('Duplicate option ' + opt.name)\n      rpc.options[opt.name] = opt.value\n    } else {\n      throw new Error('Unexpected token in rpc options: ' + tokens[0])\n    }\n  }\n\n  throw new Error('No closing tag for rpc')\n}\n\nvar parse = function (buf) {\n  var tokens = tokenize(buf.toString())\n  // check for isolated strings in tokens by looking for opening quote\n  for (var i = 0; i < tokens.length; i++) {\n    if (/^(\"|')([^'\"]*)$/.test(tokens[i])) {\n      var j\n      if (tokens[i].length === 1) {\n        j = i + 1\n      } else {\n        j = i\n      }\n      // look ahead for the closing quote and collapse all\n      // in-between tokens into a single token\n      for (j; j < tokens.length; j++) {\n        if (/^[^'\"\\\\]*(?:\\\\.[^'\"\\\\]*)*(\"|')$/.test(tokens[j])) {\n          tokens = tokens.slice(0, i).concat(tokens.slice(i, j + 1).join('')).concat(tokens.slice(j + 1))\n          break\n        }\n      }\n    }\n  }\n  var schema = {\n    syntax: 3,\n    package: null,\n    imports: [],\n    enums: [],\n    messages: [],\n    options: {},\n    extends: []\n  }\n\n  var firstline = true\n\n  while (tokens.length) {\n    switch (tokens[0]) {\n      case 'package':\n        schema.package = onpackagename(tokens)\n        break\n\n      case 'syntax':\n        if (!firstline) throw new Error('Protobuf syntax version should be first thing in file')\n        schema.syntax = onsyntaxversion(tokens)\n        break\n\n      case 'message':\n        schema.messages.push(onmessage(tokens))\n        break\n\n      case 'enum':\n        schema.enums.push(onenum(tokens))\n        break\n\n      case 'option':\n        var opt = onoption(tokens)\n        if (schema.options[opt.name]) throw new Error('Duplicate option ' + opt.name)\n        schema.options[opt.name] = opt.value\n        break\n\n      case 'import':\n        schema.imports.push(onimport(tokens))\n        break\n\n      case 'extend':\n        schema.extends.push(onextend(tokens))\n        break\n\n      case 'service':\n        if (!schema.services) schema.services = []\n        schema.services.push(onservice(tokens))\n        break\n\n      default:\n        throw new Error('Unexpected token: ' + tokens[0])\n    }\n    firstline = false\n  }\n\n  // now iterate over messages and propagate extends\n  schema.extends.forEach(function (ext) {\n    schema.messages.forEach(function (msg) {\n      if (msg.name === ext.name) {\n        ext.message.fields.forEach(function (field) {\n          if (!msg.extensions || field.tag < msg.extensions.from || field.tag > msg.extensions.to) {\n            throw new Error(msg.name + ' does not declare ' + field.tag + ' as an extension number')\n          }\n          msg.fields.push(field)\n        })\n      }\n    })\n  })\n\n  schema.messages.forEach(function (msg) {\n    msg.fields.forEach(function (field) {\n      var fieldSplit\n      var messageName\n      var nestedEnumName\n      var message\n\n      function enumNameIsFieldType (en) {\n        return en.name === field.type\n      }\n\n      function enumNameIsNestedEnumName (en) {\n        return en.name === nestedEnumName\n      }\n\n      if (field.options && field.options.packed === 'true') {\n        if (PACKABLE_TYPES.indexOf(field.type) === -1) {\n          // let's see if it's an enum\n          if (field.type.indexOf('.') === -1) {\n            if (msg.enums && msg.enums.some(enumNameIsFieldType)) {\n              return\n            }\n          } else {\n            fieldSplit = field.type.split('.')\n            if (fieldSplit.length > 2) {\n              throw new Error('what is this?')\n            }\n\n            messageName = fieldSplit[0]\n            nestedEnumName = fieldSplit[1]\n\n            schema.messages.some(function (msg) {\n              if (msg.name === messageName) {\n                message = msg\n                return msg\n              }\n            })\n\n            if (message && message.enums && message.enums.some(enumNameIsNestedEnumName)) {\n              return\n            }\n          }\n\n          throw new Error(\n            'Fields of type ' + field.type + ' cannot be declared [packed=true]. ' +\n            'Only repeated fields of primitive numeric types (types which use ' +\n            'the varint, 32-bit, or 64-bit wire types) can be declared \"packed\". ' +\n            'See https://developers.google.com/protocol-buffers/docs/encoding#optional'\n          )\n        }\n      }\n    })\n  })\n\n  return schema\n}\n\nmodule.exports = parse\n","module.exports = function (sch) {\n  var noComments = function (line) {\n    var i = line.indexOf('//')\n    return i > -1 ? line.slice(0, i) : line\n  }\n\n  var noMultilineComments = function () {\n    var inside = false\n    return function (token) {\n      if (token === '/*') {\n        inside = true\n        return false\n      }\n      if (token === '*/') {\n        inside = false\n        return false\n      }\n      return !inside\n    }\n  }\n\n  var trim = function (line) {\n    return line.trim()\n  }\n\n  var removeQuotedLines = function (list) {\n    return function (str) {\n      var s = '$' + list.length + '$'\n      list.push(str)\n      return s\n    }\n  }\n\n  var restoreQuotedLines = function (list) {\n    var re = /^\\$(\\d+)\\$$/\n    return function (line) {\n      var m = line.match(re)\n      return m ? list[+m[1]] : line\n    }\n  }\n\n  var replacements = []\n  return sch\n    .replace(/\"(\\\\\"|[^\"\\n])*?\"|'(\\\\'|[^'\\n])*?'/gm, removeQuotedLines(replacements))\n    .replace(/([;,{}()=:[\\]<>]|\\/\\*|\\*\\/)/g, ' $1 ')\n    .split(/\\n/)\n    .map(trim)\n    .filter(Boolean)\n    .map(noComments)\n    .map(trim)\n    .filter(Boolean)\n    .join('\\n')\n    .split(/\\s+|\\n+/gm)\n    .filter(noMultilineComments())\n    .map(restoreQuotedLines(replacements))\n}\n","var onfield = function (f, result) {\n  var prefix = f.repeated ? 'repeated' : f.required ? 'required' : 'optional'\n  if (f.type === 'map') prefix = 'map<' + f.map.from + ',' + f.map.to + '>'\n  if (f.oneof) prefix = ''\n\n  var opts = Object.keys(f.options || {}).map(function (key) {\n    return key + ' = ' + f.options[key]\n  }).join(',')\n\n  if (opts) opts = ' [' + opts + ']'\n\n  result.push((prefix ? prefix + ' ' : '') + (f.map === 'map' ? '' : f.type + ' ') + f.name + ' = ' + f.tag + opts + ';')\n  return result\n}\n\nvar onmessage = function (m, result) {\n  result.push('message ' + m.name + ' {')\n\n  if (!m.options) m.options = {}\n  onoption(m.options, result)\n\n  if (!m.enums) m.enums = []\n  m.enums.forEach(function (e) {\n    result.push(onenum(e, []))\n  })\n\n  if (!m.messages) m.messages = []\n  m.messages.forEach(function (m) {\n    result.push(onmessage(m, []))\n  })\n\n  var oneofs = {}\n\n  if (!m.fields) m.fields = []\n  m.fields.forEach(function (f) {\n    if (f.oneof) {\n      if (!oneofs[f.oneof]) oneofs[f.oneof] = []\n      oneofs[f.oneof].push(onfield(f, []))\n    } else {\n      result.push(onfield(f, []))\n    }\n  })\n\n  Object.keys(oneofs).forEach(function (n) {\n    oneofs[n].unshift('oneof ' + n + ' {')\n    oneofs[n].push('}')\n    result.push(oneofs[n])\n  })\n\n  result.push('}', '')\n  return result\n}\n\nvar onenum = function (e, result) {\n  result.push('enum ' + e.name + ' {')\n  if (!e.options) e.options = {}\n  var options = onoption(e.options, [])\n  if (options.length > 1) {\n    result.push(options.slice(0, -1))\n  }\n  Object.keys(e.values).map(function (v) {\n    var val = onenumvalue(e.values[v])\n    result.push([v + ' = ' + val + ';'])\n  })\n  result.push('}', '')\n  return result\n}\n\nvar onenumvalue = function (v, result) {\n  var opts = Object.keys(v.options || {}).map(function (key) {\n    return key + ' = ' + v.options[key]\n  }).join(',')\n\n  if (opts) opts = ' [' + opts + ']'\n  var val = v.value + opts\n  return val\n}\n\nvar onoption = function (o, result) {\n  var keys = Object.keys(o)\n  keys.forEach(function (option) {\n    var v = o[option]\n    if (~option.indexOf('.')) option = '(' + option + ')'\n\n    var type = typeof v\n\n    if (type === 'object') {\n      v = onoptionMap(v, [])\n      if (v.length) result.push('option ' + option + ' = {', v, '};')\n    } else {\n      if (type === 'string' && option !== 'optimize_for') v = '\"' + v + '\"'\n      result.push('option ' + option + ' = ' + v + ';')\n    }\n  })\n  if (keys.length > 0) {\n    result.push('')\n  }\n\n  return result\n}\n\nvar onoptionMap = function (o, result) {\n  var keys = Object.keys(o)\n  keys.forEach(function (k) {\n    var v = o[k]\n\n    var type = typeof v\n\n    if (type === 'object') {\n      if (Array.isArray(v)) {\n        v.forEach(function (v) {\n          v = onoptionMap(v, [])\n          if (v.length) result.push(k + ' {', v, '}')\n        })\n      } else {\n        v = onoptionMap(v, [])\n        if (v.length) result.push(k + ' {', v, '}')\n      }\n    } else {\n      if (type === 'string') v = '\"' + v + '\"'\n      result.push(k + ': ' + v)\n    }\n  })\n\n  return result\n}\n\nvar onservices = function (s, result) {\n  result.push('service ' + s.name + ' {')\n\n  if (!s.options) s.options = {}\n  onoption(s.options, result)\n  if (!s.methods) s.methods = []\n  s.methods.forEach(function (m) {\n    result.push(onrpc(m, []))\n  })\n\n  result.push('}', '')\n  return result\n}\n\nvar onrpc = function (rpc, result) {\n  var def = 'rpc ' + rpc.name + '('\n  if (rpc.client_streaming) def += 'stream '\n  def += rpc.input_type + ') returns ('\n  if (rpc.server_streaming) def += 'stream '\n  def += rpc.output_type + ')'\n\n  if (!rpc.options) rpc.options = {}\n\n  var options = onoption(rpc.options, [])\n  if (options.length > 1) {\n    result.push(def + ' {', options.slice(0, -1), '}')\n  } else {\n    result.push(def + ';')\n  }\n\n  return result\n}\n\nvar indent = function (lvl) {\n  return function (line) {\n    if (Array.isArray(line)) return line.map(indent(lvl + '  ')).join('\\n')\n    return lvl + line\n  }\n}\n\nmodule.exports = function (schema) {\n  var result = []\n\n  result.push('syntax = \"proto' + schema.syntax + '\";', '')\n\n  if (schema.package) result.push('package ' + schema.package + ';', '')\n\n  if (!schema.options) schema.options = {}\n\n  onoption(schema.options, result)\n\n  if (!schema.enums) schema.enums = []\n  schema.enums.forEach(function (e) {\n    onenum(e, result)\n  })\n\n  if (!schema.messages) schema.messages = []\n  schema.messages.forEach(function (m) {\n    onmessage(m, result)\n  })\n\n  if (schema.services) {\n    schema.services.forEach(function (s) {\n      onservices(s, result)\n    })\n  }\n  return result.map(indent('')).join('\\n')\n}\n","'use strict'\n\nconst encodings = require('./encodings')\nconst compileDecode = require('./decode')\nconst compileEncode = require('./encode')\nconst compileEncodingLength = require('./encoding-length')\nconst varint = require('varint')\n\nconst flatten = function (values) {\n  if (!values) return null\n  const result = {}\n  Object.keys(values).forEach(function (k) {\n    result[k] = values[k].value\n  })\n  return result\n}\n\nmodule.exports = function (schema, extraEncodings) {\n  const messages = {}\n  const enums = {}\n  const cache = {}\n\n  const visit = function (schema, prefix) {\n    if (schema.enums) {\n      schema.enums.forEach(function (e) {\n        e.id = prefix + (prefix ? '.' : '') + e.name\n        enums[e.id] = e\n        visit(e, e.id)\n      })\n    }\n    if (schema.messages) {\n      schema.messages.forEach(function (m) {\n        m.id = prefix + (prefix ? '.' : '') + m.name\n        messages[m.id] = m\n        m.fields.forEach(function (f) {\n          if (!f.map) return\n\n          const name = 'Map_' + f.map.from + '_' + f.map.to\n          const map = {\n            name: name,\n            enums: [],\n            messages: [],\n            fields: [{\n              name: 'key',\n              type: f.map.from,\n              tag: 1,\n              repeated: false,\n              required: true\n            }, {\n              name: 'value',\n              type: f.map.to,\n              tag: 2,\n              repeated: false,\n              required: false\n            }],\n            extensions: null,\n            id: prefix + (prefix ? '.' : '') + name\n          }\n\n          if (!messages[map.id]) {\n            messages[map.id] = map\n            schema.messages.push(map)\n          }\n          f.type = name\n          f.repeated = true\n        })\n        visit(m, m.id)\n      })\n    }\n  }\n\n  visit(schema, '')\n\n  const compileEnum = function (e) {\n    const values = Object.keys(e.values || []).map(function (k) {\n      return parseInt(e.values[k].value, 10)\n    })\n\n    const encode = function enumEncode (val, buf, view, offset) {\n      if (!values.length || values.indexOf(val) === -1) {\n        throw new Error('Invalid enum value: ' + val)\n      }\n      varint.encode(val, buf, offset)\n      enumEncode.bytes = varint.encode.bytes\n      return buf\n    }\n\n    const decode = function enumDecode (buf, view, offset) {\n      var val = varint.decode(buf, offset)\n      if (!values.length || values.indexOf(val) === -1) {\n        throw new Error('Invalid enum value: ' + val)\n      }\n      enumDecode.bytes = varint.decode.bytes\n      return val\n    }\n\n    return encodings.make(0, encode, decode, varint.encodingLength)\n  }\n\n  const compileMessage = function (m, exports) {\n    m.messages.forEach(function (nested) {\n      exports[nested.name] = resolve(nested.name, m.id)\n    })\n\n    m.enums.forEach(function (val) {\n      exports[val.name] = flatten(val.values)\n    })\n\n    exports.type = 2\n    exports.message = true\n    exports.name = m.name\n\n    const oneofs = {}\n\n    m.fields.forEach(function (f) {\n      if (!f.oneof) return\n      if (!oneofs[f.oneof]) oneofs[f.oneof] = []\n      oneofs[f.oneof].push(f.name)\n    })\n\n    const enc = m.fields.map(function (f) {\n      return resolve(f.type, m.id)\n    })\n\n    const encodingLength = compileEncodingLength(m, enc, oneofs)\n    const encode = compileEncode(m, resolve, enc, oneofs, encodingLength)\n    const decode = compileDecode(m, resolve, enc)\n\n    // end of compilation - return all the things\n\n    encode.bytes = decode.bytes = 0\n\n    exports.buffer = true\n    exports.encode = encode\n    exports.decode = decode\n    exports.encodingLength = encodingLength\n\n    return exports\n  }\n\n  const resolve = function (name, from, compile) {\n    if (extraEncodings && extraEncodings[name]) return extraEncodings[name]\n    if (encodings[name]) return encodings[name]\n\n    const m = (from ? from + '.' + name : name).split('.')\n      .map(function (part, i, list) {\n        return list.slice(0, i).concat(name).join('.')\n      })\n      .reverse()\n      .reduce(function (result, id) {\n        return result || messages[id] || enums[id]\n      }, null)\n\n    if (compile === false) return m\n    if (!m) throw new Error('Could not resolve ' + name)\n\n    if (m.values) return compileEnum(m)\n    const res = cache[m.id] || compileMessage(m, cache[m.id] = {})\n    return res\n  }\n\n  return (schema.enums || []).concat((schema.messages || []).map(function (message) {\n    return resolve(message.id)\n  }))\n}\n","'use strict'\n\nexports.make = require('./encoder')\nexports.bytes = require('./bytes')\nexports.string = require('./string')\nexports.bool = require('./bool')\nexports.int32 = require('./int32')\nexports.int64 = require('./int64')\nexports.sint32 =\nexports.sint64 = require('./sint64')\nexports.uint32 =\nexports.uint64 =\nexports.enum =\nexports.varint = require('./varint')\n\n// we cannot represent these in javascript so we just use buffers\nexports.fixed64 =\nexports.sfixed64 = require('./fixed64')\nexports.double = require('./double')\nexports.fixed32 = require('./fixed32')\nexports.sfixed32 = require('./sfixed32')\nexports.float = require('./float')\n","'use strict'\n\nconst varint = require('varint')\nconst encoder = require('./encoder')\n\nfunction bytesBufferLength (val) {\n  return val.byteLength\n}\n\nfunction bytesEncodingLength (val) {\n  const len = bytesBufferLength(val)\n  return varint.encodingLength(len) + len\n}\n\nfunction bytesEncode (val, buffer, dataView, offset) {\n  const oldOffset = offset\n  const len = bytesBufferLength(val)\n\n  varint.encode(len, buffer, offset)\n  offset += varint.encode.bytes\n\n  buffer.set(val, offset)\n  offset += len\n\n  bytesEncode.bytes = offset - oldOffset\n}\n\nfunction bytesDecode (buffer, dataView, offset) {\n  const oldOffset = offset\n\n  const len = varint.decode(buffer, offset)\n  offset += varint.decode.bytes\n\n  const val = buffer.slice(offset, offset + len)\n  offset += val.length\n\n  bytesDecode.bytes = offset - oldOffset\n\n  return val\n}\n\nmodule.exports = encoder(2, bytesEncode, bytesDecode, bytesEncodingLength)\n","module.exports = encode\n\nvar MSB = 0x80\n  , REST = 0x7F\n  , MSBALL = ~REST\n  , INT = Math.pow(2, 31)\n\nfunction encode(num, out, offset) {\n  out = out || []\n  offset = offset || 0\n  var oldOffset = offset\n\n  while(num >= INT) {\n    out[offset++] = (num & 0xFF) | MSB\n    num /= 128\n  }\n  while(num & MSBALL) {\n    out[offset++] = (num & 0xFF) | MSB\n    num >>>= 7\n  }\n  out[offset] = num | 0\n  \n  encode.bytes = offset - oldOffset + 1\n  \n  return out\n}\n","module.exports = read\n\nvar MSB = 0x80\n  , REST = 0x7F\n\nfunction read(buf, offset) {\n  var res    = 0\n    , offset = offset || 0\n    , shift  = 0\n    , counter = offset\n    , b\n    , l = buf.length\n\n  do {\n    if (counter >= l) {\n      read.bytes = 0\n      throw new RangeError('Could not decode varint')\n    }\n    b = buf[counter++]\n    res += shift < 28\n      ? (b & REST) << shift\n      : (b & REST) * Math.pow(2, shift)\n    shift += 7\n  } while (b >= MSB)\n\n  read.bytes = counter - offset\n\n  return res\n}\n","\nvar N1 = Math.pow(2,  7)\nvar N2 = Math.pow(2, 14)\nvar N3 = Math.pow(2, 21)\nvar N4 = Math.pow(2, 28)\nvar N5 = Math.pow(2, 35)\nvar N6 = Math.pow(2, 42)\nvar N7 = Math.pow(2, 49)\nvar N8 = Math.pow(2, 56)\nvar N9 = Math.pow(2, 63)\n\nmodule.exports = function (value) {\n  return (\n    value < N1 ? 1\n  : value < N2 ? 2\n  : value < N3 ? 3\n  : value < N4 ? 4\n  : value < N5 ? 5\n  : value < N6 ? 6\n  : value < N7 ? 7\n  : value < N8 ? 8\n  : value < N9 ? 9\n  :              10\n  )\n}\n","'use strict'\n\nconst varint = require('varint')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\nconst uint8ArrayToString = require('uint8arrays/to-string')\nconst encoder = require('./encoder')\n\nfunction stringEncodingLength (val) {\n  const len = uint8ArrayFromString(val).byteLength\n  return varint.encodingLength(len) + len\n}\n\nfunction stringEncode (val, buffer, dataView, offset) {\n  const oldOffset = offset\n  const len = uint8ArrayFromString(val).byteLength\n\n  varint.encode(len, buffer, offset, 'utf-8')\n  offset += varint.encode.bytes\n\n  const arr = uint8ArrayFromString(val)\n  buffer.set(arr, offset)\n  offset += arr.length\n\n  stringEncode.bytes = offset - oldOffset\n}\n\nfunction stringDecode (buffer, dataView, offset) {\n  const oldOffset = offset\n\n  const len = varint.decode(buffer, offset)\n  offset += varint.decode.bytes\n\n  const val = uint8ArrayToString(buffer.subarray(offset, offset + len))\n  offset += len\n\n  stringDecode.bytes = offset - oldOffset\n\n  return val\n}\n\nmodule.exports = encoder(2, stringEncode, stringDecode, stringEncodingLength)\n","'use strict'\n\nconst encoder = require('./encoder')\n\nfunction boolEncodingLength () {\n  return 1\n}\n\nfunction boolEncode (value, buffer, dataView, offset) {\n  buffer[offset] = value ? 1 : 0\n  boolEncode.bytes = 1\n}\n\nfunction boolDecode (buffer, dataView, offset) {\n  const bool = buffer[offset] > 0\n  boolDecode.bytes = 1\n\n  return bool\n}\n\nmodule.exports = encoder(0, boolEncode, boolDecode, boolEncodingLength)\n","'use strict'\n\nconst varint = require('varint')\nconst encoder = require('./encoder')\n\nfunction in32Encode (val, buffer, dataView, offset) {\n  varint.encode(val < 0 ? val + 4294967296 : val, buffer, offset)\n  in32Encode.bytes = varint.encode.bytes\n}\n\nfunction int32Decode (buffer, dataView, offset) {\n  const val = varint.decode(buffer, offset)\n  int32Decode.bytes = varint.decode.bytes\n\n  return val > 2147483647 ? val - 4294967296 : val\n}\n\nfunction int32EncodingLength (val) {\n  return varint.encodingLength(val < 0 ? val + 4294967296 : val)\n}\n\nmodule.exports = encoder(0, in32Encode, int32Decode, int32EncodingLength)\n","'use strict'\n\nconst varint = require('varint')\nconst encoder = require('./encoder')\n\nfunction int64Encode (val, buffer, dataView, offset) {\n  if (val < 0) {\n    const last = offset + 9\n    varint.encode(val * -1, buffer, offset)\n\n    offset += varint.encode.bytes - 1\n    buffer[offset] = buffer[offset] | 0x80\n\n    while (offset < last - 1) {\n      offset++\n      buffer[offset] = 0xff\n    }\n    buffer[last] = 0x01\n\n    int64Encode.bytes = 10\n  } else {\n    varint.encode(val, buffer, offset)\n    int64Encode.bytes = varint.encode.bytes\n  }\n}\n\nfunction int64Decode (buffer, dataView, offset) {\n  let val = varint.decode(buffer, offset)\n\n  if (val >= Math.pow(2, 63)) {\n    let limit = 9\n    while (buffer[offset + limit - 1] === 0xff) limit--\n    limit = limit || 9\n    const subset = buffer.subarray(offset, offset + limit)\n    subset[limit - 1] = subset[limit - 1] & 0x7f\n    val = -1 * varint.decode(subset, 0)\n    int64Decode.bytes = 10\n  } else {\n    int64Decode.bytes = varint.decode.bytes\n  }\n\n  return val\n}\n\nfunction int64EncodingLength (val) {\n  return val < 0 ? 10 : varint.encodingLength(val)\n}\n\nmodule.exports = encoder(0, int64Encode, int64Decode, int64EncodingLength)\n","'use strict'\n\nconst svarint = require('signed-varint')\nconst encoder = require('./encoder')\n\nfunction svarintEncode (val, buffer, dataView, offset) {\n  svarint.encode(val, buffer, offset)\n\n  svarintEncode.bytes = svarint.encode.bytes\n}\n\nfunction svarintDecode (buffer, dataView, offset) {\n  const val = svarint.decode(buffer, offset)\n  svarintDecode.bytes = svarint.decode.bytes\n\n  return val\n}\n\nmodule.exports = encoder(0, svarintEncode, svarintDecode, svarint.encodingLength)\n","var varint = require('varint')\nexports.encode = function encode (v, b, o) {\n  v = v >= 0 ? v*2 : v*-2 - 1\n  var r = varint.encode(v, b, o)\n  encode.bytes = varint.encode.bytes\n  return r\n}\nexports.decode = function decode (b, o) {\n  var v = varint.decode(b, o)\n  decode.bytes = varint.decode.bytes\n  return v & 1 ? (v+1) / -2 : v / 2\n}\n\nexports.encodingLength = function (v) {\n  return varint.encodingLength(v >= 0 ? v*2 : v*-2 - 1)\n}\n","'use strict'\n\nconst varint = require('varint')\nconst encoder = require('./encoder')\n\nfunction varintEncode (val, buffer, dataView, offset) {\n  varint.encode(val, buffer, offset)\n\n  varintEncode.bytes = varint.encode.bytes\n}\n\nfunction varintDecode (buffer, dataView, offset) {\n  const val = varint.decode(buffer, offset)\n  varintDecode.bytes = varint.decode.bytes\n\n  return val\n}\n\nmodule.exports = encoder(0, varintEncode, varintDecode, varint.encodingLength)\n","'use strict'\n\nconst encoder = require('./encoder')\n\nfunction fixed64EncodingLength () {\n  return 8\n}\n\nfunction fixed64Encode (val, buffer, dataView, offset) {\n  for (const byte of val) {\n    buffer[offset] = byte\n    offset++\n  }\n\n  fixed64Encode.bytes = 8\n}\n\nfunction fixed64Decode (buffer, dataView, offset) {\n  const val = buffer.slice(offset, offset + 8)\n  fixed64Decode.bytes = 8\n\n  return val\n}\n\nmodule.exports = encoder(1, fixed64Encode, fixed64Decode, fixed64EncodingLength)\n","'use strict'\n\nconst encoder = require('./encoder')\n\nfunction doubleEncodingLength () {\n  return 8\n}\n\nfunction doubleEncode (val, buffer, dataView, offset) {\n  dataView.setFloat64(offset, val, true)\n  doubleEncode.bytes = 8\n}\n\nfunction doubleDecode (buffer, dataView, offset) {\n  const val = dataView.getFloat64(offset, true)\n  doubleDecode.bytes = 8\n\n  return val\n}\n\nmodule.exports = encoder(1, doubleEncode, doubleDecode, doubleEncodingLength)\n","'use strict'\n\nconst encoder = require('./encoder')\n\nfunction fixed32EncodingLength (val) {\n  return 4\n}\n\nfunction fixed32Encode (val, buffer, dataView, offset) {\n  dataView.setUint32(offset, val, true)\n  fixed32Encode.bytes = 4\n}\n\nfunction fixed32Decode (buffer, dataView, offset) {\n  const val = dataView.getUint32(offset, true)\n  fixed32Decode.bytes = 4\n\n  return val\n}\n\nmodule.exports = encoder(5, fixed32Encode, fixed32Decode, fixed32EncodingLength)\n","'use strict'\n\nconst encoder = require('./encoder')\n\nfunction sfixed32EncodingLength (val) {\n  return 4\n}\n\nfunction sfixed32Encode (val, buffer, dataView, offset) {\n  dataView.setInt32(offset, val, true)\n  sfixed32Encode.bytes = 4\n}\n\nfunction sfixed32Decode (buffer, dataView, offset) {\n  const val = dataView.getInt32(offset, true)\n  sfixed32Decode.bytes = 4\n\n  return val\n}\n\nmodule.exports = encoder(5, sfixed32Encode, sfixed32Decode, sfixed32EncodingLength)\n","'use strict'\n\nconst encoder = require('./encoder')\n\nfunction floatEncodingLength () {\n  return 4\n}\n\nfunction floatEncode (val, buffer, dataView, offset) {\n  dataView.setFloat32(offset, val, true)\n  floatEncode.bytes = 4\n}\n\nfunction floatDecode (buffer, dataView, offset) {\n  const val = dataView.getFloat32(offset, true)\n  floatDecode.bytes = 4\n\n  return val\n}\n\nmodule.exports = encoder(5, floatEncode, floatDecode, floatEncodingLength)\n","/* eslint max-depth: 1 */\n'use strict'\n\nconst varint = require('varint')\nconst defined = require('./utils').defined\n\nfunction toSentenceCase (string) {\n  return `${string.substring(0, 1).toUpperCase()}${string.substring(1)}`\n}\n\nfunction addPropertyAccessors (obj, name, value, defaultValue) {\n  if (Object.prototype.hasOwnProperty.call(obj, name)) {\n    // have already added this property\n    return\n  }\n\n  const sentenceCaseName = toSentenceCase(name)\n\n  Object.defineProperties(obj, {\n    [name]: {\n      enumerable: true,\n      configurable: true,\n      set: (val) => {\n        value = val\n      },\n      get: () => {\n        if (value === undefined) {\n          return defaultValue\n        }\n\n        return value\n      }\n    },\n    [`has${sentenceCaseName}`]: {\n      configurable: true,\n      value: () => {\n        return value !== undefined\n      }\n    },\n    [`set${sentenceCaseName}`]: {\n      configurable: true,\n      value: (val) => {\n        value = val\n      }\n    },\n    [`get${sentenceCaseName}`]: {\n      configurable: true,\n      value: () => {\n        return value\n      }\n    },\n    [`clear${sentenceCaseName}`]: {\n      configurable: true,\n      value: () => {\n        value = undefined\n        obj[name] = undefined\n      }\n    }\n  })\n}\n\nfunction compileDecode (m, resolve, enc) {\n  const requiredFields = []\n  const fields = {}\n  const oneofFields = []\n  const vals = []\n\n  for (var i = 0; i < enc.length; i++) {\n    const field = m.fields[i]\n\n    fields[field.tag] = i\n\n    const def = field.options && field.options.default\n    const resolved = resolve(field.type, m.id, false)\n    vals[i] = [def, resolved && resolved.values]\n\n    m.fields[i].packed = field.repeated && field.options && field.options.packed && field.options.packed !== 'false'\n\n    if (field.required) {\n      requiredFields.push(field.name)\n    }\n\n    if (field.oneof) {\n      oneofFields.push(field.name)\n    }\n  }\n\n  function decodeField (e, field, obj, buf, dataView, offset, i) {\n    const name = field.name\n\n    if (field.oneof) {\n      // clear already defined oneof fields\n      const props = Object.keys(obj)\n      for (var j = 0; j < props.length; j++) {\n        if (oneofFields.indexOf(props[j]) > -1) {\n          const sentenceCase = toSentenceCase(props[j])\n          delete obj[`has${sentenceCase}`]\n          delete obj[`get${sentenceCase}`]\n          delete obj[`set${sentenceCase}`]\n          delete obj[`clear${sentenceCase}`]\n          delete obj[props[j]]\n        }\n      }\n    }\n\n    let value\n\n    if (e.message) {\n      const len = varint.decode(buf, offset)\n      offset += varint.decode.bytes\n\n      const decoded = e.decode(buf, dataView, offset, offset + len)\n\n      if (field.map) {\n        value = obj[name] || {}\n        value[decoded.key] = decoded.value\n      } else if (field.repeated) {\n        value = obj[name] || []\n        value.push(decoded)\n      } else {\n        value = decoded\n      }\n    } else {\n      if (field.repeated) {\n        value = obj[name] || []\n        value.push(e.decode(buf, dataView, offset))\n      } else {\n        value = e.decode(buf, dataView, offset)\n      }\n    }\n\n    addPropertyAccessors(obj, name, value)\n\n    offset += e.decode.bytes\n\n    return offset\n  }\n\n  return function decode (buf, view, offset, end) {\n    if (offset == null) {\n      offset = 0\n    }\n\n    if (end == null) {\n      end = buf.length\n    }\n\n    if (!(end <= buf.length && offset <= buf.length)) {\n      throw new Error('Decoded message is not valid')\n    }\n\n    if (!view) {\n      view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength)\n    }\n\n    var oldOffset = offset\n    var obj = {}\n    var field\n\n    while (true) {\n      if (end <= offset) {\n        // finished\n\n        // check required methods\n        var name = ''\n        var j = 0\n        for (j = 0; j < requiredFields.length; j++) {\n          name = requiredFields[j]\n          if (!defined(obj[name])) {\n            throw new Error('Decoded message is not valid, missing required field: ' + name)\n          }\n        }\n\n        // fill out missing defaults\n        var val\n        var def\n        for (j = 0; j < enc.length; j++) {\n          field = m.fields[j]\n          def = vals[j][0]\n          val = vals[j][1]\n          name = field.name\n          let defaultVal\n\n          if (Object.prototype.hasOwnProperty.call(obj, name)) {\n            continue\n          }\n\n          var done = false\n\n          if (field.oneof) {\n            var props = Object.keys(obj)\n\n            for (var k = 0; k < props.length; k++) {\n              if (oneofFields.indexOf(props[k]) > -1) {\n                done = true\n                break\n              }\n            }\n          }\n\n          if (done) {\n            continue\n          }\n\n          if (val) { // is enum\n            if (field.repeated) {\n              def = []\n            } else {\n              def = (def && val[def]) ? val[def].value : val[Object.keys(val)[0]].value\n              def = parseInt(def || 0, 10)\n            }\n          } else {\n            defaultVal = defaultValue(field)\n            def = coerceValue(field, def)\n          }\n\n          addPropertyAccessors(obj, name, def, defaultVal)\n        }\n\n        decode.bytes = offset - oldOffset\n        return obj\n      }\n\n      var prefix = varint.decode(buf, offset)\n      offset += varint.decode.bytes\n      var tag = prefix >> 3\n\n      var i = fields[tag]\n\n      if (i == null) {\n        offset = skip(prefix & 7, buf, view, offset)\n        continue\n      }\n\n      var e = enc[i]\n      field = m.fields[i]\n\n      if (field.packed) {\n        var packedEnd = varint.decode(buf, offset)\n        offset += varint.decode.bytes\n        packedEnd += offset\n\n        while (offset < packedEnd) {\n          offset = decodeField(e, field, obj, buf, view, offset, i)\n        }\n      } else {\n        offset = decodeField(e, field, obj, buf, view, offset, i)\n      }\n    }\n  }\n}\n\nvar skip = function (type, buffer, view, offset) {\n  switch (type) {\n    case 0:\n      varint.decode(buffer, offset)\n      return offset + varint.decode.bytes\n\n    case 1:\n      return offset + 8\n\n    case 2:\n      var len = varint.decode(buffer, offset)\n      return offset + varint.decode.bytes + len\n\n    case 3:\n    case 4:\n      throw new Error('Groups are not supported')\n\n    case 5:\n      return offset + 4\n    default:\n      throw new Error('Unknown wire type: ' + type)\n  }\n}\n\nvar defaultValue = function (f) {\n  if (f.map) return {}\n  if (f.repeated) return []\n\n  switch (f.type) {\n    case 'string':\n      return ''\n    case 'bool':\n      return false\n    case 'float':\n    case 'double':\n    case 'sfixed32':\n    case 'fixed32':\n    case 'varint':\n    case 'enum':\n    case 'uint64':\n    case 'uint32':\n    case 'int64':\n    case 'int32':\n    case 'sint64':\n    case 'sint32':\n      return 0\n    default:\n      return null\n  }\n}\n\nvar coerceValue = function (f, def) {\n  if (def === undefined) {\n    return def\n  }\n\n  switch (f.type) {\n    case 'bool':\n      return def === 'true'\n    case 'float':\n    case 'double':\n    case 'sfixed32':\n    case 'fixed32':\n    case 'varint':\n    case 'enum':\n    case 'uint64':\n    case 'uint32':\n    case 'int64':\n    case 'int32':\n    case 'sint64':\n    case 'sint32':\n      return parseInt(def, 10)\n    default:\n      return def\n  }\n}\n\nmodule.exports = compileDecode\n","'use strict'\n\nvar defined = require('./utils').defined\nvar varint = require('varint')\n\nfunction compileEncode (m, resolve, enc, oneofs, encodingLength) {\n  const oneofsKeys = Object.keys(oneofs)\n  const encLength = enc.length\n  const ints = {}\n  for (let i = 0; i < encLength; i++) {\n    ints[i] = {\n      p: varint.encode(m.fields[i].tag << 3 | 2),\n      h: varint.encode(m.fields[i].tag << 3 | enc[i].type)\n    }\n\n    const field = m.fields[i]\n    m.fields[i].packed = field.repeated && field.options && field.options.packed && field.options.packed !== 'false'\n  }\n\n  function encodeField (buf, view, offset, h, e, packed, innerVal) {\n    let j = 0\n    if (!packed) {\n      for (j = 0; j < h.length; j++) {\n        buf[offset++] = h[j]\n      }\n    }\n\n    if (e.message) {\n      varint.encode(e.encodingLength(innerVal), buf, offset)\n      offset += varint.encode.bytes\n    }\n\n    e.encode(innerVal, buf, view, offset)\n\n    return offset + e.encode.bytes\n  }\n\n  return function encode (obj, buf, view, offset = 0) {\n    if (buf == null) {\n      buf = new Uint8Array(encodingLength(obj))\n    }\n\n    if (view == null) {\n      view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength)\n    }\n\n    const oldOffset = offset\n    const objKeys = Object.keys(obj)\n    let i = 0\n\n    // oneof checks\n\n    let match = false\n    for (i = 0; i < oneofsKeys.length; i++) {\n      const name = oneofsKeys[i]\n      const prop = oneofs[i]\n      if (objKeys.indexOf(prop) > -1) {\n        if (match) {\n          throw new Error('only one of the properties defined in oneof ' + name + ' can be set')\n        }\n\n        match = true\n      }\n    }\n\n    for (i = 0; i < encLength; i++) {\n      const e = enc[i]\n      const field = m.fields[i] // was f\n      let val = obj[field.name]\n      let j = 0\n\n      if (!defined(val)) {\n        if (field.required) {\n          throw new Error(field.name + ' is required')\n        }\n        continue\n      }\n      const p = ints[i].p\n      const h = ints[i].h\n\n      const packed = field.packed\n\n      if (field.map) {\n        const tmp = Object.keys(val)\n        for (j = 0; j < tmp.length; j++) {\n          tmp[j] = {\n            key: tmp[j],\n            value: val[tmp[j]]\n          }\n        }\n        val = tmp\n      }\n\n      if (packed) {\n        let packedLen = 0\n        for (j = 0; j < val.length; j++) {\n          if (!Object.prototype.hasOwnProperty.call(val, j)) {\n            continue\n          }\n\n          packedLen += e.encodingLength(val[j])\n        }\n\n        if (packedLen) {\n          for (j = 0; j < h.length; j++) {\n            buf[offset++] = p[j]\n          }\n          varint.encode(packedLen, buf, offset)\n          offset += varint.encode.bytes\n        }\n      }\n\n      if (field.repeated) {\n        let innerVal\n        for (j = 0; j < val.length; j++) {\n          innerVal = val[j]\n          if (!defined(innerVal)) {\n            continue\n          }\n\n          offset = encodeField(buf, view, offset, h, e, packed, innerVal)\n        }\n      } else {\n        offset = encodeField(buf, view, offset, h, e, packed, val)\n      }\n    }\n\n    encode.bytes = offset - oldOffset\n    return buf\n  }\n}\n\nmodule.exports = compileEncode\n","'use strict'\n\nvar defined = require('./utils').defined\nvar varint = require('varint')\n\nfunction compileEncodingLength (m, enc, oneofs) {\n  const oneofsKeys = Object.keys(oneofs)\n  const encLength = enc.length\n\n  const hls = new Array(encLength)\n\n  for (let i = 0; i < m.fields.length; i++) {\n    hls[i] = varint.encodingLength(m.fields[i].tag << 3 | enc[i].type)\n\n    const field = m.fields[i]\n    m.fields[i].packed = field.repeated && field.options && field.options.packed && field.options.packed !== 'false'\n  }\n\n  return function encodingLength (obj) {\n    let length = 0\n    let i = 0\n    let j = 0\n\n    for (i = 0; i < oneofsKeys.length; i++) {\n      const name = oneofsKeys[i]\n      const props = oneofs[name]\n\n      let match = false\n      for (j = 0; j < props.length; j++) {\n        if (defined(obj[props[j]])) {\n          if (match) {\n            throw new Error('only one of the properties defined in oneof ' + name + ' can be set')\n          }\n          match = true\n        }\n      }\n    }\n\n    for (i = 0; i < encLength; i++) {\n      const e = enc[i]\n      const field = m.fields[i]\n      let val = obj[field.name]\n      const hl = hls[i]\n      let len\n\n      if (!defined(val)) {\n        if (field.required) {\n          throw new Error(field.name + ' is required')\n        }\n\n        continue\n      }\n\n      if (field.map) {\n        const tmp = Object.keys(val)\n        for (j = 0; j < tmp.length; j++) {\n          tmp[j] = {\n            key: tmp[j],\n            value: val[tmp[j]]\n          }\n        }\n\n        val = tmp\n      }\n\n      if (field.packed) {\n        let packedLen = 0\n        for (j = 0; j < val.length; j++) {\n          if (!defined(val[j])) {\n            continue\n          }\n          len = e.encodingLength(val[j])\n          packedLen += len\n\n          if (e.message) {\n            packedLen += varint.encodingLength(len)\n          }\n        }\n\n        if (packedLen) {\n          length += hl + packedLen + varint.encodingLength(packedLen)\n        }\n      } else if (field.repeated) {\n        for (j = 0; j < val.length; j++) {\n          if (!defined(val[j])) {\n            continue\n          }\n\n          len = e.encodingLength(val[j])\n          length += hl + len + (e.message ? varint.encodingLength(len) : 0)\n        }\n      } else {\n        len = e.encodingLength(val)\n        length += hl + len + (e.message ? varint.encodingLength(len) : 0)\n      }\n    }\n\n    return length\n  }\n}\n\nmodule.exports = compileEncodingLength\n","'use strict'\n\nconst DAGLink = require('../dag-link/dagLink')\nconst genCid = require('../genCid')\n\n/*\n * toDAGLink converts a DAGNode to a DAGLink\n */\nconst toDAGLink = async (node, options = {}) => {\n  const nodeCid = await genCid.cid(node.serialize(), options)\n  return new DAGLink(options.name || '', node.size, nodeCid)\n}\n\nmodule.exports = toDAGLink\n","/**\n * Implementation of the multicodec specification.\n *\n * @module multicodec\n * @example\n * const multicodec = require('multicodec')\n *\n * const prefixedProtobuf = multicodec.addPrefix('protobuf', protobufBuffer)\n * // prefixedProtobuf 0x50...\n *\n */\n'use strict'\n\n/** @typedef {import('./generated-types').CodecName} CodecName */\n/** @typedef {import('./generated-types').CodecNumber} CodecNumber */\n\nconst varint = require('varint')\nconst intTable = require('./int-table')\nconst codecNameToCodeVarint = require('./varint-table')\nconst util = require('./util')\nconst uint8ArrayConcat = require('uint8arrays/concat')\n\n/**\n * Prefix a buffer with a multicodec-packed.\n *\n * @param {CodecName|Uint8Array} multicodecStrOrCode\n * @param {Uint8Array} data\n * @returns {Uint8Array}\n */\nfunction addPrefix (multicodecStrOrCode, data) {\n  let prefix\n\n  if (multicodecStrOrCode instanceof Uint8Array) {\n    prefix = util.varintUint8ArrayEncode(multicodecStrOrCode)\n  } else {\n    if (codecNameToCodeVarint[multicodecStrOrCode]) {\n      prefix = codecNameToCodeVarint[multicodecStrOrCode]\n    } else {\n      throw new Error('multicodec not recognized')\n    }\n  }\n  return uint8ArrayConcat([prefix, data], prefix.length + data.length)\n}\n\n/**\n * Decapsulate the multicodec-packed prefix from the data.\n *\n * @param {Uint8Array} data\n * @returns {Uint8Array}\n */\nfunction rmPrefix (data) {\n  varint.decode(data)\n  return data.slice(varint.decode.bytes)\n}\n\n/**\n * Get the codec of the prefixed data.\n *\n * @param {Uint8Array} prefixedData\n * @returns {CodecName}\n */\nfunction getCodec (prefixedData) {\n  const code = varint.decode(prefixedData)\n  const codecName = intTable.get(code)\n  if (codecName === undefined) {\n    throw new Error(`Code ${code} not found`)\n  }\n  return codecName\n}\n\n/**\n * Get the name of the codec.\n *\n * @param {CodecNumber} codec\n * @returns {CodecName|undefined}\n */\nfunction getName (codec) {\n  return intTable.get(codec)\n}\n\n/**\n * Get the code of the codec\n *\n * @param {CodecName} name\n * @returns {CodecNumber}\n */\nfunction getNumber (name) {\n  const code = codecNameToCodeVarint[name]\n  if (code === undefined) {\n    throw new Error('Codec `' + name + '` not found')\n  }\n  return varint.decode(code)\n}\n\n/**\n * Get the code of the prefixed data.\n *\n * @param {Uint8Array} prefixedData\n * @returns {CodecNumber}\n */\nfunction getCode (prefixedData) {\n  return varint.decode(prefixedData)\n}\n\n/**\n * Get the code as varint of a codec name.\n *\n * @param {CodecName} codecName\n * @returns {Uint8Array}\n */\nfunction getCodeVarint (codecName) {\n  const code = codecNameToCodeVarint[codecName]\n  if (code === undefined) {\n    throw new Error('Codec `' + codecName + '` not found')\n  }\n  return code\n}\n\n/**\n * Get the varint of a code.\n *\n * @param {CodecNumber} code\n * @returns {Array.<number>}\n */\nfunction getVarint (code) {\n  return varint.encode(code)\n}\n\n// Make the constants top-level constants\nconst constants = require('./constants')\n\n// Human friendly names for printing, e.g. in error messages\nconst print = require('./print')\n\nmodule.exports = {\n  addPrefix,\n  rmPrefix,\n  getCodec,\n  getName,\n  getNumber,\n  getCode,\n  getCodeVarint,\n  getVarint,\n  print,\n  ...constants\n}\n","module.exports = encode\n\nvar MSB = 0x80\n  , REST = 0x7F\n  , MSBALL = ~REST\n  , INT = Math.pow(2, 31)\n\nfunction encode(num, out, offset) {\n  if (Number.MAX_SAFE_INTEGER && num > Number.MAX_SAFE_INTEGER) {\n    encode.bytes = 0\n    throw new RangeError('Could not encode varint')\n  }\n  out = out || []\n  offset = offset || 0\n  var oldOffset = offset\n\n  while(num >= INT) {\n    out[offset++] = (num & 0xFF) | MSB\n    num /= 128\n  }\n  while(num & MSBALL) {\n    out[offset++] = (num & 0xFF) | MSB\n    num >>>= 7\n  }\n  out[offset] = num | 0\n  \n  encode.bytes = offset - oldOffset + 1\n  \n  return out\n}\n","module.exports = read\n\nvar MSB = 0x80\n  , REST = 0x7F\n\nfunction read(buf, offset) {\n  var res    = 0\n    , offset = offset || 0\n    , shift  = 0\n    , counter = offset\n    , b\n    , l = buf.length\n\n  do {\n    if (counter >= l || shift > 49) {\n      read.bytes = 0\n      throw new RangeError('Could not decode varint')\n    }\n    b = buf[counter++]\n    res += shift < 28\n      ? (b & REST) << shift\n      : (b & REST) * Math.pow(2, shift)\n    shift += 7\n  } while (b >= MSB)\n\n  read.bytes = counter - offset\n\n  return res\n}\n","\nvar N1 = Math.pow(2,  7)\nvar N2 = Math.pow(2, 14)\nvar N3 = Math.pow(2, 21)\nvar N4 = Math.pow(2, 28)\nvar N5 = Math.pow(2, 35)\nvar N6 = Math.pow(2, 42)\nvar N7 = Math.pow(2, 49)\nvar N8 = Math.pow(2, 56)\nvar N9 = Math.pow(2, 63)\n\nmodule.exports = function (value) {\n  return (\n    value < N1 ? 1\n  : value < N2 ? 2\n  : value < N3 ? 3\n  : value < N4 ? 4\n  : value < N5 ? 5\n  : value < N6 ? 6\n  : value < N7 ? 7\n  : value < N8 ? 8\n  : value < N9 ? 9\n  :              10\n  )\n}\n","'use strict'\n\n/** @typedef {import('./generated-types').CodecName} CodecName */\n/** @typedef {import('./generated-types').CodecNumber} CodecNumber */\n\nconst { baseTable } = require('./base-table')\n\n/**\n * @type {Map<CodecNumber,CodecName>}\n */\nconst nameTable = new Map()\n\nfor (const encodingName in baseTable) {\n  const code = baseTable[encodingName]\n  nameTable.set(code, /** @type {CodecName} */(encodingName))\n}\n\nmodule.exports = Object.freeze(nameTable)\n","'use strict'\n\n/** @typedef {import('./generated-types').NameUint8ArrayMap} NameUint8ArrayMap */\n\nconst { baseTable } = require('./base-table')\nconst varintEncode = require('./util').varintEncode\n\nconst varintTable = /** @type {NameUint8ArrayMap} */ ({})\n\nfor (const encodingName in baseTable) {\n  const code = baseTable[encodingName]\n  varintTable[encodingName] = varintEncode(code)\n}\n\nmodule.exports = Object.freeze(varintTable)\n","'use strict'\n\n/**\n * Returns a new Uint8Array created by concatenating the passed ArrayLikes\n *\n * @param {Array<ArrayLike<number>>} arrays\n * @param {Number} length\n * @returns {Uint8Array}\n */\nfunction concat (arrays, length) {\n  if (!length) {\n    length = arrays.reduce((acc, curr) => acc + curr.length, 0)\n  }\n\n  const output = new Uint8Array(length)\n  let offset = 0\n\n  for (const arr of arrays) {\n    output.set(arr, offset)\n    offset += arr.length\n  }\n\n  return output\n}\n\nmodule.exports = concat\n","'use strict'\n\n/** @typedef {import('./generated-types').ConstantNumberMap} ConstantNumberMap */\n\nconst { baseTable } = require('./base-table')\n\nconst constants = /** @type {ConstantNumberMap} */({})\n\nfor (const [name, code] of Object.entries(baseTable)) {\n  const constant = name.toUpperCase().replace(/-/g, '_')\n  constants[constant] = code\n}\n\nmodule.exports = Object.freeze(constants)\n","'use strict'\n\n/** @typedef {import('./generated-types').CodecName} CodecName */\n/** @typedef {import('./generated-types').NumberNameMap} NumberNameMap */\n\nconst { baseTable } = require('./base-table')\n\nconst tableByCode = /** @type {NumberNameMap} */({})\n\nfor (const [name, code] of Object.entries(baseTable)) {\n  if (tableByCode[code] === undefined) {\n    tableByCode[code] = /** @type {CodecName} **/(name)\n  }\n}\n\nmodule.exports = /** @type {NumberNameMap} */(Object.freeze(tableByCode))\n","'use strict'\n\nconst errcode = require('err-code')\nconst multihash = require('multihashes')\nconst crypto = require('./crypto')\nconst equals = require('uint8arrays/equals')\n\n/**\n * @typedef {import(\"./types\").Digest} Digest\n * @typedef {import(\"multihashes\").HashName} HashName\n */\n\n/**\n * Hash the given `bytes` using the algorithm specified by `alg`.\n *\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nasync function Multihashing (bytes, alg, length) {\n  const digest = await Multihashing.digest(bytes, alg, length)\n  return multihash.encode(digest, alg, length)\n}\n\n/**\n * Expose multihash itself, to avoid silly double requires.\n */\nMultihashing.multihash = multihash\n\n/**\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nMultihashing.digest = async (bytes, alg, length) => {\n  const hash = Multihashing.createHash(alg)\n  const digest = await hash(bytes)\n  return length ? digest.slice(0, length) : digest\n}\n\n/**\n * Creates a function that hashes with the given algorithm\n *\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @returns {Digest} - The hash function corresponding to `alg`\n */\nMultihashing.createHash = function (alg) {\n  if (!alg) {\n    const e = errcode(new Error('hash algorithm must be specified'), 'ERR_HASH_ALGORITHM_NOT_SPECIFIED')\n    throw e\n  }\n\n  const code = multihash.coerceCode(alg)\n  if (!Multihashing.functions[code]) {\n    throw errcode(new Error(`multihash function '${alg}' not yet supported`), 'ERR_HASH_ALGORITHM_NOT_SUPPORTED')\n  }\n\n  return Multihashing.functions[code]\n}\n\n/**\n * Mapping of multihash codes to their hashing functions.\n *\n * @type {Record<number, Digest>}\n */\n// @ts-ignore - most of those functions aren't typed\nMultihashing.functions = {\n  // identity\n  0x00: crypto.identity,\n  // sha1\n  0x11: crypto.sha1,\n  // sha2-256\n  0x12: crypto.sha2256,\n  // sha2-512\n  0x13: crypto.sha2512,\n  // sha3-512\n  0x14: crypto.sha3512,\n  // sha3-384\n  0x15: crypto.sha3384,\n  // sha3-256\n  0x16: crypto.sha3256,\n  // sha3-224\n  0x17: crypto.sha3224,\n  // shake-128\n  0x18: crypto.shake128,\n  // shake-256\n  0x19: crypto.shake256,\n  // keccak-224\n  0x1A: crypto.keccak224,\n  // keccak-256\n  0x1B: crypto.keccak256,\n  // keccak-384\n  0x1C: crypto.keccak384,\n  // keccak-512\n  0x1D: crypto.keccak512,\n  // murmur3-128\n  0x22: crypto.murmur3128,\n  // murmur3-32\n  0x23: crypto.murmur332,\n  // dbl-sha2-256\n  0x56: crypto.dblSha2256\n}\n\n// add blake functions\ncrypto.addBlake(Multihashing.functions)\n\n/**\n * @param {Uint8Array} bytes\n * @param {Uint8Array} hash\n * @returns {Promise<boolean>}\n */\nMultihashing.validate = async (bytes, hash) => {\n  const newHash = await Multihashing(bytes, multihash.decode(hash).name)\n\n  return equals(hash, newHash)\n}\n\nmodule.exports = Multihashing\n","'use strict';\n\n/**\n * @typedef {{ [key: string]: any }} Extensions\n * @typedef {Error} Err\n * @property {string} message\n */\n\n/**\n *\n * @param {Error} obj\n * @param {Extensions} props\n * @returns {Error & Extensions}\n */\nfunction assign(obj, props) {\n    for (const key in props) {\n        Object.defineProperty(obj, key, {\n            value: props[key],\n            enumerable: true,\n            configurable: true,\n        });\n    }\n\n    return obj;\n}\n\n/**\n *\n * @param {any} err - An Error\n * @param {string|Extensions} code - A string code or props to set on the error\n * @param {Extensions} [props] - Props to set on the error\n * @returns {Error & Extensions}\n */\nfunction createError(err, code, props) {\n    if (!err || typeof err === 'string') {\n        throw new TypeError('Please pass an Error to err-code');\n    }\n\n    if (!props) {\n        props = {};\n    }\n\n    if (typeof code === 'object') {\n        props = code;\n        code = '';\n    }\n\n    if (code) {\n        props.code = code;\n    }\n\n    try {\n        return assign(err, props);\n    } catch (_) {\n        props.message = err.message;\n        props.stack = err.stack;\n\n        const ErrClass = function () {};\n\n        ErrClass.prototype = Object.create(Object.getPrototypeOf(err));\n\n        // @ts-ignore\n        const output = assign(new ErrClass(), props);\n\n        return output;\n    }\n}\n\nmodule.exports = createError;\n","'use strict'\n\nconst baseX = require('@multiformats/base-x')\nconst Base = require('./base.js')\nconst { rfc4648 } = require('./rfc4648')\nconst { decodeText, encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import('./types').Codec} Codec */\n/** @typedef {import('./types').BaseName} BaseName */\n/** @typedef {import('./types').BaseCode} BaseCode */\n\n/** @type {CodecFactory} */\nconst identity = () => {\n  return {\n    encode: decodeText,\n    decode: encodeText\n  }\n}\n\n/**\n *\n * name, code, implementation, alphabet\n *\n * @type {Array<[BaseName, BaseCode, CodecFactory, string]>}\n */\nconst constants = [\n  ['identity', '\\x00', identity, ''],\n  ['base2', '0', rfc4648(1), '01'],\n  ['base8', '7', rfc4648(3), '01234567'],\n  ['base10', '9', baseX, '0123456789'],\n  ['base16', 'f', rfc4648(4), '0123456789abcdef'],\n  ['base16upper', 'F', rfc4648(4), '0123456789ABCDEF'],\n  ['base32hex', 'v', rfc4648(5), '0123456789abcdefghijklmnopqrstuv'],\n  ['base32hexupper', 'V', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV'],\n  ['base32hexpad', 't', rfc4648(5), '0123456789abcdefghijklmnopqrstuv='],\n  ['base32hexpadupper', 'T', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV='],\n  ['base32', 'b', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567'],\n  ['base32upper', 'B', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'],\n  ['base32pad', 'c', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567='],\n  ['base32padupper', 'C', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567='],\n  ['base32z', 'h', rfc4648(5), 'ybndrfg8ejkmcpqxot1uwisza345h769'],\n  ['base36', 'k', baseX, '0123456789abcdefghijklmnopqrstuvwxyz'],\n  ['base36upper', 'K', baseX, '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'],\n  ['base58btc', 'z', baseX, '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'],\n  ['base58flickr', 'Z', baseX, '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'],\n  ['base64', 'm', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'],\n  ['base64pad', 'M', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/='],\n  ['base64url', 'u', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_'],\n  ['base64urlpad', 'U', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=']\n]\n\n/** @type {Record<BaseName,Base>} */\nconst names = constants.reduce((prev, tupple) => {\n  prev[tupple[0]] = new Base(tupple[0], tupple[1], tupple[2], tupple[3])\n  return prev\n}, /** @type {Record<BaseName,Base>} */({}))\n\n/** @type {Record<BaseCode,Base>} */\nconst codes = constants.reduce((prev, tupple) => {\n  prev[tupple[1]] = names[tupple[0]]\n  return prev\n}, /** @type {Record<BaseCode,Base>} */({}))\n\nmodule.exports = {\n  names,\n  codes\n}\n","'use strict'\n\nconst { encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import(\"./types\").BaseName} BaseName */\n/** @typedef {import(\"./types\").BaseCode} BaseCode */\n\n/**\n * Class to encode/decode in the supported Bases\n *\n */\nclass Base {\n  /**\n   * @param {BaseName} name\n   * @param {BaseCode} code\n   * @param {CodecFactory} factory\n   * @param {string} alphabet\n   */\n  constructor (name, code, factory, alphabet) {\n    this.name = name\n    this.code = code\n    this.codeBuf = encodeText(this.code)\n    this.alphabet = alphabet\n    this.codec = factory(alphabet)\n  }\n\n  /**\n   * @param {Uint8Array} buf\n   * @returns {string}\n   */\n  encode (buf) {\n    return this.codec.encode(buf)\n  }\n\n  /**\n   * @param {string} string\n   * @returns {Uint8Array}\n   */\n  decode (string) {\n    for (const char of string) {\n      if (this.alphabet && this.alphabet.indexOf(char) < 0) {\n        throw new Error(`invalid character '${char}' in '${string}'`)\n      }\n    }\n    return this.codec.decode(string)\n  }\n}\n\nmodule.exports = Base\n","'use strict'\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n\n/**\n * @param {string} string\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {Uint8Array}\n */\nconst decode = (string, alphabet, bitsPerChar) => {\n  // Build the character lookup table:\n  /** @type {Record<string, number>} */\n  const codes = {}\n  for (let i = 0; i < alphabet.length; ++i) {\n    codes[alphabet[i]] = i\n  }\n\n  // Count the padding bytes:\n  let end = string.length\n  while (string[end - 1] === '=') {\n    --end\n  }\n\n  // Allocate the output:\n  const out = new Uint8Array((end * bitsPerChar / 8) | 0)\n\n  // Parse the data:\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  let written = 0 // Next byte to write\n  for (let i = 0; i < end; ++i) {\n    // Read one character from the string:\n    const value = codes[string[i]]\n    if (value === undefined) {\n      throw new SyntaxError('Invalid character ' + string[i])\n    }\n\n    // Append the bits to the buffer:\n    buffer = (buffer << bitsPerChar) | value\n    bits += bitsPerChar\n\n    // Write out some bits if the buffer has a byte's worth:\n    if (bits >= 8) {\n      bits -= 8\n      out[written++] = 0xff & (buffer >> bits)\n    }\n  }\n\n  // Verify that we have received just enough bits:\n  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {\n    throw new SyntaxError('Unexpected end of data')\n  }\n\n  return out\n}\n\n/**\n * @param {Uint8Array} data\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {string}\n */\nconst encode = (data, alphabet, bitsPerChar) => {\n  const pad = alphabet[alphabet.length - 1] === '='\n  const mask = (1 << bitsPerChar) - 1\n  let out = ''\n\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  for (let i = 0; i < data.length; ++i) {\n    // Slurp data into the buffer:\n    buffer = (buffer << 8) | data[i]\n    bits += 8\n\n    // Write out as much as we can:\n    while (bits > bitsPerChar) {\n      bits -= bitsPerChar\n      out += alphabet[mask & (buffer >> bits)]\n    }\n  }\n\n  // Partial character:\n  if (bits) {\n    out += alphabet[mask & (buffer << (bitsPerChar - bits))]\n  }\n\n  // Add padding characters until we hit a byte boundary:\n  if (pad) {\n    while ((out.length * bitsPerChar) & 7) {\n      out += '='\n    }\n  }\n\n  return out\n}\n\n/**\n * RFC4648 Factory\n *\n * @param {number} bitsPerChar\n * @returns {CodecFactory}\n */\nconst rfc4648 = (bitsPerChar) => (alphabet) => {\n  return {\n    /**\n     * @param {Uint8Array} input\n     * @returns {string}\n     */\n    encode (input) {\n      return encode(input, alphabet, bitsPerChar)\n    },\n    /**\n     * @param {string} input\n     * @returns {Uint8Array}\n     */\n    decode (input) {\n      return decode(input, alphabet, bitsPerChar)\n    }\n  }\n}\n\nmodule.exports = { rfc4648 }\n","module.exports = {\n    encode: require('./encode.js')\n  , decode: require('./decode.js')\n  , encodingLength: require('./length.js')\n}\n","module.exports = encode\n\nvar MSB = 0x80\n  , REST = 0x7F\n  , MSBALL = ~REST\n  , INT = Math.pow(2, 31)\n\nfunction encode(num, out, offset) {\n  out = out || []\n  offset = offset || 0\n  var oldOffset = offset\n\n  while(num >= INT) {\n    out[offset++] = (num & 0xFF) | MSB\n    num /= 128\n  }\n  while(num & MSBALL) {\n    out[offset++] = (num & 0xFF) | MSB\n    num >>>= 7\n  }\n  out[offset] = num | 0\n  \n  encode.bytes = offset - oldOffset + 1\n  \n  return out\n}\n","module.exports = read\n\nvar MSB = 0x80\n  , REST = 0x7F\n\nfunction read(buf, offset) {\n  var res    = 0\n    , offset = offset || 0\n    , shift  = 0\n    , counter = offset\n    , b\n    , l = buf.length\n\n  do {\n    if (counter >= l) {\n      read.bytes = 0\n      throw new RangeError('Could not decode varint')\n    }\n    b = buf[counter++]\n    res += shift < 28\n      ? (b & REST) << shift\n      : (b & REST) * Math.pow(2, shift)\n    shift += 7\n  } while (b >= MSB)\n\n  read.bytes = counter - offset\n\n  return res\n}\n","\nvar N1 = Math.pow(2,  7)\nvar N2 = Math.pow(2, 14)\nvar N3 = Math.pow(2, 21)\nvar N4 = Math.pow(2, 28)\nvar N5 = Math.pow(2, 35)\nvar N6 = Math.pow(2, 42)\nvar N7 = Math.pow(2, 49)\nvar N8 = Math.pow(2, 56)\nvar N9 = Math.pow(2, 63)\n\nmodule.exports = function (value) {\n  return (\n    value < N1 ? 1\n  : value < N2 ? 2\n  : value < N3 ? 3\n  : value < N4 ? 4\n  : value < N5 ? 5\n  : value < N6 ? 6\n  : value < N7 ? 7\n  : value < N8 ? 8\n  : value < N9 ? 9\n  :              10\n  )\n}\n","/* eslint quote-props: off */\n'use strict'\n\n/**\n * Names for all available hashes\n *\n * @typedef { \"identity\" | \"sha1\" | \"sha2-256\" | \"sha2-512\" | \"sha3-512\" | \"sha3-384\" | \"sha3-256\" | \"sha3-224\" | \"shake-128\" | \"shake-256\" | \"keccak-224\" | \"keccak-256\" | \"keccak-384\" | \"keccak-512\" | \"blake3\" | \"murmur3-128\" | \"murmur3-32\" | \"dbl-sha2-256\" | \"md4\" | \"md5\" | \"bmt\" | \"sha2-256-trunc254-padded\" | \"ripemd-128\" | \"ripemd-160\" | \"ripemd-256\" | \"ripemd-320\" | \"x11\" | \"kangarootwelve\" | \"sm3-256\" | \"blake2b-8\" | \"blake2b-16\" | \"blake2b-24\" | \"blake2b-32\" | \"blake2b-40\" | \"blake2b-48\" | \"blake2b-56\" | \"blake2b-64\" | \"blake2b-72\" | \"blake2b-80\" | \"blake2b-88\" | \"blake2b-96\" | \"blake2b-104\" | \"blake2b-112\" | \"blake2b-120\" | \"blake2b-128\" | \"blake2b-136\" | \"blake2b-144\" | \"blake2b-152\" | \"blake2b-160\" | \"blake2b-168\" | \"blake2b-176\" | \"blake2b-184\" | \"blake2b-192\" | \"blake2b-200\" | \"blake2b-208\" | \"blake2b-216\" | \"blake2b-224\" | \"blake2b-232\" | \"blake2b-240\" | \"blake2b-248\" | \"blake2b-256\" | \"blake2b-264\" | \"blake2b-272\" | \"blake2b-280\" | \"blake2b-288\" | \"blake2b-296\" | \"blake2b-304\" | \"blake2b-312\" | \"blake2b-320\" | \"blake2b-328\" | \"blake2b-336\" | \"blake2b-344\" | \"blake2b-352\" | \"blake2b-360\" | \"blake2b-368\" | \"blake2b-376\" | \"blake2b-384\" | \"blake2b-392\" | \"blake2b-400\" | \"blake2b-408\" | \"blake2b-416\" | \"blake2b-424\" | \"blake2b-432\" | \"blake2b-440\" | \"blake2b-448\" | \"blake2b-456\" | \"blake2b-464\" | \"blake2b-472\" | \"blake2b-480\" | \"blake2b-488\" | \"blake2b-496\" | \"blake2b-504\" | \"blake2b-512\" | \"blake2s-8\" | \"blake2s-16\" | \"blake2s-24\" | \"blake2s-32\" | \"blake2s-40\" | \"blake2s-48\" | \"blake2s-56\" | \"blake2s-64\" | \"blake2s-72\" | \"blake2s-80\" | \"blake2s-88\" | \"blake2s-96\" | \"blake2s-104\" | \"blake2s-112\" | \"blake2s-120\" | \"blake2s-128\" | \"blake2s-136\" | \"blake2s-144\" | \"blake2s-152\" | \"blake2s-160\" | \"blake2s-168\" | \"blake2s-176\" | \"blake2s-184\" | \"blake2s-192\" | \"blake2s-200\" | \"blake2s-208\" | \"blake2s-216\" | \"blake2s-224\" | \"blake2s-232\" | \"blake2s-240\" | \"blake2s-248\" | \"blake2s-256\" | \"skein256-8\" | \"skein256-16\" | \"skein256-24\" | \"skein256-32\" | \"skein256-40\" | \"skein256-48\" | \"skein256-56\" | \"skein256-64\" | \"skein256-72\" | \"skein256-80\" | \"skein256-88\" | \"skein256-96\" | \"skein256-104\" | \"skein256-112\" | \"skein256-120\" | \"skein256-128\" | \"skein256-136\" | \"skein256-144\" | \"skein256-152\" | \"skein256-160\" | \"skein256-168\" | \"skein256-176\" | \"skein256-184\" | \"skein256-192\" | \"skein256-200\" | \"skein256-208\" | \"skein256-216\" | \"skein256-224\" | \"skein256-232\" | \"skein256-240\" | \"skein256-248\" | \"skein256-256\" | \"skein512-8\" | \"skein512-16\" | \"skein512-24\" | \"skein512-32\" | \"skein512-40\" | \"skein512-48\" | \"skein512-56\" | \"skein512-64\" | \"skein512-72\" | \"skein512-80\" | \"skein512-88\" | \"skein512-96\" | \"skein512-104\" | \"skein512-112\" | \"skein512-120\" | \"skein512-128\" | \"skein512-136\" | \"skein512-144\" | \"skein512-152\" | \"skein512-160\" | \"skein512-168\" | \"skein512-176\" | \"skein512-184\" | \"skein512-192\" | \"skein512-200\" | \"skein512-208\" | \"skein512-216\" | \"skein512-224\" | \"skein512-232\" | \"skein512-240\" | \"skein512-248\" | \"skein512-256\" | \"skein512-264\" | \"skein512-272\" | \"skein512-280\" | \"skein512-288\" | \"skein512-296\" | \"skein512-304\" | \"skein512-312\" | \"skein512-320\" | \"skein512-328\" | \"skein512-336\" | \"skein512-344\" | \"skein512-352\" | \"skein512-360\" | \"skein512-368\" | \"skein512-376\" | \"skein512-384\" | \"skein512-392\" | \"skein512-400\" | \"skein512-408\" | \"skein512-416\" | \"skein512-424\" | \"skein512-432\" | \"skein512-440\" | \"skein512-448\" | \"skein512-456\" | \"skein512-464\" | \"skein512-472\" | \"skein512-480\" | \"skein512-488\" | \"skein512-496\" | \"skein512-504\" | \"skein512-512\" | \"skein1024-8\" | \"skein1024-16\" | \"skein1024-24\" | \"skein1024-32\" | \"skein1024-40\" | \"skein1024-48\" | \"skein1024-56\" | \"skein1024-64\" | \"skein1024-72\" | \"skein1024-80\" | \"skein1024-88\" | \"skein1024-96\" | \"skein1024-104\" | \"skein1024-112\" | \"skein1024-120\" | \"skein1024-128\" | \"skein1024-136\" | \"skein1024-144\" | \"skein1024-152\" | \"skein1024-160\" | \"skein1024-168\" | \"skein1024-176\" | \"skein1024-184\" | \"skein1024-192\" | \"skein1024-200\" | \"skein1024-208\" | \"skein1024-216\" | \"skein1024-224\" | \"skein1024-232\" | \"skein1024-240\" | \"skein1024-248\" | \"skein1024-256\" | \"skein1024-264\" | \"skein1024-272\" | \"skein1024-280\" | \"skein1024-288\" | \"skein1024-296\" | \"skein1024-304\" | \"skein1024-312\" | \"skein1024-320\" | \"skein1024-328\" | \"skein1024-336\" | \"skein1024-344\" | \"skein1024-352\" | \"skein1024-360\" | \"skein1024-368\" | \"skein1024-376\" | \"skein1024-384\" | \"skein1024-392\" | \"skein1024-400\" | \"skein1024-408\" | \"skein1024-416\" | \"skein1024-424\" | \"skein1024-432\" | \"skein1024-440\" | \"skein1024-448\" | \"skein1024-456\" | \"skein1024-464\" | \"skein1024-472\" | \"skein1024-480\" | \"skein1024-488\" | \"skein1024-496\" | \"skein1024-504\" | \"skein1024-512\" | \"skein1024-520\" | \"skein1024-528\" | \"skein1024-536\" | \"skein1024-544\" | \"skein1024-552\" | \"skein1024-560\" | \"skein1024-568\" | \"skein1024-576\" | \"skein1024-584\" | \"skein1024-592\" | \"skein1024-600\" | \"skein1024-608\" | \"skein1024-616\" | \"skein1024-624\" | \"skein1024-632\" | \"skein1024-640\" | \"skein1024-648\" | \"skein1024-656\" | \"skein1024-664\" | \"skein1024-672\" | \"skein1024-680\" | \"skein1024-688\" | \"skein1024-696\" | \"skein1024-704\" | \"skein1024-712\" | \"skein1024-720\" | \"skein1024-728\" | \"skein1024-736\" | \"skein1024-744\" | \"skein1024-752\" | \"skein1024-760\" | \"skein1024-768\" | \"skein1024-776\" | \"skein1024-784\" | \"skein1024-792\" | \"skein1024-800\" | \"skein1024-808\" | \"skein1024-816\" | \"skein1024-824\" | \"skein1024-832\" | \"skein1024-840\" | \"skein1024-848\" | \"skein1024-856\" | \"skein1024-864\" | \"skein1024-872\" | \"skein1024-880\" | \"skein1024-888\" | \"skein1024-896\" | \"skein1024-904\" | \"skein1024-912\" | \"skein1024-920\" | \"skein1024-928\" | \"skein1024-936\" | \"skein1024-944\" | \"skein1024-952\" | \"skein1024-960\" | \"skein1024-968\" | \"skein1024-976\" | \"skein1024-984\" | \"skein1024-992\" | \"skein1024-1000\" | \"skein1024-1008\" | \"skein1024-1016\" | \"skein1024-1024\" | \"poseidon-bls12_381-a2-fc1\" | \"poseidon-bls12_381-a2-fc1-sc\" } HashName\n */\n/**\n * Codes for all available hashes\n *\n * @typedef { 0x00 | 0x11 | 0x12 | 0x13 | 0x14 | 0x15 | 0x16 | 0x17 | 0x18 | 0x19 | 0x1a | 0x1b | 0x1c | 0x1d | 0x1e | 0x22 | 0x23 | 0x56 | 0xd4 | 0xd5 | 0xd6 | 0x1012 | 0x1052 | 0x1053 | 0x1054 | 0x1055 | 0x1100 | 0x1d01 | 0x534d | 0xb201 | 0xb202 | 0xb203 | 0xb204 | 0xb205 | 0xb206 | 0xb207 | 0xb208 | 0xb209 | 0xb20a | 0xb20b | 0xb20c | 0xb20d | 0xb20e | 0xb20f | 0xb210 | 0xb211 | 0xb212 | 0xb213 | 0xb214 | 0xb215 | 0xb216 | 0xb217 | 0xb218 | 0xb219 | 0xb21a | 0xb21b | 0xb21c | 0xb21d | 0xb21e | 0xb21f | 0xb220 | 0xb221 | 0xb222 | 0xb223 | 0xb224 | 0xb225 | 0xb226 | 0xb227 | 0xb228 | 0xb229 | 0xb22a | 0xb22b | 0xb22c | 0xb22d | 0xb22e | 0xb22f | 0xb230 | 0xb231 | 0xb232 | 0xb233 | 0xb234 | 0xb235 | 0xb236 | 0xb237 | 0xb238 | 0xb239 | 0xb23a | 0xb23b | 0xb23c | 0xb23d | 0xb23e | 0xb23f | 0xb240 | 0xb241 | 0xb242 | 0xb243 | 0xb244 | 0xb245 | 0xb246 | 0xb247 | 0xb248 | 0xb249 | 0xb24a | 0xb24b | 0xb24c | 0xb24d | 0xb24e | 0xb24f | 0xb250 | 0xb251 | 0xb252 | 0xb253 | 0xb254 | 0xb255 | 0xb256 | 0xb257 | 0xb258 | 0xb259 | 0xb25a | 0xb25b | 0xb25c | 0xb25d | 0xb25e | 0xb25f | 0xb260 | 0xb301 | 0xb302 | 0xb303 | 0xb304 | 0xb305 | 0xb306 | 0xb307 | 0xb308 | 0xb309 | 0xb30a | 0xb30b | 0xb30c | 0xb30d | 0xb30e | 0xb30f | 0xb310 | 0xb311 | 0xb312 | 0xb313 | 0xb314 | 0xb315 | 0xb316 | 0xb317 | 0xb318 | 0xb319 | 0xb31a | 0xb31b | 0xb31c | 0xb31d | 0xb31e | 0xb31f | 0xb320 | 0xb321 | 0xb322 | 0xb323 | 0xb324 | 0xb325 | 0xb326 | 0xb327 | 0xb328 | 0xb329 | 0xb32a | 0xb32b | 0xb32c | 0xb32d | 0xb32e | 0xb32f | 0xb330 | 0xb331 | 0xb332 | 0xb333 | 0xb334 | 0xb335 | 0xb336 | 0xb337 | 0xb338 | 0xb339 | 0xb33a | 0xb33b | 0xb33c | 0xb33d | 0xb33e | 0xb33f | 0xb340 | 0xb341 | 0xb342 | 0xb343 | 0xb344 | 0xb345 | 0xb346 | 0xb347 | 0xb348 | 0xb349 | 0xb34a | 0xb34b | 0xb34c | 0xb34d | 0xb34e | 0xb34f | 0xb350 | 0xb351 | 0xb352 | 0xb353 | 0xb354 | 0xb355 | 0xb356 | 0xb357 | 0xb358 | 0xb359 | 0xb35a | 0xb35b | 0xb35c | 0xb35d | 0xb35e | 0xb35f | 0xb360 | 0xb361 | 0xb362 | 0xb363 | 0xb364 | 0xb365 | 0xb366 | 0xb367 | 0xb368 | 0xb369 | 0xb36a | 0xb36b | 0xb36c | 0xb36d | 0xb36e | 0xb36f | 0xb370 | 0xb371 | 0xb372 | 0xb373 | 0xb374 | 0xb375 | 0xb376 | 0xb377 | 0xb378 | 0xb379 | 0xb37a | 0xb37b | 0xb37c | 0xb37d | 0xb37e | 0xb37f | 0xb380 | 0xb381 | 0xb382 | 0xb383 | 0xb384 | 0xb385 | 0xb386 | 0xb387 | 0xb388 | 0xb389 | 0xb38a | 0xb38b | 0xb38c | 0xb38d | 0xb38e | 0xb38f | 0xb390 | 0xb391 | 0xb392 | 0xb393 | 0xb394 | 0xb395 | 0xb396 | 0xb397 | 0xb398 | 0xb399 | 0xb39a | 0xb39b | 0xb39c | 0xb39d | 0xb39e | 0xb39f | 0xb3a0 | 0xb3a1 | 0xb3a2 | 0xb3a3 | 0xb3a4 | 0xb3a5 | 0xb3a6 | 0xb3a7 | 0xb3a8 | 0xb3a9 | 0xb3aa | 0xb3ab | 0xb3ac | 0xb3ad | 0xb3ae | 0xb3af | 0xb3b0 | 0xb3b1 | 0xb3b2 | 0xb3b3 | 0xb3b4 | 0xb3b5 | 0xb3b6 | 0xb3b7 | 0xb3b8 | 0xb3b9 | 0xb3ba | 0xb3bb | 0xb3bc | 0xb3bd | 0xb3be | 0xb3bf | 0xb3c0 | 0xb3c1 | 0xb3c2 | 0xb3c3 | 0xb3c4 | 0xb3c5 | 0xb3c6 | 0xb3c7 | 0xb3c8 | 0xb3c9 | 0xb3ca | 0xb3cb | 0xb3cc | 0xb3cd | 0xb3ce | 0xb3cf | 0xb3d0 | 0xb3d1 | 0xb3d2 | 0xb3d3 | 0xb3d4 | 0xb3d5 | 0xb3d6 | 0xb3d7 | 0xb3d8 | 0xb3d9 | 0xb3da | 0xb3db | 0xb3dc | 0xb3dd | 0xb3de | 0xb3df | 0xb3e0 | 0xb401 | 0xb402 } HashCode\n */\n\n/**\n * @type { Record<HashName,HashCode> }\n */\nconst names = Object.freeze({\n  'identity': 0x00,\n  'sha1': 0x11,\n  'sha2-256': 0x12,\n  'sha2-512': 0x13,\n  'sha3-512': 0x14,\n  'sha3-384': 0x15,\n  'sha3-256': 0x16,\n  'sha3-224': 0x17,\n  'shake-128': 0x18,\n  'shake-256': 0x19,\n  'keccak-224': 0x1a,\n  'keccak-256': 0x1b,\n  'keccak-384': 0x1c,\n  'keccak-512': 0x1d,\n  'blake3': 0x1e,\n  'murmur3-128': 0x22,\n  'murmur3-32': 0x23,\n  'dbl-sha2-256': 0x56,\n  'md4': 0xd4,\n  'md5': 0xd5,\n  'bmt': 0xd6,\n  'sha2-256-trunc254-padded': 0x1012,\n  'ripemd-128': 0x1052,\n  'ripemd-160': 0x1053,\n  'ripemd-256': 0x1054,\n  'ripemd-320': 0x1055,\n  'x11': 0x1100,\n  'kangarootwelve': 0x1d01,\n  'sm3-256': 0x534d,\n  'blake2b-8': 0xb201,\n  'blake2b-16': 0xb202,\n  'blake2b-24': 0xb203,\n  'blake2b-32': 0xb204,\n  'blake2b-40': 0xb205,\n  'blake2b-48': 0xb206,\n  'blake2b-56': 0xb207,\n  'blake2b-64': 0xb208,\n  'blake2b-72': 0xb209,\n  'blake2b-80': 0xb20a,\n  'blake2b-88': 0xb20b,\n  'blake2b-96': 0xb20c,\n  'blake2b-104': 0xb20d,\n  'blake2b-112': 0xb20e,\n  'blake2b-120': 0xb20f,\n  'blake2b-128': 0xb210,\n  'blake2b-136': 0xb211,\n  'blake2b-144': 0xb212,\n  'blake2b-152': 0xb213,\n  'blake2b-160': 0xb214,\n  'blake2b-168': 0xb215,\n  'blake2b-176': 0xb216,\n  'blake2b-184': 0xb217,\n  'blake2b-192': 0xb218,\n  'blake2b-200': 0xb219,\n  'blake2b-208': 0xb21a,\n  'blake2b-216': 0xb21b,\n  'blake2b-224': 0xb21c,\n  'blake2b-232': 0xb21d,\n  'blake2b-240': 0xb21e,\n  'blake2b-248': 0xb21f,\n  'blake2b-256': 0xb220,\n  'blake2b-264': 0xb221,\n  'blake2b-272': 0xb222,\n  'blake2b-280': 0xb223,\n  'blake2b-288': 0xb224,\n  'blake2b-296': 0xb225,\n  'blake2b-304': 0xb226,\n  'blake2b-312': 0xb227,\n  'blake2b-320': 0xb228,\n  'blake2b-328': 0xb229,\n  'blake2b-336': 0xb22a,\n  'blake2b-344': 0xb22b,\n  'blake2b-352': 0xb22c,\n  'blake2b-360': 0xb22d,\n  'blake2b-368': 0xb22e,\n  'blake2b-376': 0xb22f,\n  'blake2b-384': 0xb230,\n  'blake2b-392': 0xb231,\n  'blake2b-400': 0xb232,\n  'blake2b-408': 0xb233,\n  'blake2b-416': 0xb234,\n  'blake2b-424': 0xb235,\n  'blake2b-432': 0xb236,\n  'blake2b-440': 0xb237,\n  'blake2b-448': 0xb238,\n  'blake2b-456': 0xb239,\n  'blake2b-464': 0xb23a,\n  'blake2b-472': 0xb23b,\n  'blake2b-480': 0xb23c,\n  'blake2b-488': 0xb23d,\n  'blake2b-496': 0xb23e,\n  'blake2b-504': 0xb23f,\n  'blake2b-512': 0xb240,\n  'blake2s-8': 0xb241,\n  'blake2s-16': 0xb242,\n  'blake2s-24': 0xb243,\n  'blake2s-32': 0xb244,\n  'blake2s-40': 0xb245,\n  'blake2s-48': 0xb246,\n  'blake2s-56': 0xb247,\n  'blake2s-64': 0xb248,\n  'blake2s-72': 0xb249,\n  'blake2s-80': 0xb24a,\n  'blake2s-88': 0xb24b,\n  'blake2s-96': 0xb24c,\n  'blake2s-104': 0xb24d,\n  'blake2s-112': 0xb24e,\n  'blake2s-120': 0xb24f,\n  'blake2s-128': 0xb250,\n  'blake2s-136': 0xb251,\n  'blake2s-144': 0xb252,\n  'blake2s-152': 0xb253,\n  'blake2s-160': 0xb254,\n  'blake2s-168': 0xb255,\n  'blake2s-176': 0xb256,\n  'blake2s-184': 0xb257,\n  'blake2s-192': 0xb258,\n  'blake2s-200': 0xb259,\n  'blake2s-208': 0xb25a,\n  'blake2s-216': 0xb25b,\n  'blake2s-224': 0xb25c,\n  'blake2s-232': 0xb25d,\n  'blake2s-240': 0xb25e,\n  'blake2s-248': 0xb25f,\n  'blake2s-256': 0xb260,\n  'skein256-8': 0xb301,\n  'skein256-16': 0xb302,\n  'skein256-24': 0xb303,\n  'skein256-32': 0xb304,\n  'skein256-40': 0xb305,\n  'skein256-48': 0xb306,\n  'skein256-56': 0xb307,\n  'skein256-64': 0xb308,\n  'skein256-72': 0xb309,\n  'skein256-80': 0xb30a,\n  'skein256-88': 0xb30b,\n  'skein256-96': 0xb30c,\n  'skein256-104': 0xb30d,\n  'skein256-112': 0xb30e,\n  'skein256-120': 0xb30f,\n  'skein256-128': 0xb310,\n  'skein256-136': 0xb311,\n  'skein256-144': 0xb312,\n  'skein256-152': 0xb313,\n  'skein256-160': 0xb314,\n  'skein256-168': 0xb315,\n  'skein256-176': 0xb316,\n  'skein256-184': 0xb317,\n  'skein256-192': 0xb318,\n  'skein256-200': 0xb319,\n  'skein256-208': 0xb31a,\n  'skein256-216': 0xb31b,\n  'skein256-224': 0xb31c,\n  'skein256-232': 0xb31d,\n  'skein256-240': 0xb31e,\n  'skein256-248': 0xb31f,\n  'skein256-256': 0xb320,\n  'skein512-8': 0xb321,\n  'skein512-16': 0xb322,\n  'skein512-24': 0xb323,\n  'skein512-32': 0xb324,\n  'skein512-40': 0xb325,\n  'skein512-48': 0xb326,\n  'skein512-56': 0xb327,\n  'skein512-64': 0xb328,\n  'skein512-72': 0xb329,\n  'skein512-80': 0xb32a,\n  'skein512-88': 0xb32b,\n  'skein512-96': 0xb32c,\n  'skein512-104': 0xb32d,\n  'skein512-112': 0xb32e,\n  'skein512-120': 0xb32f,\n  'skein512-128': 0xb330,\n  'skein512-136': 0xb331,\n  'skein512-144': 0xb332,\n  'skein512-152': 0xb333,\n  'skein512-160': 0xb334,\n  'skein512-168': 0xb335,\n  'skein512-176': 0xb336,\n  'skein512-184': 0xb337,\n  'skein512-192': 0xb338,\n  'skein512-200': 0xb339,\n  'skein512-208': 0xb33a,\n  'skein512-216': 0xb33b,\n  'skein512-224': 0xb33c,\n  'skein512-232': 0xb33d,\n  'skein512-240': 0xb33e,\n  'skein512-248': 0xb33f,\n  'skein512-256': 0xb340,\n  'skein512-264': 0xb341,\n  'skein512-272': 0xb342,\n  'skein512-280': 0xb343,\n  'skein512-288': 0xb344,\n  'skein512-296': 0xb345,\n  'skein512-304': 0xb346,\n  'skein512-312': 0xb347,\n  'skein512-320': 0xb348,\n  'skein512-328': 0xb349,\n  'skein512-336': 0xb34a,\n  'skein512-344': 0xb34b,\n  'skein512-352': 0xb34c,\n  'skein512-360': 0xb34d,\n  'skein512-368': 0xb34e,\n  'skein512-376': 0xb34f,\n  'skein512-384': 0xb350,\n  'skein512-392': 0xb351,\n  'skein512-400': 0xb352,\n  'skein512-408': 0xb353,\n  'skein512-416': 0xb354,\n  'skein512-424': 0xb355,\n  'skein512-432': 0xb356,\n  'skein512-440': 0xb357,\n  'skein512-448': 0xb358,\n  'skein512-456': 0xb359,\n  'skein512-464': 0xb35a,\n  'skein512-472': 0xb35b,\n  'skein512-480': 0xb35c,\n  'skein512-488': 0xb35d,\n  'skein512-496': 0xb35e,\n  'skein512-504': 0xb35f,\n  'skein512-512': 0xb360,\n  'skein1024-8': 0xb361,\n  'skein1024-16': 0xb362,\n  'skein1024-24': 0xb363,\n  'skein1024-32': 0xb364,\n  'skein1024-40': 0xb365,\n  'skein1024-48': 0xb366,\n  'skein1024-56': 0xb367,\n  'skein1024-64': 0xb368,\n  'skein1024-72': 0xb369,\n  'skein1024-80': 0xb36a,\n  'skein1024-88': 0xb36b,\n  'skein1024-96': 0xb36c,\n  'skein1024-104': 0xb36d,\n  'skein1024-112': 0xb36e,\n  'skein1024-120': 0xb36f,\n  'skein1024-128': 0xb370,\n  'skein1024-136': 0xb371,\n  'skein1024-144': 0xb372,\n  'skein1024-152': 0xb373,\n  'skein1024-160': 0xb374,\n  'skein1024-168': 0xb375,\n  'skein1024-176': 0xb376,\n  'skein1024-184': 0xb377,\n  'skein1024-192': 0xb378,\n  'skein1024-200': 0xb379,\n  'skein1024-208': 0xb37a,\n  'skein1024-216': 0xb37b,\n  'skein1024-224': 0xb37c,\n  'skein1024-232': 0xb37d,\n  'skein1024-240': 0xb37e,\n  'skein1024-248': 0xb37f,\n  'skein1024-256': 0xb380,\n  'skein1024-264': 0xb381,\n  'skein1024-272': 0xb382,\n  'skein1024-280': 0xb383,\n  'skein1024-288': 0xb384,\n  'skein1024-296': 0xb385,\n  'skein1024-304': 0xb386,\n  'skein1024-312': 0xb387,\n  'skein1024-320': 0xb388,\n  'skein1024-328': 0xb389,\n  'skein1024-336': 0xb38a,\n  'skein1024-344': 0xb38b,\n  'skein1024-352': 0xb38c,\n  'skein1024-360': 0xb38d,\n  'skein1024-368': 0xb38e,\n  'skein1024-376': 0xb38f,\n  'skein1024-384': 0xb390,\n  'skein1024-392': 0xb391,\n  'skein1024-400': 0xb392,\n  'skein1024-408': 0xb393,\n  'skein1024-416': 0xb394,\n  'skein1024-424': 0xb395,\n  'skein1024-432': 0xb396,\n  'skein1024-440': 0xb397,\n  'skein1024-448': 0xb398,\n  'skein1024-456': 0xb399,\n  'skein1024-464': 0xb39a,\n  'skein1024-472': 0xb39b,\n  'skein1024-480': 0xb39c,\n  'skein1024-488': 0xb39d,\n  'skein1024-496': 0xb39e,\n  'skein1024-504': 0xb39f,\n  'skein1024-512': 0xb3a0,\n  'skein1024-520': 0xb3a1,\n  'skein1024-528': 0xb3a2,\n  'skein1024-536': 0xb3a3,\n  'skein1024-544': 0xb3a4,\n  'skein1024-552': 0xb3a5,\n  'skein1024-560': 0xb3a6,\n  'skein1024-568': 0xb3a7,\n  'skein1024-576': 0xb3a8,\n  'skein1024-584': 0xb3a9,\n  'skein1024-592': 0xb3aa,\n  'skein1024-600': 0xb3ab,\n  'skein1024-608': 0xb3ac,\n  'skein1024-616': 0xb3ad,\n  'skein1024-624': 0xb3ae,\n  'skein1024-632': 0xb3af,\n  'skein1024-640': 0xb3b0,\n  'skein1024-648': 0xb3b1,\n  'skein1024-656': 0xb3b2,\n  'skein1024-664': 0xb3b3,\n  'skein1024-672': 0xb3b4,\n  'skein1024-680': 0xb3b5,\n  'skein1024-688': 0xb3b6,\n  'skein1024-696': 0xb3b7,\n  'skein1024-704': 0xb3b8,\n  'skein1024-712': 0xb3b9,\n  'skein1024-720': 0xb3ba,\n  'skein1024-728': 0xb3bb,\n  'skein1024-736': 0xb3bc,\n  'skein1024-744': 0xb3bd,\n  'skein1024-752': 0xb3be,\n  'skein1024-760': 0xb3bf,\n  'skein1024-768': 0xb3c0,\n  'skein1024-776': 0xb3c1,\n  'skein1024-784': 0xb3c2,\n  'skein1024-792': 0xb3c3,\n  'skein1024-800': 0xb3c4,\n  'skein1024-808': 0xb3c5,\n  'skein1024-816': 0xb3c6,\n  'skein1024-824': 0xb3c7,\n  'skein1024-832': 0xb3c8,\n  'skein1024-840': 0xb3c9,\n  'skein1024-848': 0xb3ca,\n  'skein1024-856': 0xb3cb,\n  'skein1024-864': 0xb3cc,\n  'skein1024-872': 0xb3cd,\n  'skein1024-880': 0xb3ce,\n  'skein1024-888': 0xb3cf,\n  'skein1024-896': 0xb3d0,\n  'skein1024-904': 0xb3d1,\n  'skein1024-912': 0xb3d2,\n  'skein1024-920': 0xb3d3,\n  'skein1024-928': 0xb3d4,\n  'skein1024-936': 0xb3d5,\n  'skein1024-944': 0xb3d6,\n  'skein1024-952': 0xb3d7,\n  'skein1024-960': 0xb3d8,\n  'skein1024-968': 0xb3d9,\n  'skein1024-976': 0xb3da,\n  'skein1024-984': 0xb3db,\n  'skein1024-992': 0xb3dc,\n  'skein1024-1000': 0xb3dd,\n  'skein1024-1008': 0xb3de,\n  'skein1024-1016': 0xb3df,\n  'skein1024-1024': 0xb3e0,\n  'poseidon-bls12_381-a2-fc1': 0xb401,\n  'poseidon-bls12_381-a2-fc1-sc': 0xb402\n})\n\nmodule.exports = { names }\n","'use strict'\n\nconst { encoding: getCodec } = require('multibase')\nconst { TextDecoder } = require('web-encoding')\nconst utf8Decoder = new TextDecoder('utf8')\n\n/**\n * @typedef {import('multibase/src/types').BaseName} BaseName\n */\n\n/**\n * Turns a Uint8Array of bytes into a string with each\n * character being the char code of the corresponding byte\n *\n * @param {Uint8Array} array - The array to turn into a string\n */\nfunction uint8ArrayToAsciiString (array) {\n  let string = ''\n\n  for (let i = 0; i < array.length; i++) {\n    string += String.fromCharCode(array[i])\n  }\n  return string\n}\n\n/**\n * Turns a `Uint8Array` into a string.\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {Uint8Array} array - The array to turn into a string\n * @param {BaseName | 'utf8' | 'utf-8' | 'ascii'} [encoding=utf8] - The encoding to use\n * @returns {string}\n */\nfunction toString (array, encoding = 'utf8') {\n  if (encoding === 'utf8' || encoding === 'utf-8') {\n    return utf8Decoder.decode(array)\n  }\n\n  if (encoding === 'ascii') {\n    return uint8ArrayToAsciiString(array)\n  }\n\n  return getCodec(encoding).encode(array)\n}\n\nmodule.exports = toString\n","'use strict'\n\nconst { encoding: getCodec } = require('multibase')\nconst { TextEncoder } = require('web-encoding')\nconst utf8Encoder = new TextEncoder()\n\n/**\n * @typedef {import('multibase/src/types').BaseName} BaseName\n */\n\n/**\n * Interprets each character in a string as a byte and\n * returns a Uint8Array of those bytes.\n *\n * @param {string} string - The string to turn into an array\n */\nfunction asciiStringToUint8Array (string) {\n  const array = new Uint8Array(string.length)\n\n  for (let i = 0; i < string.length; i++) {\n    array[i] = string.charCodeAt(i)\n  }\n\n  return array\n}\n\n/**\n * Create a `Uint8Array` from the passed string\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {string} string\n * @param {BaseName | 'utf8' | 'utf-8' | 'ascii'} [encoding=utf8] - utf8, base16, base64, base64urlpad, etc\n * @returns {Uint8Array}\n */\nfunction fromString (string, encoding = 'utf8') {\n  if (encoding === 'utf8' || encoding === 'utf-8') {\n    return utf8Encoder.encode(string)\n  }\n\n  if (encoding === 'ascii') {\n    return asciiStringToUint8Array(string)\n  }\n\n  return getCodec(encoding).decode(string)\n}\n\nmodule.exports = fromString\n","'use strict'\n\n/**\n * Returns a new Uint8Array created by concatenating the passed ArrayLikes\n *\n * @param {Array<ArrayLike<number>>} arrays\n * @param {number} [length]\n */\nfunction concat (arrays, length) {\n  if (!length) {\n    length = arrays.reduce((acc, curr) => acc + curr.length, 0)\n  }\n\n  const output = new Uint8Array(length)\n  let offset = 0\n\n  for (const arr of arrays) {\n    output.set(arr, offset)\n    offset += arr.length\n  }\n\n  return output\n}\n\nmodule.exports = concat\n","'use strict'\n\nconst sha3 = require('js-sha3')\n// @ts-ignore - no types available\nconst mur = require('murmurhash3js-revisited')\nconst { factory: sha } = require('./sha')\nconst { fromNumberTo32BitBuf } = require('./utils')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\n// Note that although this function doesn't do any asynchronous work, we mark\n// the function as async because it must return a Promise to match the API\n// for other functions that do perform asynchronous work (see sha.browser.js)\n// eslint-disable-next-line\n/**\n * @param {string} algorithm\n * @returns {import('./types').Digest}\n */\nconst hash = (algorithm) => async (data) => {\n  switch (algorithm) {\n    case 'sha3-224':\n      return new Uint8Array(sha3.sha3_224.arrayBuffer(data))\n    case 'sha3-256':\n      return new Uint8Array(sha3.sha3_256.arrayBuffer(data))\n    case 'sha3-384':\n      return new Uint8Array(sha3.sha3_384.arrayBuffer(data))\n    case 'sha3-512':\n      return new Uint8Array(sha3.sha3_512.arrayBuffer(data))\n    case 'shake-128':\n      return new Uint8Array(sha3.shake128.create(128).update(data).arrayBuffer())\n    case 'shake-256':\n      return new Uint8Array(sha3.shake256.create(256).update(data).arrayBuffer())\n    case 'keccak-224':\n      return new Uint8Array(sha3.keccak224.arrayBuffer(data))\n    case 'keccak-256':\n      return new Uint8Array(sha3.keccak256.arrayBuffer(data))\n    case 'keccak-384':\n      return new Uint8Array(sha3.keccak384.arrayBuffer(data))\n    case 'keccak-512':\n      return new Uint8Array(sha3.keccak512.arrayBuffer(data))\n    case 'murmur3-128':\n      return uint8ArrayFromString(mur.x64.hash128(data), 'base16')\n    case 'murmur3-32':\n      return fromNumberTo32BitBuf(mur.x86.hash32(data))\n\n    default:\n      throw new TypeError(`${algorithm} is not a supported algorithm`)\n  }\n}\n\n/** @type {import('./types').Digest} */\nconst identity = data => data\n\nmodule.exports = {\n  identity,\n  sha1: sha('sha1'),\n  sha2256: sha('sha2-256'),\n  sha2512: sha('sha2-512'),\n  dblSha2256: sha('dbl-sha2-256'),\n  sha3224: hash('sha3-224'),\n  sha3256: hash('sha3-256'),\n  sha3384: hash('sha3-384'),\n  sha3512: hash('sha3-512'),\n  shake128: hash('shake-128'),\n  shake256: hash('shake-256'),\n  keccak224: hash('keccak-224'),\n  keccak256: hash('keccak-256'),\n  keccak384: hash('keccak-384'),\n  keccak512: hash('keccak-512'),\n  murmur3128: hash('murmur3-128'),\n  murmur332: hash('murmur3-32'),\n  addBlake: require('./blake')\n}\n","/* globals __webpack_amd_options__ */\nmodule.exports = __webpack_amd_options__;\n","/* jshint -W086: true */\n// +----------------------------------------------------------------------+\n// | murmurHash3js.js v3.0.1 // https://github.com/pid/murmurHash3js\n// | A javascript implementation of MurmurHash3's x86 hashing algorithms. |\n// |----------------------------------------------------------------------|\n// | Copyright (c) 2012-2015 Karan Lyons                                       |\n// | https://github.com/karanlyons/murmurHash3.js/blob/c1778f75792abef7bdd74bc85d2d4e1a3d25cfe9/murmurHash3.js |\n// | Freely distributable under the MIT license.                          |\n// +----------------------------------------------------------------------+\n\n;(function (root, undefined) {\n    'use strict';\n\n    // Create a local object that'll be exported or referenced globally.\n    var library = {\n        'version': '3.0.0',\n        'x86': {},\n        'x64': {},\n        'inputValidation': true\n    };\n\n    // PRIVATE FUNCTIONS\n    // -----------------\n\n    function _validBytes(bytes) {\n        // check the input is an array or a typed array\n        if (!Array.isArray(bytes) && !ArrayBuffer.isView(bytes)) {\n            return false;\n        }\n\n        // check all bytes are actually bytes\n        for (var i = 0; i < bytes.length; i++) {\n            if (!Number.isInteger(bytes[i]) || bytes[i] < 0 || bytes[i] > 255) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    function _x86Multiply(m, n) {\n        //\n        // Given two 32bit ints, returns the two multiplied together as a\n        // 32bit int.\n        //\n\n        return ((m & 0xffff) * n) + ((((m >>> 16) * n) & 0xffff) << 16);\n    }\n\n    function _x86Rotl(m, n) {\n        //\n        // Given a 32bit int and an int representing a number of bit positions,\n        // returns the 32bit int rotated left by that number of positions.\n        //\n\n        return (m << n) | (m >>> (32 - n));\n    }\n\n    function _x86Fmix(h) {\n        //\n        // Given a block, returns murmurHash3's final x86 mix of that block.\n        //\n\n        h ^= h >>> 16;\n        h = _x86Multiply(h, 0x85ebca6b);\n        h ^= h >>> 13;\n        h = _x86Multiply(h, 0xc2b2ae35);\n        h ^= h >>> 16;\n\n        return h;\n    }\n\n    function _x64Add(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // added together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n        n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n        var o = [0, 0, 0, 0];\n\n        o[3] += m[3] + n[3];\n        o[2] += o[3] >>> 16;\n        o[3] &= 0xffff;\n\n        o[2] += m[2] + n[2];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[1] += m[1] + n[1];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[0] += m[0] + n[0];\n        o[0] &= 0xffff;\n\n        return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];\n    }\n\n    function _x64Multiply(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // multiplied together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n        n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n        var o = [0, 0, 0, 0];\n\n        o[3] += m[3] * n[3];\n        o[2] += o[3] >>> 16;\n        o[3] &= 0xffff;\n\n        o[2] += m[2] * n[3];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[2] += m[3] * n[2];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[1] += m[1] * n[3];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[1] += m[2] * n[2];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[1] += m[3] * n[1];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[0] += (m[0] * n[3]) + (m[1] * n[2]) + (m[2] * n[1]) + (m[3] * n[0]);\n        o[0] &= 0xffff;\n\n        return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];\n    }\n\n    function _x64Rotl(m, n) {\n        //\n        // Given a 64bit int (as an array of two 32bit ints) and an int\n        // representing a number of bit positions, returns the 64bit int (as an\n        // array of two 32bit ints) rotated left by that number of positions.\n        //\n\n        n %= 64;\n\n        if (n === 32) {\n            return [m[1], m[0]];\n        } else if (n < 32) {\n            return [(m[0] << n) | (m[1] >>> (32 - n)), (m[1] << n) | (m[0] >>> (32 - n))];\n        } else {\n            n -= 32;\n            return [(m[1] << n) | (m[0] >>> (32 - n)), (m[0] << n) | (m[1] >>> (32 - n))];\n        }\n    }\n\n    function _x64LeftShift(m, n) {\n        //\n        // Given a 64bit int (as an array of two 32bit ints) and an int\n        // representing a number of bit positions, returns the 64bit int (as an\n        // array of two 32bit ints) shifted left by that number of positions.\n        //\n\n        n %= 64;\n\n        if (n === 0) {\n            return m;\n        } else if (n < 32) {\n            return [(m[0] << n) | (m[1] >>> (32 - n)), m[1] << n];\n        } else {\n            return [m[1] << (n - 32), 0];\n        }\n    }\n\n    function _x64Xor(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // xored together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        return [m[0] ^ n[0], m[1] ^ n[1]];\n    }\n\n    function _x64Fmix(h) {\n        //\n        // Given a block, returns murmurHash3's final x64 mix of that block.\n        // (`[0, h[0] >>> 1]` is a 33 bit unsigned right shift. This is the\n        // only place where we need to right shift 64bit ints.)\n        //\n\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n        h = _x64Multiply(h, [0xff51afd7, 0xed558ccd]);\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n        h = _x64Multiply(h, [0xc4ceb9fe, 0x1a85ec53]);\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n\n        return h;\n    }\n\n    // PUBLIC FUNCTIONS\n    // ----------------\n\n    library.x86.hash32 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 32 bit hash\n        // using the x86 flavor of MurmurHash3, as an unsigned int.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n        seed = seed || 0;\n\n        var remainder = bytes.length % 4;\n        var blocks = bytes.length - remainder;\n\n        var h1 = seed;\n\n        var k1 = 0;\n\n        var c1 = 0xcc9e2d51;\n        var c2 = 0x1b873593;\n\n        for (var i = 0; i < blocks; i = i + 4) {\n            k1 = (bytes[i]) | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);\n\n            k1 = _x86Multiply(k1, c1);\n            k1 = _x86Rotl(k1, 15);\n            k1 = _x86Multiply(k1, c2);\n\n            h1 ^= k1;\n            h1 = _x86Rotl(h1, 13);\n            h1 = _x86Multiply(h1, 5) + 0xe6546b64;\n        }\n\n        k1 = 0;\n\n        switch (remainder) {\n            case 3:\n                k1 ^= bytes[i + 2] << 16;\n\n            case 2:\n                k1 ^= bytes[i + 1] << 8;\n\n            case 1:\n                k1 ^= bytes[i];\n                k1 = _x86Multiply(k1, c1);\n                k1 = _x86Rotl(k1, 15);\n                k1 = _x86Multiply(k1, c2);\n                h1 ^= k1;\n        }\n\n        h1 ^= bytes.length;\n        h1 = _x86Fmix(h1);\n\n        return h1 >>> 0;\n    };\n\n    library.x86.hash128 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 128 bit\n        // hash using the x86 flavor of MurmurHash3, as an unsigned hex.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n\n        seed = seed || 0;\n        var remainder = bytes.length % 16;\n        var blocks = bytes.length - remainder;\n\n        var h1 = seed;\n        var h2 = seed;\n        var h3 = seed;\n        var h4 = seed;\n\n        var k1 = 0;\n        var k2 = 0;\n        var k3 = 0;\n        var k4 = 0;\n\n        var c1 = 0x239b961b;\n        var c2 = 0xab0e9789;\n        var c3 = 0x38b34ae5;\n        var c4 = 0xa1e38b93;\n\n        for (var i = 0; i < blocks; i = i + 16) {\n            k1 = (bytes[i]) | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);\n            k2 = (bytes[i + 4]) | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24);\n            k3 = (bytes[i + 8]) | (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24);\n            k4 = (bytes[i + 12]) | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24);\n\n            k1 = _x86Multiply(k1, c1);\n            k1 = _x86Rotl(k1, 15);\n            k1 = _x86Multiply(k1, c2);\n            h1 ^= k1;\n\n            h1 = _x86Rotl(h1, 19);\n            h1 += h2;\n            h1 = _x86Multiply(h1, 5) + 0x561ccd1b;\n\n            k2 = _x86Multiply(k2, c2);\n            k2 = _x86Rotl(k2, 16);\n            k2 = _x86Multiply(k2, c3);\n            h2 ^= k2;\n\n            h2 = _x86Rotl(h2, 17);\n            h2 += h3;\n            h2 = _x86Multiply(h2, 5) + 0x0bcaa747;\n\n            k3 = _x86Multiply(k3, c3);\n            k3 = _x86Rotl(k3, 17);\n            k3 = _x86Multiply(k3, c4);\n            h3 ^= k3;\n\n            h3 = _x86Rotl(h3, 15);\n            h3 += h4;\n            h3 = _x86Multiply(h3, 5) + 0x96cd1c35;\n\n            k4 = _x86Multiply(k4, c4);\n            k4 = _x86Rotl(k4, 18);\n            k4 = _x86Multiply(k4, c1);\n            h4 ^= k4;\n\n            h4 = _x86Rotl(h4, 13);\n            h4 += h1;\n            h4 = _x86Multiply(h4, 5) + 0x32ac3b17;\n        }\n\n        k1 = 0;\n        k2 = 0;\n        k3 = 0;\n        k4 = 0;\n\n        switch (remainder) {\n            case 15:\n                k4 ^= bytes[i + 14] << 16;\n\n            case 14:\n                k4 ^= bytes[i + 13] << 8;\n\n            case 13:\n                k4 ^= bytes[i + 12];\n                k4 = _x86Multiply(k4, c4);\n                k4 = _x86Rotl(k4, 18);\n                k4 = _x86Multiply(k4, c1);\n                h4 ^= k4;\n\n            case 12:\n                k3 ^= bytes[i + 11] << 24;\n\n            case 11:\n                k3 ^= bytes[i + 10] << 16;\n\n            case 10:\n                k3 ^= bytes[i + 9] << 8;\n\n            case 9:\n                k3 ^= bytes[i + 8];\n                k3 = _x86Multiply(k3, c3);\n                k3 = _x86Rotl(k3, 17);\n                k3 = _x86Multiply(k3, c4);\n                h3 ^= k3;\n\n            case 8:\n                k2 ^= bytes[i + 7] << 24;\n\n            case 7:\n                k2 ^= bytes[i + 6] << 16;\n\n            case 6:\n                k2 ^= bytes[i + 5] << 8;\n\n            case 5:\n                k2 ^= bytes[i + 4];\n                k2 = _x86Multiply(k2, c2);\n                k2 = _x86Rotl(k2, 16);\n                k2 = _x86Multiply(k2, c3);\n                h2 ^= k2;\n\n            case 4:\n                k1 ^= bytes[i + 3] << 24;\n\n            case 3:\n                k1 ^= bytes[i + 2] << 16;\n\n            case 2:\n                k1 ^= bytes[i + 1] << 8;\n\n            case 1:\n                k1 ^= bytes[i];\n                k1 = _x86Multiply(k1, c1);\n                k1 = _x86Rotl(k1, 15);\n                k1 = _x86Multiply(k1, c2);\n                h1 ^= k1;\n        }\n\n        h1 ^= bytes.length;\n        h2 ^= bytes.length;\n        h3 ^= bytes.length;\n        h4 ^= bytes.length;\n\n        h1 += h2;\n        h1 += h3;\n        h1 += h4;\n        h2 += h1;\n        h3 += h1;\n        h4 += h1;\n\n        h1 = _x86Fmix(h1);\n        h2 = _x86Fmix(h2);\n        h3 = _x86Fmix(h3);\n        h4 = _x86Fmix(h4);\n\n        h1 += h2;\n        h1 += h3;\n        h1 += h4;\n        h2 += h1;\n        h3 += h1;\n        h4 += h1;\n\n        return (\"00000000\" + (h1 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h3 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h4 >>> 0).toString(16)).slice(-8);\n    };\n\n    library.x64.hash128 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 128 bit\n        // hash using the x64 flavor of MurmurHash3, as an unsigned hex.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n        seed = seed || 0;\n\n        var remainder = bytes.length % 16;\n        var blocks = bytes.length - remainder;\n\n        var h1 = [0, seed];\n        var h2 = [0, seed];\n\n        var k1 = [0, 0];\n        var k2 = [0, 0];\n\n        var c1 = [0x87c37b91, 0x114253d5];\n        var c2 = [0x4cf5ad43, 0x2745937f];\n\n        for (var i = 0; i < blocks; i = i + 16) {\n            k1 = [(bytes[i + 4]) | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24), (bytes[i]) |\n                (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24)];\n            k2 = [(bytes[i + 12]) | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24), (bytes[i + 8]) |\n                (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24)];\n\n            k1 = _x64Multiply(k1, c1);\n            k1 = _x64Rotl(k1, 31);\n            k1 = _x64Multiply(k1, c2);\n            h1 = _x64Xor(h1, k1);\n\n            h1 = _x64Rotl(h1, 27);\n            h1 = _x64Add(h1, h2);\n            h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 0x52dce729]);\n\n            k2 = _x64Multiply(k2, c2);\n            k2 = _x64Rotl(k2, 33);\n            k2 = _x64Multiply(k2, c1);\n            h2 = _x64Xor(h2, k2);\n\n            h2 = _x64Rotl(h2, 31);\n            h2 = _x64Add(h2, h1);\n            h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 0x38495ab5]);\n        }\n\n        k1 = [0, 0];\n        k2 = [0, 0];\n\n        switch (remainder) {\n            case 15:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 14]], 48));\n\n            case 14:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 13]], 40));\n\n            case 13:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 12]], 32));\n\n            case 12:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 11]], 24));\n\n            case 11:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 10]], 16));\n\n            case 10:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 9]], 8));\n\n            case 9:\n                k2 = _x64Xor(k2, [0, bytes[i + 8]]);\n                k2 = _x64Multiply(k2, c2);\n                k2 = _x64Rotl(k2, 33);\n                k2 = _x64Multiply(k2, c1);\n                h2 = _x64Xor(h2, k2);\n\n            case 8:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 7]], 56));\n\n            case 7:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 6]], 48));\n\n            case 6:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 5]], 40));\n\n            case 5:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 4]], 32));\n\n            case 4:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 3]], 24));\n\n            case 3:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 2]], 16));\n\n            case 2:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 1]], 8));\n\n            case 1:\n                k1 = _x64Xor(k1, [0, bytes[i]]);\n                k1 = _x64Multiply(k1, c1);\n                k1 = _x64Rotl(k1, 31);\n                k1 = _x64Multiply(k1, c2);\n                h1 = _x64Xor(h1, k1);\n        }\n\n        h1 = _x64Xor(h1, [0, bytes.length]);\n        h2 = _x64Xor(h2, [0, bytes.length]);\n\n        h1 = _x64Add(h1, h2);\n        h2 = _x64Add(h2, h1);\n\n        h1 = _x64Fmix(h1);\n        h2 = _x64Fmix(h2);\n\n        h1 = _x64Add(h1, h2);\n        h2 = _x64Add(h2, h1);\n\n        return (\"00000000\" + (h1[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h1[1] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[1] >>> 0).toString(16)).slice(-8);\n    };\n\n    // INITIALIZATION\n    // --------------\n\n    // Export murmurHash3 for CommonJS, either as an AMD module or just as part\n    // of the global object.\n    if (typeof exports !== 'undefined') {\n\n        if (typeof module !== 'undefined' && module.exports) {\n            exports = module.exports = library;\n        }\n\n        exports.murmurHash3 = library;\n\n    } else if (typeof define === 'function' && define.amd) {\n\n        define([], function () {\n            return library;\n        });\n    } else {\n\n        // Use murmurHash3.noConflict to restore `murmurHash3` back to its\n        // original value. Returns a reference to the library object, to allow\n        // it to be used under a different name.\n        library._murmurHash3 = root.murmurHash3;\n\n        library.noConflict = function () {\n            root.murmurHash3 = library._murmurHash3;\n            library._murmurHash3 = undefined;\n            library.noConflict = undefined;\n\n            return library;\n        };\n\n        root.murmurHash3 = library;\n    }\n})(this);\n","/* eslint-disable require-await */\n'use strict'\n\nconst multihash = require('multihashes')\n/**\n * @typedef {import('multihashes').HashName} HashName\n * @typedef {import('./types').Digest} Digest\n */\n\n/**\n * @type {Crypto}\n */\nconst crypto =\n  self.crypto ||\n  /** @type {typeof window.crypto} */\n  // @ts-ignore - unknown property\n  (self.msCrypto)\n\n/**\n *\n * @param {Uint8Array} data\n * @param {HashName} alg\n * @returns {Promise<Uint8Array>}\n */\nconst digest = async (data, alg) => {\n  if (typeof self === 'undefined' || !crypto) {\n    throw new Error(\n      'Please use a browser with webcrypto support and ensure the code has been delivered securely via HTTPS/TLS and run within a Secure Context'\n    )\n  }\n  switch (alg) {\n    case 'sha1':\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-1' }, data))\n    case 'sha2-256':\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-256' }, data))\n    case 'sha2-512':\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-512' }, data))\n    case 'dbl-sha2-256': {\n      const d = await crypto.subtle.digest({ name: 'SHA-256' }, data)\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-256' }, d))\n    }\n    default:\n      throw new Error(`${alg} is not a supported algorithm`)\n  }\n}\n\nmodule.exports = {\n  /**\n   * @param {HashName} alg\n   * @returns {Digest}\n   */\n  factory: (alg) => async (data) => {\n    return digest(data, alg)\n  },\n  digest,\n  /**\n   * @param {Uint8Array} buf\n   * @param {HashName} alg\n   * @param {number} [length]\n   */\n  multihashing: async (buf, alg, length) => {\n    const h = await digest(buf, alg)\n    return multihash.encode(h, alg, length)\n  }\n}\n","'use strict'\n\n/**\n * @param {number} number\n * @returns {Uint8Array}\n */\nconst fromNumberTo32BitBuf = (number) => {\n  const bytes = new Uint8Array(4)\n\n  for (let i = 0; i < 4; i++) {\n    bytes[i] = number & 0xff\n    number = number >> 8\n  }\n\n  return bytes\n}\n\nmodule.exports = {\n  fromNumberTo32BitBuf\n}\n","'use strict'\n\nconst { encoding: getCodec } = require('multibase')\nconst { TextEncoder } = require('web-encoding')\nconst utf8Encoder = new TextEncoder()\n\n/**\n * @typedef {import('multibase/src/types').BaseName} BaseName\n */\n\n/**\n * Interprets each character in a string as a byte and\n * returns a Uint8Array of those bytes.\n *\n * @param {string} string - The string to turn into an array\n */\nfunction asciiStringToUint8Array (string) {\n  const array = new Uint8Array(string.length)\n\n  for (let i = 0; i < string.length; i++) {\n    array[i] = string.charCodeAt(i)\n  }\n\n  return array\n}\n\n/**\n * Create a `Uint8Array` from the passed string\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {string} string\n * @param {BaseName | 'utf8' | 'utf-8' | 'ascii'} [encoding=utf8] - utf8, base16, base64, base64urlpad, etc\n * @returns {Uint8Array}\n */\nfunction fromString (string, encoding = 'utf8') {\n  if (encoding === 'utf8' || encoding === 'utf-8') {\n    return utf8Encoder.encode(string)\n  }\n\n  if (encoding === 'ascii') {\n    return asciiStringToUint8Array(string)\n  }\n\n  return getCodec(encoding).decode(string)\n}\n\nmodule.exports = fromString\n","/**\n * Implementation of the [multibase](https://github.com/multiformats/multibase) specification.\n *\n */\n'use strict'\n\nconst constants = require('./constants')\nconst { encodeText, decodeText, concat } = require('./util')\n\n/** @typedef {import('./base')} Base */\n/** @typedef {import(\"./types\").BaseNameOrCode} BaseNameOrCode */\n/** @typedef {import(\"./types\").BaseCode} BaseCode */\n/** @typedef {import(\"./types\").BaseName} BaseName */\n\n/**\n * Create a new Uint8Array with the multibase varint+code.\n *\n * @param {BaseNameOrCode} nameOrCode - The multibase name or code number.\n * @param {Uint8Array} buf - The data to be prefixed with multibase.\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction multibase (nameOrCode, buf) {\n  if (!buf) {\n    throw new Error('requires an encoded Uint8Array')\n  }\n  const { name, codeBuf } = encoding(nameOrCode)\n  validEncode(name, buf)\n\n  return concat([codeBuf, buf], codeBuf.length + buf.length)\n}\n\n/**\n * Encode data with the specified base and add the multibase prefix.\n *\n * @param {BaseNameOrCode} nameOrCode - The multibase name or code number.\n * @param {Uint8Array} buf - The data to be encoded.\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n *\n */\nfunction encode (nameOrCode, buf) {\n  const enc = encoding(nameOrCode)\n  const data = encodeText(enc.encode(buf))\n\n  return concat([enc.codeBuf, data], enc.codeBuf.length + data.length)\n}\n\n/**\n * Takes a Uint8Array or string encoded with multibase header, decodes it and\n * returns the decoded buffer\n *\n * @param {Uint8Array|string} data\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n *\n */\nfunction decode (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n  const prefix = data[0]\n\n  // Make all encodings case-insensitive except the ones that include upper and lower chars in the alphabet\n  if (['f', 'F', 'v', 'V', 't', 'T', 'b', 'B', 'c', 'C', 'h', 'k', 'K'].includes(prefix)) {\n    data = data.toLowerCase()\n  }\n  const enc = encoding(/** @type {BaseCode} */(data[0]))\n  return enc.decode(data.substring(1))\n}\n\n/**\n * Is the given data multibase encoded?\n *\n * @param {Uint8Array|string} data\n * @returns {false | string}\n */\nfunction isEncoded (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n\n  // Ensure bufOrString is a string\n  if (Object.prototype.toString.call(data) !== '[object String]') {\n    return false\n  }\n\n  try {\n    const enc = encoding(/** @type {BaseCode} */(data[0]))\n    return enc.name\n  } catch (err) {\n    return false\n  }\n}\n\n/**\n * Validate encoded data\n *\n * @param {BaseNameOrCode} name\n * @param {Uint8Array} buf\n * @returns {void}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction validEncode (name, buf) {\n  const enc = encoding(name)\n  enc.decode(decodeText(buf))\n}\n\n/**\n * Get the encoding by name or code\n *\n * @param {BaseNameOrCode} nameOrCode\n * @returns {Base}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction encoding (nameOrCode) {\n  if (Object.prototype.hasOwnProperty.call(constants.names, /** @type {BaseName} */(nameOrCode))) {\n    return constants.names[/** @type {BaseName} */(nameOrCode)]\n  } else if (Object.prototype.hasOwnProperty.call(constants.codes, /** @type {BaseCode} */(nameOrCode))) {\n    return constants.codes[/** @type {BaseCode} */(nameOrCode)]\n  } else {\n    throw new Error(`Unsupported encoding: ${nameOrCode}`)\n  }\n}\n\n/**\n * Get encoding from data\n *\n * @param {string|Uint8Array} data\n * @returns {Base}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction encodingFromData (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n\n  return encoding(/** @type {BaseCode} */(data[0]))\n}\n\nexports = module.exports = multibase\nexports.encode = encode\nexports.decode = decode\nexports.isEncoded = isEncoded\nexports.encoding = encoding\nexports.encodingFromData = encodingFromData\nconst names = Object.freeze(constants.names)\nconst codes = Object.freeze(constants.codes)\nexports.names = names\nexports.codes = codes\n","'use strict'\n\nconst baseX = require('@multiformats/base-x')\nconst Base = require('./base.js')\nconst { rfc4648 } = require('./rfc4648')\nconst { decodeText, encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import('./types').Codec} Codec */\n/** @typedef {import('./types').BaseName} BaseName */\n/** @typedef {import('./types').BaseCode} BaseCode */\n\n/** @type {CodecFactory} */\nconst identity = () => {\n  return {\n    encode: decodeText,\n    decode: encodeText\n  }\n}\n\n/**\n *\n * name, code, implementation, alphabet\n *\n * @type {Array<[BaseName, BaseCode, CodecFactory, string]>}\n */\nconst constants = [\n  ['identity', '\\x00', identity, ''],\n  ['base2', '0', rfc4648(1), '01'],\n  ['base8', '7', rfc4648(3), '01234567'],\n  ['base10', '9', baseX, '0123456789'],\n  ['base16', 'f', rfc4648(4), '0123456789abcdef'],\n  ['base16upper', 'F', rfc4648(4), '0123456789ABCDEF'],\n  ['base32hex', 'v', rfc4648(5), '0123456789abcdefghijklmnopqrstuv'],\n  ['base32hexupper', 'V', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV'],\n  ['base32hexpad', 't', rfc4648(5), '0123456789abcdefghijklmnopqrstuv='],\n  ['base32hexpadupper', 'T', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV='],\n  ['base32', 'b', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567'],\n  ['base32upper', 'B', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'],\n  ['base32pad', 'c', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567='],\n  ['base32padupper', 'C', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567='],\n  ['base32z', 'h', rfc4648(5), 'ybndrfg8ejkmcpqxot1uwisza345h769'],\n  ['base36', 'k', baseX, '0123456789abcdefghijklmnopqrstuvwxyz'],\n  ['base36upper', 'K', baseX, '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'],\n  ['base58btc', 'z', baseX, '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'],\n  ['base58flickr', 'Z', baseX, '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'],\n  ['base64', 'm', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'],\n  ['base64pad', 'M', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/='],\n  ['base64url', 'u', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_'],\n  ['base64urlpad', 'U', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=']\n]\n\n/** @type {Record<BaseName,Base>} */\nconst names = constants.reduce((prev, tupple) => {\n  prev[tupple[0]] = new Base(tupple[0], tupple[1], tupple[2], tupple[3])\n  return prev\n}, /** @type {Record<BaseName,Base>} */({}))\n\n/** @type {Record<BaseCode,Base>} */\nconst codes = constants.reduce((prev, tupple) => {\n  prev[tupple[1]] = names[tupple[0]]\n  return prev\n}, /** @type {Record<BaseCode,Base>} */({}))\n\nmodule.exports = {\n  names,\n  codes\n}\n","'use strict'\n\nconst { encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import(\"./types\").BaseName} BaseName */\n/** @typedef {import(\"./types\").BaseCode} BaseCode */\n\n/**\n * Class to encode/decode in the supported Bases\n *\n */\nclass Base {\n  /**\n   * @param {BaseName} name\n   * @param {BaseCode} code\n   * @param {CodecFactory} factory\n   * @param {string} alphabet\n   */\n  constructor (name, code, factory, alphabet) {\n    this.name = name\n    this.code = code\n    this.codeBuf = encodeText(this.code)\n    this.alphabet = alphabet\n    this.codec = factory(alphabet)\n  }\n\n  /**\n   * @param {Uint8Array} buf\n   * @returns {string}\n   */\n  encode (buf) {\n    return this.codec.encode(buf)\n  }\n\n  /**\n   * @param {string} string\n   * @returns {Uint8Array}\n   */\n  decode (string) {\n    for (const char of string) {\n      if (this.alphabet && this.alphabet.indexOf(char) < 0) {\n        throw new Error(`invalid character '${char}' in '${string}'`)\n      }\n    }\n    return this.codec.decode(string)\n  }\n}\n\nmodule.exports = Base\n","'use strict'\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n\n/**\n * @param {string} string\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {Uint8Array}\n */\nconst decode = (string, alphabet, bitsPerChar) => {\n  // Build the character lookup table:\n  /** @type {Record<string, number>} */\n  const codes = {}\n  for (let i = 0; i < alphabet.length; ++i) {\n    codes[alphabet[i]] = i\n  }\n\n  // Count the padding bytes:\n  let end = string.length\n  while (string[end - 1] === '=') {\n    --end\n  }\n\n  // Allocate the output:\n  const out = new Uint8Array((end * bitsPerChar / 8) | 0)\n\n  // Parse the data:\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  let written = 0 // Next byte to write\n  for (let i = 0; i < end; ++i) {\n    // Read one character from the string:\n    const value = codes[string[i]]\n    if (value === undefined) {\n      throw new SyntaxError('Invalid character ' + string[i])\n    }\n\n    // Append the bits to the buffer:\n    buffer = (buffer << bitsPerChar) | value\n    bits += bitsPerChar\n\n    // Write out some bits if the buffer has a byte's worth:\n    if (bits >= 8) {\n      bits -= 8\n      out[written++] = 0xff & (buffer >> bits)\n    }\n  }\n\n  // Verify that we have received just enough bits:\n  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {\n    throw new SyntaxError('Unexpected end of data')\n  }\n\n  return out\n}\n\n/**\n * @param {Uint8Array} data\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {string}\n */\nconst encode = (data, alphabet, bitsPerChar) => {\n  const pad = alphabet[alphabet.length - 1] === '='\n  const mask = (1 << bitsPerChar) - 1\n  let out = ''\n\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  for (let i = 0; i < data.length; ++i) {\n    // Slurp data into the buffer:\n    buffer = (buffer << 8) | data[i]\n    bits += 8\n\n    // Write out as much as we can:\n    while (bits > bitsPerChar) {\n      bits -= bitsPerChar\n      out += alphabet[mask & (buffer >> bits)]\n    }\n  }\n\n  // Partial character:\n  if (bits) {\n    out += alphabet[mask & (buffer << (bitsPerChar - bits))]\n  }\n\n  // Add padding characters until we hit a byte boundary:\n  if (pad) {\n    while ((out.length * bitsPerChar) & 7) {\n      out += '='\n    }\n  }\n\n  return out\n}\n\n/**\n * RFC4648 Factory\n *\n * @param {number} bitsPerChar\n * @returns {CodecFactory}\n */\nconst rfc4648 = (bitsPerChar) => (alphabet) => {\n  return {\n    /**\n     * @param {Uint8Array} input\n     * @returns {string}\n     */\n    encode (input) {\n      return encode(input, alphabet, bitsPerChar)\n    },\n    /**\n     * @param {string} input\n     * @returns {Uint8Array}\n     */\n    decode (input) {\n      return decode(input, alphabet, bitsPerChar)\n    }\n  }\n}\n\nmodule.exports = { rfc4648 }\n","'use strict'\n\n// @ts-ignore - no types available\nconst blake = require('blakejs')\n\nconst minB = 0xb201\nconst minS = 0xb241\n\nconst blake2b = {\n  init: blake.blake2bInit,\n  update: blake.blake2bUpdate,\n  digest: blake.blake2bFinal\n}\n\nconst blake2s = {\n  init: blake.blake2sInit,\n  update: blake.blake2sUpdate,\n  digest: blake.blake2sFinal\n}\n\n// Note that although this function doesn't do any asynchronous work, we mark\n// the function as async because it must return a Promise to match the API\n// for other functions that do perform asynchronous work (see sha.browser.js)\n// eslint-disable-next-line\n\n/**\n * @param {number} size\n * @param {any} hf\n * @returns {import('./types').Digest}\n */\nconst makeB2Hash = (size, hf) => async (data) => {\n  const ctx = hf.init(size, null)\n  hf.update(ctx, data)\n  return hf.digest(ctx)\n}\n\n/**\n * @param {Record<number, import('./types').Digest>} table\n */\nmodule.exports = (table) => {\n  for (let i = 0; i < 64; i++) {\n    table[minB + i] = makeB2Hash(i + 1, blake2b)\n  }\n  for (let i = 0; i < 32; i++) {\n    table[minS + i] = makeB2Hash(i + 1, blake2s)\n  }\n}\n","// Blake2B in pure Javascript\n// Adapted from the reference implementation in RFC7693\n// Ported to Javascript by DC - https://github.com/dcposch\n\nvar util = require('./util')\n\n// 64-bit unsigned addition\n// Sets v[a,a+1] += v[b,b+1]\n// v should be a Uint32Array\nfunction ADD64AA (v, a, b) {\n  var o0 = v[a] + v[b]\n  var o1 = v[a + 1] + v[b + 1]\n  if (o0 >= 0x100000000) {\n    o1++\n  }\n  v[a] = o0\n  v[a + 1] = o1\n}\n\n// 64-bit unsigned addition\n// Sets v[a,a+1] += b\n// b0 is the low 32 bits of b, b1 represents the high 32 bits\nfunction ADD64AC (v, a, b0, b1) {\n  var o0 = v[a] + b0\n  if (b0 < 0) {\n    o0 += 0x100000000\n  }\n  var o1 = v[a + 1] + b1\n  if (o0 >= 0x100000000) {\n    o1++\n  }\n  v[a] = o0\n  v[a + 1] = o1\n}\n\n// Little-endian byte access\nfunction B2B_GET32 (arr, i) {\n  return (arr[i] ^\n  (arr[i + 1] << 8) ^\n  (arr[i + 2] << 16) ^\n  (arr[i + 3] << 24))\n}\n\n// G Mixing function\n// The ROTRs are inlined for speed\nfunction B2B_G (a, b, c, d, ix, iy) {\n  var x0 = m[ix]\n  var x1 = m[ix + 1]\n  var y0 = m[iy]\n  var y1 = m[iy + 1]\n\n  ADD64AA(v, a, b) // v[a,a+1] += v[b,b+1] ... in JS we must store a uint64 as two uint32s\n  ADD64AC(v, a, x0, x1) // v[a, a+1] += x ... x0 is the low 32 bits of x, x1 is the high 32 bits\n\n  // v[d,d+1] = (v[d,d+1] xor v[a,a+1]) rotated to the right by 32 bits\n  var xor0 = v[d] ^ v[a]\n  var xor1 = v[d + 1] ^ v[a + 1]\n  v[d] = xor1\n  v[d + 1] = xor0\n\n  ADD64AA(v, c, d)\n\n  // v[b,b+1] = (v[b,b+1] xor v[c,c+1]) rotated right by 24 bits\n  xor0 = v[b] ^ v[c]\n  xor1 = v[b + 1] ^ v[c + 1]\n  v[b] = (xor0 >>> 24) ^ (xor1 << 8)\n  v[b + 1] = (xor1 >>> 24) ^ (xor0 << 8)\n\n  ADD64AA(v, a, b)\n  ADD64AC(v, a, y0, y1)\n\n  // v[d,d+1] = (v[d,d+1] xor v[a,a+1]) rotated right by 16 bits\n  xor0 = v[d] ^ v[a]\n  xor1 = v[d + 1] ^ v[a + 1]\n  v[d] = (xor0 >>> 16) ^ (xor1 << 16)\n  v[d + 1] = (xor1 >>> 16) ^ (xor0 << 16)\n\n  ADD64AA(v, c, d)\n\n  // v[b,b+1] = (v[b,b+1] xor v[c,c+1]) rotated right by 63 bits\n  xor0 = v[b] ^ v[c]\n  xor1 = v[b + 1] ^ v[c + 1]\n  v[b] = (xor1 >>> 31) ^ (xor0 << 1)\n  v[b + 1] = (xor0 >>> 31) ^ (xor1 << 1)\n}\n\n// Initialization Vector\nvar BLAKE2B_IV32 = new Uint32Array([\n  0xF3BCC908, 0x6A09E667, 0x84CAA73B, 0xBB67AE85,\n  0xFE94F82B, 0x3C6EF372, 0x5F1D36F1, 0xA54FF53A,\n  0xADE682D1, 0x510E527F, 0x2B3E6C1F, 0x9B05688C,\n  0xFB41BD6B, 0x1F83D9AB, 0x137E2179, 0x5BE0CD19\n])\n\nvar SIGMA8 = [\n  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n  14, 10, 4, 8, 9, 15, 13, 6, 1, 12, 0, 2, 11, 7, 5, 3,\n  11, 8, 12, 0, 5, 2, 15, 13, 10, 14, 3, 6, 7, 1, 9, 4,\n  7, 9, 3, 1, 13, 12, 11, 14, 2, 6, 5, 10, 4, 0, 15, 8,\n  9, 0, 5, 7, 2, 4, 10, 15, 14, 1, 11, 12, 6, 8, 3, 13,\n  2, 12, 6, 10, 0, 11, 8, 3, 4, 13, 7, 5, 15, 14, 1, 9,\n  12, 5, 1, 15, 14, 13, 4, 10, 0, 7, 6, 3, 9, 2, 8, 11,\n  13, 11, 7, 14, 12, 1, 3, 9, 5, 0, 15, 4, 8, 6, 2, 10,\n  6, 15, 14, 9, 11, 3, 0, 8, 12, 2, 13, 7, 1, 4, 10, 5,\n  10, 2, 8, 4, 7, 6, 1, 5, 15, 11, 9, 14, 3, 12, 13, 0,\n  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n  14, 10, 4, 8, 9, 15, 13, 6, 1, 12, 0, 2, 11, 7, 5, 3\n]\n\n// These are offsets into a uint64 buffer.\n// Multiply them all by 2 to make them offsets into a uint32 buffer,\n// because this is Javascript and we don't have uint64s\nvar SIGMA82 = new Uint8Array(SIGMA8.map(function (x) { return x * 2 }))\n\n// Compression function. 'last' flag indicates last block.\n// Note we're representing 16 uint64s as 32 uint32s\nvar v = new Uint32Array(32)\nvar m = new Uint32Array(32)\nfunction blake2bCompress (ctx, last) {\n  var i = 0\n\n  // init work variables\n  for (i = 0; i < 16; i++) {\n    v[i] = ctx.h[i]\n    v[i + 16] = BLAKE2B_IV32[i]\n  }\n\n  // low 64 bits of offset\n  v[24] = v[24] ^ ctx.t\n  v[25] = v[25] ^ (ctx.t / 0x100000000)\n  // high 64 bits not supported, offset may not be higher than 2**53-1\n\n  // last block flag set ?\n  if (last) {\n    v[28] = ~v[28]\n    v[29] = ~v[29]\n  }\n\n  // get little-endian words\n  for (i = 0; i < 32; i++) {\n    m[i] = B2B_GET32(ctx.b, 4 * i)\n  }\n\n  // twelve rounds of mixing\n  // uncomment the DebugPrint calls to log the computation\n  // and match the RFC sample documentation\n  // util.debugPrint('          m[16]', m, 64)\n  for (i = 0; i < 12; i++) {\n    // util.debugPrint('   (i=' + (i < 10 ? ' ' : '') + i + ') v[16]', v, 64)\n    B2B_G(0, 8, 16, 24, SIGMA82[i * 16 + 0], SIGMA82[i * 16 + 1])\n    B2B_G(2, 10, 18, 26, SIGMA82[i * 16 + 2], SIGMA82[i * 16 + 3])\n    B2B_G(4, 12, 20, 28, SIGMA82[i * 16 + 4], SIGMA82[i * 16 + 5])\n    B2B_G(6, 14, 22, 30, SIGMA82[i * 16 + 6], SIGMA82[i * 16 + 7])\n    B2B_G(0, 10, 20, 30, SIGMA82[i * 16 + 8], SIGMA82[i * 16 + 9])\n    B2B_G(2, 12, 22, 24, SIGMA82[i * 16 + 10], SIGMA82[i * 16 + 11])\n    B2B_G(4, 14, 16, 26, SIGMA82[i * 16 + 12], SIGMA82[i * 16 + 13])\n    B2B_G(6, 8, 18, 28, SIGMA82[i * 16 + 14], SIGMA82[i * 16 + 15])\n  }\n  // util.debugPrint('   (i=12) v[16]', v, 64)\n\n  for (i = 0; i < 16; i++) {\n    ctx.h[i] = ctx.h[i] ^ v[i] ^ v[i + 16]\n  }\n  // util.debugPrint('h[8]', ctx.h, 64)\n}\n\n// Creates a BLAKE2b hashing context\n// Requires an output length between 1 and 64 bytes\n// Takes an optional Uint8Array key\nfunction blake2bInit (outlen, key) {\n  if (outlen === 0 || outlen > 64) {\n    throw new Error('Illegal output length, expected 0 < length <= 64')\n  }\n  if (key && key.length > 64) {\n    throw new Error('Illegal key, expected Uint8Array with 0 < length <= 64')\n  }\n\n  // state, 'param block'\n  var ctx = {\n    b: new Uint8Array(128),\n    h: new Uint32Array(16),\n    t: 0, // input count\n    c: 0, // pointer within buffer\n    outlen: outlen // output length in bytes\n  }\n\n  // initialize hash state\n  for (var i = 0; i < 16; i++) {\n    ctx.h[i] = BLAKE2B_IV32[i]\n  }\n  var keylen = key ? key.length : 0\n  ctx.h[0] ^= 0x01010000 ^ (keylen << 8) ^ outlen\n\n  // key the hash, if applicable\n  if (key) {\n    blake2bUpdate(ctx, key)\n    // at the end\n    ctx.c = 128\n  }\n\n  return ctx\n}\n\n// Updates a BLAKE2b streaming hash\n// Requires hash context and Uint8Array (byte array)\nfunction blake2bUpdate (ctx, input) {\n  for (var i = 0; i < input.length; i++) {\n    if (ctx.c === 128) { // buffer full ?\n      ctx.t += ctx.c // add counters\n      blake2bCompress(ctx, false) // compress (not last)\n      ctx.c = 0 // counter to zero\n    }\n    ctx.b[ctx.c++] = input[i]\n  }\n}\n\n// Completes a BLAKE2b streaming hash\n// Returns a Uint8Array containing the message digest\nfunction blake2bFinal (ctx) {\n  ctx.t += ctx.c // mark last block offset\n\n  while (ctx.c < 128) { // fill up with zeros\n    ctx.b[ctx.c++] = 0\n  }\n  blake2bCompress(ctx, true) // final block flag = 1\n\n  // little endian convert and store\n  var out = new Uint8Array(ctx.outlen)\n  for (var i = 0; i < ctx.outlen; i++) {\n    out[i] = ctx.h[i >> 2] >> (8 * (i & 3))\n  }\n  return out\n}\n\n// Computes the BLAKE2B hash of a string or byte array, and returns a Uint8Array\n//\n// Returns a n-byte Uint8Array\n//\n// Parameters:\n// - input - the input bytes, as a string, Buffer or Uint8Array\n// - key - optional key Uint8Array, up to 64 bytes\n// - outlen - optional output length in bytes, default 64\nfunction blake2b (input, key, outlen) {\n  // preprocess inputs\n  outlen = outlen || 64\n  input = util.normalizeInput(input)\n\n  // do the math\n  var ctx = blake2bInit(outlen, key)\n  blake2bUpdate(ctx, input)\n  return blake2bFinal(ctx)\n}\n\n// Computes the BLAKE2B hash of a string or byte array\n//\n// Returns an n-byte hash in hex, all lowercase\n//\n// Parameters:\n// - input - the input bytes, as a string, Buffer, or Uint8Array\n// - key - optional key Uint8Array, up to 64 bytes\n// - outlen - optional output length in bytes, default 64\nfunction blake2bHex (input, key, outlen) {\n  var output = blake2b(input, key, outlen)\n  return util.toHex(output)\n}\n\nmodule.exports = {\n  blake2b: blake2b,\n  blake2bHex: blake2bHex,\n  blake2bInit: blake2bInit,\n  blake2bUpdate: blake2bUpdate,\n  blake2bFinal: blake2bFinal\n}\n","'use strict'\n\nexports.byteLength = byteLength\nexports.toByteArray = toByteArray\nexports.fromByteArray = fromByteArray\n\nvar lookup = []\nvar revLookup = []\nvar Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array\n\nvar code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\nfor (var i = 0, len = code.length; i < len; ++i) {\n  lookup[i] = code[i]\n  revLookup[code.charCodeAt(i)] = i\n}\n\n// Support decoding URL-safe base64 strings, as Node.js does.\n// See: https://en.wikipedia.org/wiki/Base64#URL_applications\nrevLookup['-'.charCodeAt(0)] = 62\nrevLookup['_'.charCodeAt(0)] = 63\n\nfunction getLens (b64) {\n  var len = b64.length\n\n  if (len % 4 > 0) {\n    throw new Error('Invalid string. Length must be a multiple of 4')\n  }\n\n  // Trim off extra bytes after placeholder bytes are found\n  // See: https://github.com/beatgammit/base64-js/issues/42\n  var validLen = b64.indexOf('=')\n  if (validLen === -1) validLen = len\n\n  var placeHoldersLen = validLen === len\n    ? 0\n    : 4 - (validLen % 4)\n\n  return [validLen, placeHoldersLen]\n}\n\n// base64 is 4/3 + up to two characters of the original data\nfunction byteLength (b64) {\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction _byteLength (b64, validLen, placeHoldersLen) {\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction toByteArray (b64) {\n  var tmp\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n\n  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))\n\n  var curByte = 0\n\n  // if there are placeholders, only get up to the last complete 4 chars\n  var len = placeHoldersLen > 0\n    ? validLen - 4\n    : validLen\n\n  var i\n  for (i = 0; i < len; i += 4) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 18) |\n      (revLookup[b64.charCodeAt(i + 1)] << 12) |\n      (revLookup[b64.charCodeAt(i + 2)] << 6) |\n      revLookup[b64.charCodeAt(i + 3)]\n    arr[curByte++] = (tmp >> 16) & 0xFF\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 2) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 2) |\n      (revLookup[b64.charCodeAt(i + 1)] >> 4)\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 1) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 10) |\n      (revLookup[b64.charCodeAt(i + 1)] << 4) |\n      (revLookup[b64.charCodeAt(i + 2)] >> 2)\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  return arr\n}\n\nfunction tripletToBase64 (num) {\n  return lookup[num >> 18 & 0x3F] +\n    lookup[num >> 12 & 0x3F] +\n    lookup[num >> 6 & 0x3F] +\n    lookup[num & 0x3F]\n}\n\nfunction encodeChunk (uint8, start, end) {\n  var tmp\n  var output = []\n  for (var i = start; i < end; i += 3) {\n    tmp =\n      ((uint8[i] << 16) & 0xFF0000) +\n      ((uint8[i + 1] << 8) & 0xFF00) +\n      (uint8[i + 2] & 0xFF)\n    output.push(tripletToBase64(tmp))\n  }\n  return output.join('')\n}\n\nfunction fromByteArray (uint8) {\n  var tmp\n  var len = uint8.length\n  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes\n  var parts = []\n  var maxChunkLength = 16383 // must be multiple of 3\n\n  // go through the array every three bytes, we'll deal with trailing stuff later\n  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {\n    parts.push(encodeChunk(\n      uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)\n    ))\n  }\n\n  // pad the end with zeros, but make sure to not forget the extra bytes\n  if (extraBytes === 1) {\n    tmp = uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 2] +\n      lookup[(tmp << 4) & 0x3F] +\n      '=='\n    )\n  } else if (extraBytes === 2) {\n    tmp = (uint8[len - 2] << 8) + uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 10] +\n      lookup[(tmp >> 4) & 0x3F] +\n      lookup[(tmp << 2) & 0x3F] +\n      '='\n    )\n  }\n\n  return parts.join('')\n}\n","// BLAKE2s hash function in pure Javascript\n// Adapted from the reference implementation in RFC7693\n// Ported to Javascript by DC - https://github.com/dcposch\n\nvar util = require('./util')\n\n// Little-endian byte access.\n// Expects a Uint8Array and an index\n// Returns the little-endian uint32 at v[i..i+3]\nfunction B2S_GET32 (v, i) {\n  return v[i] ^ (v[i + 1] << 8) ^ (v[i + 2] << 16) ^ (v[i + 3] << 24)\n}\n\n// Mixing function G.\nfunction B2S_G (a, b, c, d, x, y) {\n  v[a] = v[a] + v[b] + x\n  v[d] = ROTR32(v[d] ^ v[a], 16)\n  v[c] = v[c] + v[d]\n  v[b] = ROTR32(v[b] ^ v[c], 12)\n  v[a] = v[a] + v[b] + y\n  v[d] = ROTR32(v[d] ^ v[a], 8)\n  v[c] = v[c] + v[d]\n  v[b] = ROTR32(v[b] ^ v[c], 7)\n}\n\n// 32-bit right rotation\n// x should be a uint32\n// y must be between 1 and 31, inclusive\nfunction ROTR32 (x, y) {\n  return (x >>> y) ^ (x << (32 - y))\n}\n\n// Initialization Vector.\nvar BLAKE2S_IV = new Uint32Array([\n  0x6A09E667, 0xBB67AE85, 0x3C6EF372, 0xA54FF53A,\n  0x510E527F, 0x9B05688C, 0x1F83D9AB, 0x5BE0CD19])\n\nvar SIGMA = new Uint8Array([\n  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n  14, 10, 4, 8, 9, 15, 13, 6, 1, 12, 0, 2, 11, 7, 5, 3,\n  11, 8, 12, 0, 5, 2, 15, 13, 10, 14, 3, 6, 7, 1, 9, 4,\n  7, 9, 3, 1, 13, 12, 11, 14, 2, 6, 5, 10, 4, 0, 15, 8,\n  9, 0, 5, 7, 2, 4, 10, 15, 14, 1, 11, 12, 6, 8, 3, 13,\n  2, 12, 6, 10, 0, 11, 8, 3, 4, 13, 7, 5, 15, 14, 1, 9,\n  12, 5, 1, 15, 14, 13, 4, 10, 0, 7, 6, 3, 9, 2, 8, 11,\n  13, 11, 7, 14, 12, 1, 3, 9, 5, 0, 15, 4, 8, 6, 2, 10,\n  6, 15, 14, 9, 11, 3, 0, 8, 12, 2, 13, 7, 1, 4, 10, 5,\n  10, 2, 8, 4, 7, 6, 1, 5, 15, 11, 9, 14, 3, 12, 13, 0])\n\n// Compression function. \"last\" flag indicates last block\nvar v = new Uint32Array(16)\nvar m = new Uint32Array(16)\nfunction blake2sCompress (ctx, last) {\n  var i = 0\n  for (i = 0; i < 8; i++) { // init work variables\n    v[i] = ctx.h[i]\n    v[i + 8] = BLAKE2S_IV[i]\n  }\n\n  v[12] ^= ctx.t // low 32 bits of offset\n  v[13] ^= (ctx.t / 0x100000000) // high 32 bits\n  if (last) { // last block flag set ?\n    v[14] = ~v[14]\n  }\n\n  for (i = 0; i < 16; i++) { // get little-endian words\n    m[i] = B2S_GET32(ctx.b, 4 * i)\n  }\n\n  // ten rounds of mixing\n  // uncomment the DebugPrint calls to log the computation\n  // and match the RFC sample documentation\n  // util.debugPrint('          m[16]', m, 32)\n  for (i = 0; i < 10; i++) {\n    // util.debugPrint('   (i=' + i + ')  v[16]', v, 32)\n    B2S_G(0, 4, 8, 12, m[SIGMA[i * 16 + 0]], m[SIGMA[i * 16 + 1]])\n    B2S_G(1, 5, 9, 13, m[SIGMA[i * 16 + 2]], m[SIGMA[i * 16 + 3]])\n    B2S_G(2, 6, 10, 14, m[SIGMA[i * 16 + 4]], m[SIGMA[i * 16 + 5]])\n    B2S_G(3, 7, 11, 15, m[SIGMA[i * 16 + 6]], m[SIGMA[i * 16 + 7]])\n    B2S_G(0, 5, 10, 15, m[SIGMA[i * 16 + 8]], m[SIGMA[i * 16 + 9]])\n    B2S_G(1, 6, 11, 12, m[SIGMA[i * 16 + 10]], m[SIGMA[i * 16 + 11]])\n    B2S_G(2, 7, 8, 13, m[SIGMA[i * 16 + 12]], m[SIGMA[i * 16 + 13]])\n    B2S_G(3, 4, 9, 14, m[SIGMA[i * 16 + 14]], m[SIGMA[i * 16 + 15]])\n  }\n  // util.debugPrint('   (i=10) v[16]', v, 32)\n\n  for (i = 0; i < 8; i++) {\n    ctx.h[i] ^= v[i] ^ v[i + 8]\n  }\n  // util.debugPrint('h[8]', ctx.h, 32)\n}\n\n// Creates a BLAKE2s hashing context\n// Requires an output length between 1 and 32 bytes\n// Takes an optional Uint8Array key\nfunction blake2sInit (outlen, key) {\n  if (!(outlen > 0 && outlen <= 32)) {\n    throw new Error('Incorrect output length, should be in [1, 32]')\n  }\n  var keylen = key ? key.length : 0\n  if (key && !(keylen > 0 && keylen <= 32)) {\n    throw new Error('Incorrect key length, should be in [1, 32]')\n  }\n\n  var ctx = {\n    h: new Uint32Array(BLAKE2S_IV), // hash state\n    b: new Uint32Array(64), // input block\n    c: 0, // pointer within block\n    t: 0, // input count\n    outlen: outlen // output length in bytes\n  }\n  ctx.h[0] ^= 0x01010000 ^ (keylen << 8) ^ outlen\n\n  if (keylen > 0) {\n    blake2sUpdate(ctx, key)\n    ctx.c = 64 // at the end\n  }\n\n  return ctx\n}\n\n// Updates a BLAKE2s streaming hash\n// Requires hash context and Uint8Array (byte array)\nfunction blake2sUpdate (ctx, input) {\n  for (var i = 0; i < input.length; i++) {\n    if (ctx.c === 64) { // buffer full ?\n      ctx.t += ctx.c // add counters\n      blake2sCompress(ctx, false) // compress (not last)\n      ctx.c = 0 // counter to zero\n    }\n    ctx.b[ctx.c++] = input[i]\n  }\n}\n\n// Completes a BLAKE2s streaming hash\n// Returns a Uint8Array containing the message digest\nfunction blake2sFinal (ctx) {\n  ctx.t += ctx.c // mark last block offset\n  while (ctx.c < 64) { // fill up with zeros\n    ctx.b[ctx.c++] = 0\n  }\n  blake2sCompress(ctx, true) // final block flag = 1\n\n  // little endian convert and store\n  var out = new Uint8Array(ctx.outlen)\n  for (var i = 0; i < ctx.outlen; i++) {\n    out[i] = (ctx.h[i >> 2] >> (8 * (i & 3))) & 0xFF\n  }\n  return out\n}\n\n// Computes the BLAKE2S hash of a string or byte array, and returns a Uint8Array\n//\n// Returns a n-byte Uint8Array\n//\n// Parameters:\n// - input - the input bytes, as a string, Buffer, or Uint8Array\n// - key - optional key Uint8Array, up to 32 bytes\n// - outlen - optional output length in bytes, default 64\nfunction blake2s (input, key, outlen) {\n  // preprocess inputs\n  outlen = outlen || 32\n  input = util.normalizeInput(input)\n\n  // do the math\n  var ctx = blake2sInit(outlen, key)\n  blake2sUpdate(ctx, input)\n  return blake2sFinal(ctx)\n}\n\n// Computes the BLAKE2S hash of a string or byte array\n//\n// Returns an n-byte hash in hex, all lowercase\n//\n// Parameters:\n// - input - the input bytes, as a string, Buffer, or Uint8Array\n// - key - optional key Uint8Array, up to 32 bytes\n// - outlen - optional output length in bytes, default 64\nfunction blake2sHex (input, key, outlen) {\n  var output = blake2s(input, key, outlen)\n  return util.toHex(output)\n}\n\nmodule.exports = {\n  blake2s: blake2s,\n  blake2sHex: blake2sHex,\n  blake2sInit: blake2sInit,\n  blake2sUpdate: blake2sUpdate,\n  blake2sFinal: blake2sFinal\n}\n","'use strict'\n\n/**\n * Returns true if the two passed Uint8Arrays have the same content\n *\n * @param {Uint8Array} a\n * @param {Uint8Array} b\n */\nfunction equals (a, b) {\n  if (a === b) {\n    return true\n  }\n\n  if (a.byteLength !== b.byteLength) {\n    return false\n  }\n\n  for (let i = 0; i < a.byteLength; i++) {\n    if (a[i] !== b[i]) {\n      return false\n    }\n  }\n\n  return true\n}\n\nmodule.exports = equals\n","'use strict'\n\nconst sortLinks = require('./sortLinks')\nconst DAGLink = require('../dag-link')\n\nconst asDAGLink = (link) => {\n  if (DAGLink.isDAGLink(link)) {\n    // It's a DAGLink instance\n    // no need to do anything\n    return link\n  }\n\n  // DAGNode.isDagNode() would be more appropriate here, but it can't be used\n  // as it would lead to circular dependencies as `addLink` is called from\n  // within the DAGNode object.\n  if (!('cid' in link ||\n        'hash' in link ||\n        'Hash' in link ||\n        'multihash' in link)) {\n    throw new Error('Link must be a DAGLink or DAGLink-like. Convert the DAGNode into a DAGLink via `node.toDAGLink()`.')\n  }\n\n  // It's a Object with name, multihash/hash/cid and size\n  return new DAGLink(link.Name || link.name, link.Tsize || link.size, link.Hash || link.multihash || link.hash || link.cid)\n}\n\nconst addLink = (node, link) => {\n  const dagLink = asDAGLink(link)\n  node.Links.push(dagLink)\n  sortLinks(node.Links)\n}\n\nmodule.exports = addLink\n","'use strict'\n\nconst DAGLink = require('./dagLink')\n\nfunction createDagLinkFromB58EncodedHash (link) {\n  return new DAGLink(\n    link.Name || link.name || '',\n    link.Tsize || link.Size || link.size || 0,\n    link.Hash || link.hash || link.multihash || link.cid\n  )\n}\n\nexports = module.exports\nexports.createDagLinkFromB58EncodedHash = createDagLinkFromB58EncodedHash\n","'use strict'\n\nconst CID = require('cids')\nconst uint8ArrayEquals = require('uint8arrays/equals')\n\nconst rmLink = (dagNode, nameOrCid) => {\n  let predicate = null\n\n  // It's a name\n  if (typeof nameOrCid === 'string') {\n    predicate = (link) => link.Name === nameOrCid\n  } else if (nameOrCid instanceof Uint8Array || CID.isCID(nameOrCid)) {\n    predicate = (link) => uint8ArrayEquals(link.Hash, nameOrCid)\n  }\n\n  if (predicate) {\n    const links = dagNode.Links\n    let index = 0\n    while (index < links.length) {\n      const link = links[index]\n      if (predicate(link)) {\n        links.splice(index, 1)\n      } else {\n        index++\n      }\n    }\n  } else {\n    throw new Error('second arg needs to be a name or CID')\n  }\n}\n\nmodule.exports = rmLink\n","'use strict'\n\n/**\n * Returns true if the two passed Uint8Arrays have the same content\n *\n * @param {Uint8Array} a\n * @param {Uint8Array} b\n * @returns {boolean}\n */\nfunction equals (a, b) {\n  if (a === b) {\n    return true\n  }\n\n  if (a.byteLength !== b.byteLength) {\n    return false\n  }\n\n  for (let i = 0; i < a.byteLength; i++) {\n    if (a[i] !== b[i]) {\n      return false\n    }\n  }\n\n  return true\n}\n\nmodule.exports = equals\n","'use strict'\n\nconst CID = require('cids')\n\nconst util = require('./util')\n\n/**\n * Resolves a path within a PB block.\n *\n * Returns the value or a link and the partial mising path. This way the\n * IPLD Resolver can fetch the link and continue to resolve.\n *\n * @param {Uint8Array} binaryBlob - Binary representation of a PB block\n * @param {string} [path='/'] - Path that should be resolved\n * @returns {Object} result - Result of the path it it was resolved successfully\n * @returns {*} result.value - Value the path resolves to\n * @returns {string} result.remainderPath - If the path resolves half-way to a\n *   link, then the `remainderPath` is the part after the link that can be used\n *   for further resolving\n */\nexports.resolve = (binaryBlob, path) => {\n  let node = util.deserialize(binaryBlob)\n\n  const parts = path.split('/').filter(Boolean)\n  while (parts.length) {\n    const key = parts.shift()\n    if (node[key] === undefined) {\n      // There might be a matching named link\n      for (const link of node.Links) {\n        if (link.Name === key) {\n          return {\n            value: link.Hash,\n            remainderPath: parts.join('/')\n          }\n        }\n      }\n\n      // There wasn't even a matching named link\n      throw new Error(`Object has no property '${key}'`)\n    }\n\n    node = node[key]\n    if (CID.isCID(node)) {\n      return {\n        value: node,\n        remainderPath: parts.join('/')\n      }\n    }\n  }\n\n  return {\n    value: node,\n    remainderPath: ''\n  }\n}\n\n/**\n * Return all available paths of a block.\n *\n * @generator\n * @param {Uint8Array} binaryBlob - Binary representation of a PB block\n * @yields {string} - A single path\n */\nexports.tree = function * (binaryBlob) {\n  const node = util.deserialize(binaryBlob)\n\n  // There is always a `Data` and `Links` property\n  yield 'Data'\n  yield 'Links'\n  for (let ii = 0; ii < node.Links.length; ii++) {\n    yield `Links/${ii}`\n    yield `Links/${ii}/Name`\n    yield `Links/${ii}/Tsize`\n    yield `Links/${ii}/Hash`\n  }\n}\n","'use strict'\n\nexports.util = require('./util.js')\nexports.resolver = require('./resolver.js')\nexports.codec = exports.util.codec\nexports.defaultHashAlg = exports.util.defaultHashAlg\n","'use strict'\n\nconst { Buffer } = require('buffer')\nconst Decoder = require('./decoder')\nconst utils = require('./utils')\n\n/**\n * Output the diagnostic format from a stream of CBOR bytes.\n *\n */\nclass Diagnose extends Decoder {\n  createTag (tagNumber, value) {\n    return `${tagNumber}(${value})`\n  }\n\n  createInt (val) {\n    return super.createInt(val).toString()\n  }\n\n  createInt32 (f, g) {\n    return super.createInt32(f, g).toString()\n  }\n\n  createInt64 (f1, f2, g1, g2) {\n    return super.createInt64(f1, f2, g1, g2).toString()\n  }\n\n  createInt32Neg (f, g) {\n    return super.createInt32Neg(f, g).toString()\n  }\n\n  createInt64Neg (f1, f2, g1, g2) {\n    return super.createInt64Neg(f1, f2, g1, g2).toString()\n  }\n\n  createTrue () {\n    return 'true'\n  }\n\n  createFalse () {\n    return 'false'\n  }\n\n  createFloat (val) {\n    const fl = super.createFloat(val)\n    if (utils.isNegativeZero(val)) {\n      return '-0_1'\n    }\n\n    return `${fl}_1`\n  }\n\n  createFloatSingle (a, b, c, d) {\n    const fl = super.createFloatSingle(a, b, c, d)\n    return `${fl}_2`\n  }\n\n  createFloatDouble (a, b, c, d, e, f, g, h) {\n    const fl = super.createFloatDouble(a, b, c, d, e, f, g, h)\n    return `${fl}_3`\n  }\n\n  createByteString (raw, len) {\n    const val = raw.join(', ')\n\n    if (len === -1) {\n      return `(_ ${val})`\n    }\n    return `h'${val}`\n  }\n\n  createByteStringFromHeap (start, end) {\n    const val = (Buffer.from(\n      super.createByteStringFromHeap(start, end)\n    )).toString('hex')\n\n    return `h'${val}'`\n  }\n\n  createInfinity () {\n    return 'Infinity_1'\n  }\n\n  createInfinityNeg () {\n    return '-Infinity_1'\n  }\n\n  createNaN () {\n    return 'NaN_1'\n  }\n\n  createNaNNeg () {\n    return '-NaN_1'\n  }\n\n  createNull () {\n    return 'null'\n  }\n\n  createUndefined () {\n    return 'undefined'\n  }\n\n  createSimpleUnassigned (val) {\n    return `simple(${val})`\n  }\n\n  createArray (arr, len) {\n    const val = super.createArray(arr, len)\n\n    if (len === -1) {\n      // indefinite\n      return `[_ ${val.join(', ')}]`\n    }\n\n    return `[${val.join(', ')}]`\n  }\n\n  createMap (map, len) {\n    const val = super.createMap(map)\n    const list = Array.from(val.keys())\n      .reduce(collectObject(val), '')\n\n    if (len === -1) {\n      return `{_ ${list}}`\n    }\n\n    return `{${list}}`\n  }\n\n  createObject (obj, len) {\n    const val = super.createObject(obj)\n    const map = Object.keys(val)\n      .reduce(collectObject(val), '')\n\n    if (len === -1) {\n      return `{_ ${map}}`\n    }\n\n    return `{${map}}`\n  }\n\n  createUtf8String (raw, len) {\n    const val = raw.join(', ')\n\n    if (len === -1) {\n      return `(_ ${val})`\n    }\n\n    return `\"${val}\"`\n  }\n\n  createUtf8StringFromHeap (start, end) {\n    const val = (Buffer.from(\n      super.createUtf8StringFromHeap(start, end)\n    )).toString('utf8')\n\n    return `\"${val}\"`\n  }\n\n  static diagnose (input, enc) {\n    if (typeof input === 'string') {\n      input = Buffer.from(input, enc || 'hex')\n    }\n\n    const dec = new Diagnose()\n    return dec.decodeFirst(input)\n  }\n}\n\nmodule.exports = Diagnose\n\nfunction collectObject (val) {\n  return (acc, key) => {\n    if (acc) {\n      return `${acc}, ${key}: ${val[key]}`\n    }\n    return `${key}: ${val[key]}`\n  }\n}\n","var getPrototypeOf = require(\"./getPrototypeOf\");\n\nfunction _superPropBase(object, property) {\n  while (!Object.prototype.hasOwnProperty.call(object, property)) {\n    object = getPrototypeOf(object);\n    if (object === null) break;\n  }\n\n  return object;\n}\n\nmodule.exports = _superPropBase;","/* eslint-disable */\n\nmodule.exports = function decodeAsm (stdlib, foreign, buffer) {\n  'use asm'\n\n  // -- Imports\n\n  var heap = new stdlib.Uint8Array(buffer)\n  // var log = foreign.log\n  var pushInt = foreign.pushInt\n  var pushInt32 = foreign.pushInt32\n  var pushInt32Neg = foreign.pushInt32Neg\n  var pushInt64 = foreign.pushInt64\n  var pushInt64Neg = foreign.pushInt64Neg\n  var pushFloat = foreign.pushFloat\n  var pushFloatSingle = foreign.pushFloatSingle\n  var pushFloatDouble = foreign.pushFloatDouble\n  var pushTrue = foreign.pushTrue\n  var pushFalse = foreign.pushFalse\n  var pushUndefined = foreign.pushUndefined\n  var pushNull = foreign.pushNull\n  var pushInfinity = foreign.pushInfinity\n  var pushInfinityNeg = foreign.pushInfinityNeg\n  var pushNaN = foreign.pushNaN\n  var pushNaNNeg = foreign.pushNaNNeg\n\n  var pushArrayStart = foreign.pushArrayStart\n  var pushArrayStartFixed = foreign.pushArrayStartFixed\n  var pushArrayStartFixed32 = foreign.pushArrayStartFixed32\n  var pushArrayStartFixed64 = foreign.pushArrayStartFixed64\n  var pushObjectStart = foreign.pushObjectStart\n  var pushObjectStartFixed = foreign.pushObjectStartFixed\n  var pushObjectStartFixed32 = foreign.pushObjectStartFixed32\n  var pushObjectStartFixed64 = foreign.pushObjectStartFixed64\n\n  var pushByteString = foreign.pushByteString\n  var pushByteStringStart = foreign.pushByteStringStart\n  var pushUtf8String = foreign.pushUtf8String\n  var pushUtf8StringStart = foreign.pushUtf8StringStart\n\n  var pushSimpleUnassigned = foreign.pushSimpleUnassigned\n\n  var pushTagStart = foreign.pushTagStart\n  var pushTagStart4 = foreign.pushTagStart4\n  var pushTagStart8 = foreign.pushTagStart8\n  var pushTagUnassigned = foreign.pushTagUnassigned\n\n  var pushBreak = foreign.pushBreak\n\n  var pow = stdlib.Math.pow\n\n  // -- Constants\n\n\n  // -- Mutable Variables\n\n  var offset = 0\n  var inputLength = 0\n  var code = 0\n\n  // Decode a cbor string represented as Uint8Array\n  // which is allocated on the heap from 0 to inputLength\n  //\n  // input - Int\n  //\n  // Returns Code - Int,\n  // Success = 0\n  // Error > 0\n  function parse (input) {\n    input = input | 0\n\n    offset = 0\n    inputLength = input\n\n    while ((offset | 0) < (inputLength | 0)) {\n      code = jumpTable[heap[offset] & 255](heap[offset] | 0) | 0\n\n      if ((code | 0) > 0) {\n        break\n      }\n    }\n\n    return code | 0\n  }\n\n  // -- Helper Function\n\n  function checkOffset (n) {\n    n = n | 0\n\n    if ((((offset | 0) + (n | 0)) | 0) < (inputLength | 0)) {\n      return 0\n    }\n\n    return 1\n  }\n\n  function readUInt16 (n) {\n    n = n | 0\n\n    return (\n      (heap[n | 0] << 8) | heap[(n + 1) | 0]\n    ) | 0\n  }\n\n  function readUInt32 (n) {\n    n = n | 0\n\n    return (\n      (heap[n | 0] << 24) | (heap[(n + 1) | 0] << 16) | (heap[(n + 2) | 0] << 8) | heap[(n + 3) | 0]\n    ) | 0\n  }\n\n  // -- Initial Byte Handlers\n\n  function INT_P (octet) {\n    octet = octet | 0\n\n    pushInt(octet | 0)\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function UINT_P_8 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(1) | 0) {\n      return 1\n    }\n\n    pushInt(heap[(offset + 1) | 0] | 0)\n\n    offset = (offset + 2) | 0\n\n    return 0\n  }\n\n  function UINT_P_16 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(2) | 0) {\n      return 1\n    }\n\n    pushInt(\n      readUInt16((offset + 1) | 0) | 0\n    )\n\n    offset = (offset + 3) | 0\n\n    return 0\n  }\n\n  function UINT_P_32 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(4) | 0) {\n      return 1\n    }\n\n    pushInt32(\n      readUInt16((offset + 1) | 0) | 0,\n      readUInt16((offset + 3) | 0) | 0\n    )\n\n    offset = (offset + 5) | 0\n\n    return 0\n  }\n\n  function UINT_P_64 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(8) | 0) {\n      return 1\n    }\n\n    pushInt64(\n      readUInt16((offset + 1) | 0) | 0,\n      readUInt16((offset + 3) | 0) | 0,\n      readUInt16((offset + 5) | 0) | 0,\n      readUInt16((offset + 7) | 0) | 0\n    )\n\n    offset = (offset + 9) | 0\n\n    return 0\n  }\n\n  function INT_N (octet) {\n    octet = octet | 0\n\n    pushInt((-1 - ((octet - 32) | 0)) | 0)\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function UINT_N_8 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(1) | 0) {\n      return 1\n    }\n\n    pushInt(\n      (-1 - (heap[(offset + 1) | 0] | 0)) | 0\n    )\n\n    offset = (offset + 2) | 0\n\n    return 0\n  }\n\n  function UINT_N_16 (octet) {\n    octet = octet | 0\n\n    var val = 0\n\n    if (checkOffset(2) | 0) {\n      return 1\n    }\n\n    val = readUInt16((offset + 1) | 0) | 0\n    pushInt((-1 - (val | 0)) | 0)\n\n    offset = (offset + 3) | 0\n\n    return 0\n  }\n\n  function UINT_N_32 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(4) | 0) {\n      return 1\n    }\n\n    pushInt32Neg(\n      readUInt16((offset + 1) | 0) | 0,\n      readUInt16((offset + 3) | 0) | 0\n    )\n\n    offset = (offset + 5) | 0\n\n    return 0\n  }\n\n  function UINT_N_64 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(8) | 0) {\n      return 1\n    }\n\n    pushInt64Neg(\n      readUInt16((offset + 1) | 0) | 0,\n      readUInt16((offset + 3) | 0) | 0,\n      readUInt16((offset + 5) | 0) | 0,\n      readUInt16((offset + 7) | 0) | 0\n    )\n\n    offset = (offset + 9) | 0\n\n    return 0\n  }\n\n  function BYTE_STRING (octet) {\n    octet = octet | 0\n\n    var start = 0\n    var end = 0\n    var step = 0\n\n    step = (octet - 64) | 0\n    if (checkOffset(step | 0) | 0) {\n      return 1\n    }\n\n    start = (offset + 1) | 0\n    end = (((offset + 1) | 0) + (step | 0)) | 0\n\n    pushByteString(start | 0, end | 0)\n\n    offset = end | 0\n\n    return 0\n  }\n\n  function BYTE_STRING_8 (octet) {\n    octet = octet | 0\n\n    var start = 0\n    var end = 0\n    var length = 0\n\n    if (checkOffset(1) | 0) {\n      return 1\n    }\n\n    length = heap[(offset + 1) | 0] | 0\n    start = (offset + 2) | 0\n    end = (((offset + 2) | 0) + (length | 0)) | 0\n\n    if (checkOffset((length + 1) | 0) | 0) {\n      return 1\n    }\n\n    pushByteString(start | 0, end | 0)\n\n    offset = end | 0\n\n    return 0\n  }\n\n  function BYTE_STRING_16 (octet) {\n    octet = octet | 0\n\n    var start = 0\n    var end = 0\n    var length = 0\n\n    if (checkOffset(2) | 0) {\n      return 1\n    }\n\n    length = readUInt16((offset + 1) | 0) | 0\n    start = (offset + 3) | 0\n    end = (((offset + 3) | 0) + (length | 0)) | 0\n\n\n    if (checkOffset((length + 2) | 0) | 0) {\n      return 1\n    }\n\n    pushByteString(start | 0, end | 0)\n\n    offset = end | 0\n\n    return 0\n  }\n\n  function BYTE_STRING_32 (octet) {\n    octet = octet | 0\n\n    var start = 0\n    var end = 0\n    var length = 0\n\n    if (checkOffset(4) | 0) {\n      return 1\n    }\n\n    length = readUInt32((offset + 1) | 0) | 0\n    start = (offset + 5) | 0\n    end = (((offset + 5) | 0) + (length | 0)) | 0\n\n\n    if (checkOffset((length + 4) | 0) | 0) {\n      return 1\n    }\n\n    pushByteString(start | 0, end | 0)\n\n    offset = end | 0\n\n    return 0\n  }\n\n  function BYTE_STRING_64 (octet) {\n    // NOT IMPLEMENTED\n    octet = octet | 0\n\n    return 1\n  }\n\n  function BYTE_STRING_BREAK (octet) {\n    octet = octet | 0\n\n    pushByteStringStart()\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function UTF8_STRING (octet) {\n    octet = octet | 0\n\n    var start = 0\n    var end = 0\n    var step = 0\n\n    step = (octet - 96) | 0\n\n    if (checkOffset(step | 0) | 0) {\n      return 1\n    }\n\n    start = (offset + 1) | 0\n    end = (((offset + 1) | 0) + (step | 0)) | 0\n\n    pushUtf8String(start | 0, end | 0)\n\n    offset = end | 0\n\n    return 0\n  }\n\n  function UTF8_STRING_8 (octet) {\n    octet = octet | 0\n\n    var start = 0\n    var end = 0\n    var length = 0\n\n    if (checkOffset(1) | 0) {\n      return 1\n    }\n\n    length = heap[(offset + 1) | 0] | 0\n    start = (offset + 2) | 0\n    end = (((offset + 2) | 0) + (length | 0)) | 0\n\n    if (checkOffset((length + 1) | 0) | 0) {\n      return 1\n    }\n\n    pushUtf8String(start | 0, end | 0)\n\n    offset = end | 0\n\n    return 0\n  }\n\n  function UTF8_STRING_16 (octet) {\n    octet = octet | 0\n\n    var start = 0\n    var end = 0\n    var length = 0\n\n    if (checkOffset(2) | 0) {\n      return 1\n    }\n\n    length = readUInt16((offset + 1) | 0) | 0\n    start = (offset + 3) | 0\n    end = (((offset + 3) | 0) + (length | 0)) | 0\n\n    if (checkOffset((length + 2) | 0) | 0) {\n      return 1\n    }\n\n    pushUtf8String(start | 0, end | 0)\n\n    offset = end | 0\n\n    return 0\n  }\n\n  function UTF8_STRING_32 (octet) {\n    octet = octet | 0\n\n    var start = 0\n    var end = 0\n    var length = 0\n\n    if (checkOffset(4) | 0) {\n      return 1\n    }\n\n    length = readUInt32((offset + 1) | 0) | 0\n    start = (offset + 5) | 0\n    end = (((offset + 5) | 0) + (length | 0)) | 0\n\n    if (checkOffset((length + 4) | 0) | 0) {\n      return 1\n    }\n\n    pushUtf8String(start | 0, end | 0)\n\n    offset = end | 0\n\n    return 0\n  }\n\n  function UTF8_STRING_64 (octet) {\n    // NOT IMPLEMENTED\n    octet = octet | 0\n\n    return 1\n  }\n\n  function UTF8_STRING_BREAK (octet) {\n    octet = octet | 0\n\n    pushUtf8StringStart()\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function ARRAY (octet) {\n    octet = octet | 0\n\n    pushArrayStartFixed((octet - 128) | 0)\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function ARRAY_8 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(1) | 0) {\n      return 1\n    }\n\n    pushArrayStartFixed(heap[(offset + 1) | 0] | 0)\n\n    offset = (offset + 2) | 0\n\n    return 0\n  }\n\n  function ARRAY_16 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(2) | 0) {\n      return 1\n    }\n\n    pushArrayStartFixed(\n      readUInt16((offset + 1) | 0) | 0\n    )\n\n    offset = (offset + 3) | 0\n\n    return 0\n  }\n\n  function ARRAY_32 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(4) | 0) {\n      return 1\n    }\n\n    pushArrayStartFixed32(\n      readUInt16((offset + 1) | 0) | 0,\n      readUInt16((offset + 3) | 0) | 0\n    )\n\n    offset = (offset + 5) | 0\n\n    return 0\n  }\n\n  function ARRAY_64 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(8) | 0) {\n      return 1\n    }\n\n    pushArrayStartFixed64(\n      readUInt16((offset + 1) | 0) | 0,\n      readUInt16((offset + 3) | 0) | 0,\n      readUInt16((offset + 5) | 0) | 0,\n      readUInt16((offset + 7) | 0) | 0\n    )\n\n    offset = (offset + 9) | 0\n\n    return 0\n  }\n\n  function ARRAY_BREAK (octet) {\n    octet = octet | 0\n\n    pushArrayStart()\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function MAP (octet) {\n    octet = octet | 0\n\n    var step = 0\n\n    step = (octet - 160) | 0\n\n    if (checkOffset(step | 0) | 0) {\n      return 1\n    }\n\n    pushObjectStartFixed(step | 0)\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function MAP_8 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(1) | 0) {\n      return 1\n    }\n\n    pushObjectStartFixed(heap[(offset + 1) | 0] | 0)\n\n    offset = (offset + 2) | 0\n\n    return 0\n  }\n\n  function MAP_16 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(2) | 0) {\n      return 1\n    }\n\n    pushObjectStartFixed(\n      readUInt16((offset + 1) | 0) | 0\n    )\n\n    offset = (offset + 3) | 0\n\n    return 0\n  }\n\n  function MAP_32 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(4) | 0) {\n      return 1\n    }\n\n    pushObjectStartFixed32(\n      readUInt16((offset + 1) | 0) | 0,\n      readUInt16((offset + 3) | 0) | 0\n    )\n\n    offset = (offset + 5) | 0\n\n    return 0\n  }\n\n  function MAP_64 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(8) | 0) {\n      return 1\n    }\n\n    pushObjectStartFixed64(\n      readUInt16((offset + 1) | 0) | 0,\n      readUInt16((offset + 3) | 0) | 0,\n      readUInt16((offset + 5) | 0) | 0,\n      readUInt16((offset + 7) | 0) | 0\n    )\n\n    offset = (offset + 9) | 0\n\n    return 0\n  }\n\n  function MAP_BREAK (octet) {\n    octet = octet | 0\n\n    pushObjectStart()\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function TAG_KNOWN (octet) {\n    octet = octet | 0\n\n    pushTagStart((octet - 192| 0) | 0)\n\n    offset = (offset + 1 | 0)\n\n    return 0\n  }\n\n  function TAG_BIGNUM_POS (octet) {\n    octet = octet | 0\n\n    pushTagStart(octet | 0)\n\n    offset = (offset + 1 | 0)\n\n    return 0\n  }\n\n  function TAG_BIGNUM_NEG (octet) {\n    octet = octet | 0\n\n    pushTagStart(octet | 0)\n\n    offset = (offset + 1 | 0)\n\n    return 0\n  }\n\n  function TAG_FRAC (octet) {\n    octet = octet | 0\n\n    pushTagStart(octet | 0)\n\n    offset = (offset + 1 | 0)\n\n    return 0\n  }\n\n  function TAG_BIGNUM_FLOAT (octet) {\n    octet = octet | 0\n\n    pushTagStart(octet | 0)\n\n    offset = (offset + 1 | 0)\n\n    return 0\n  }\n\n  function TAG_UNASSIGNED (octet) {\n    octet = octet | 0\n\n    pushTagStart((octet - 192| 0) | 0)\n\n    offset = (offset + 1 | 0)\n\n    return 0\n  }\n\n  function TAG_BASE64_URL (octet) {\n    octet = octet | 0\n\n    pushTagStart(octet | 0)\n\n    offset = (offset + 1 | 0)\n\n    return 0\n  }\n\n  function TAG_BASE64 (octet) {\n    octet = octet | 0\n\n    pushTagStart(octet | 0)\n\n    offset = (offset + 1 | 0)\n\n    return 0\n  }\n\n  function TAG_BASE16 (octet) {\n    octet = octet | 0\n\n    pushTagStart(octet | 0)\n\n    offset = (offset + 1 | 0)\n\n    return 0\n  }\n\n  function TAG_MORE_1 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(1) | 0) {\n      return 1\n    }\n\n    pushTagStart(heap[(offset + 1) | 0] | 0)\n\n    offset = (offset + 2 | 0)\n\n    return 0\n  }\n\n  function TAG_MORE_2 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(2) | 0) {\n      return 1\n    }\n\n    pushTagStart(\n      readUInt16((offset + 1) | 0) | 0\n    )\n\n    offset = (offset + 3 | 0)\n\n    return 0\n  }\n\n  function TAG_MORE_4 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(4) | 0) {\n      return 1\n    }\n\n    pushTagStart4(\n      readUInt16((offset + 1) | 0) | 0,\n      readUInt16((offset + 3) | 0) | 0\n    )\n\n    offset = (offset + 5 | 0)\n\n    return 0\n  }\n\n  function TAG_MORE_8 (octet) {\n    octet = octet | 0\n\n    if (checkOffset(8) | 0) {\n      return 1\n    }\n\n    pushTagStart8(\n      readUInt16((offset + 1) | 0) | 0,\n      readUInt16((offset + 3) | 0) | 0,\n      readUInt16((offset + 5) | 0) | 0,\n      readUInt16((offset + 7) | 0) | 0\n    )\n\n    offset = (offset + 9 | 0)\n\n    return 0\n  }\n\n  function SIMPLE_UNASSIGNED (octet) {\n    octet = octet | 0\n\n    pushSimpleUnassigned(((octet | 0) - 224) | 0)\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function SIMPLE_FALSE (octet) {\n    octet = octet | 0\n\n    pushFalse()\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function SIMPLE_TRUE (octet) {\n    octet = octet | 0\n\n    pushTrue()\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function SIMPLE_NULL (octet) {\n    octet = octet | 0\n\n    pushNull()\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function SIMPLE_UNDEFINED (octet) {\n    octet = octet | 0\n\n    pushUndefined()\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  function SIMPLE_BYTE (octet) {\n    octet = octet | 0\n\n    if (checkOffset(1) | 0) {\n      return 1\n    }\n\n    pushSimpleUnassigned(heap[(offset + 1) | 0] | 0)\n\n    offset = (offset + 2)  | 0\n\n    return 0\n  }\n\n  function SIMPLE_FLOAT_HALF (octet) {\n    octet = octet | 0\n\n    var f = 0\n    var g = 0\n    var sign = 1.0\n    var exp = 0.0\n    var mant = 0.0\n    var r = 0.0\n    if (checkOffset(2) | 0) {\n      return 1\n    }\n\n    f = heap[(offset + 1) | 0] | 0\n    g = heap[(offset + 2) | 0] | 0\n\n    if ((f | 0) & 0x80) {\n      sign = -1.0\n    }\n\n    exp = +(((f | 0) & 0x7C) >> 2)\n    mant = +((((f | 0) & 0x03) << 8) | g)\n\n    if (+exp == 0.0) {\n      pushFloat(+(\n        (+sign) * +5.9604644775390625e-8 * (+mant)\n      ))\n    } else if (+exp == 31.0) {\n      if (+sign == 1.0) {\n        if (+mant > 0.0) {\n          pushNaN()\n        } else {\n          pushInfinity()\n        }\n      } else {\n        if (+mant > 0.0) {\n          pushNaNNeg()\n        } else {\n          pushInfinityNeg()\n        }\n      }\n    } else {\n      pushFloat(+(\n        +sign * pow(+2, +(+exp - 25.0)) * +(1024.0 + mant)\n      ))\n    }\n\n    offset = (offset + 3) | 0\n\n    return 0\n  }\n\n  function SIMPLE_FLOAT_SINGLE (octet) {\n    octet = octet | 0\n\n    if (checkOffset(4) | 0) {\n      return 1\n    }\n\n    pushFloatSingle(\n      heap[(offset + 1) | 0] | 0,\n      heap[(offset + 2) | 0] | 0,\n      heap[(offset + 3) | 0] | 0,\n      heap[(offset + 4) | 0] | 0\n    )\n\n    offset = (offset + 5) | 0\n\n    return 0\n  }\n\n  function SIMPLE_FLOAT_DOUBLE (octet) {\n    octet = octet | 0\n\n    if (checkOffset(8) | 0) {\n      return 1\n    }\n\n    pushFloatDouble(\n      heap[(offset + 1) | 0] | 0,\n      heap[(offset + 2) | 0] | 0,\n      heap[(offset + 3) | 0] | 0,\n      heap[(offset + 4) | 0] | 0,\n      heap[(offset + 5) | 0] | 0,\n      heap[(offset + 6) | 0] | 0,\n      heap[(offset + 7) | 0] | 0,\n      heap[(offset + 8) | 0] | 0\n    )\n\n    offset = (offset + 9) | 0\n\n    return 0\n  }\n\n  function ERROR (octet) {\n    octet = octet | 0\n\n    return 1\n  }\n\n  function BREAK (octet) {\n    octet = octet | 0\n\n    pushBreak()\n\n    offset = (offset + 1) | 0\n\n    return 0\n  }\n\n  // -- Jump Table\n\n  var jumpTable = [\n    // Integer 0x00..0x17 (0..23)\n    INT_P, // 0x00\n    INT_P, // 0x01\n    INT_P, // 0x02\n    INT_P, // 0x03\n    INT_P, // 0x04\n    INT_P, // 0x05\n    INT_P, // 0x06\n    INT_P, // 0x07\n    INT_P, // 0x08\n    INT_P, // 0x09\n    INT_P, // 0x0A\n    INT_P, // 0x0B\n    INT_P, // 0x0C\n    INT_P, // 0x0D\n    INT_P, // 0x0E\n    INT_P, // 0x0F\n    INT_P, // 0x10\n    INT_P, // 0x11\n    INT_P, // 0x12\n    INT_P, // 0x13\n    INT_P, // 0x14\n    INT_P, // 0x15\n    INT_P, // 0x16\n    INT_P, // 0x17\n    // Unsigned integer (one-byte uint8_t follows)\n    UINT_P_8, // 0x18\n    // Unsigned integer (two-byte uint16_t follows)\n    UINT_P_16, // 0x19\n    // Unsigned integer (four-byte uint32_t follows)\n    UINT_P_32, // 0x1a\n    // Unsigned integer (eight-byte uint64_t follows)\n    UINT_P_64, // 0x1b\n    ERROR, // 0x1c\n    ERROR, // 0x1d\n    ERROR, // 0x1e\n    ERROR, // 0x1f\n    // Negative integer -1-0x00..-1-0x17 (-1..-24)\n    INT_N, // 0x20\n    INT_N, // 0x21\n    INT_N, // 0x22\n    INT_N, // 0x23\n    INT_N, // 0x24\n    INT_N, // 0x25\n    INT_N, // 0x26\n    INT_N, // 0x27\n    INT_N, // 0x28\n    INT_N, // 0x29\n    INT_N, // 0x2A\n    INT_N, // 0x2B\n    INT_N, // 0x2C\n    INT_N, // 0x2D\n    INT_N, // 0x2E\n    INT_N, // 0x2F\n    INT_N, // 0x30\n    INT_N, // 0x31\n    INT_N, // 0x32\n    INT_N, // 0x33\n    INT_N, // 0x34\n    INT_N, // 0x35\n    INT_N, // 0x36\n    INT_N, // 0x37\n    // Negative integer -1-n (one-byte uint8_t for n follows)\n    UINT_N_8, // 0x38\n    // Negative integer -1-n (two-byte uint16_t for n follows)\n    UINT_N_16, // 0x39\n    // Negative integer -1-n (four-byte uint32_t for nfollows)\n    UINT_N_32, // 0x3a\n    // Negative integer -1-n (eight-byte uint64_t for n follows)\n    UINT_N_64, // 0x3b\n    ERROR, // 0x3c\n    ERROR, // 0x3d\n    ERROR, // 0x3e\n    ERROR, // 0x3f\n    // byte string (0x00..0x17 bytes follow)\n    BYTE_STRING, // 0x40\n    BYTE_STRING, // 0x41\n    BYTE_STRING, // 0x42\n    BYTE_STRING, // 0x43\n    BYTE_STRING, // 0x44\n    BYTE_STRING, // 0x45\n    BYTE_STRING, // 0x46\n    BYTE_STRING, // 0x47\n    BYTE_STRING, // 0x48\n    BYTE_STRING, // 0x49\n    BYTE_STRING, // 0x4A\n    BYTE_STRING, // 0x4B\n    BYTE_STRING, // 0x4C\n    BYTE_STRING, // 0x4D\n    BYTE_STRING, // 0x4E\n    BYTE_STRING, // 0x4F\n    BYTE_STRING, // 0x50\n    BYTE_STRING, // 0x51\n    BYTE_STRING, // 0x52\n    BYTE_STRING, // 0x53\n    BYTE_STRING, // 0x54\n    BYTE_STRING, // 0x55\n    BYTE_STRING, // 0x56\n    BYTE_STRING, // 0x57\n    // byte string (one-byte uint8_t for n, and then n bytes follow)\n    BYTE_STRING_8, // 0x58\n    // byte string (two-byte uint16_t for n, and then n bytes follow)\n    BYTE_STRING_16, // 0x59\n    // byte string (four-byte uint32_t for n, and then n bytes follow)\n    BYTE_STRING_32, // 0x5a\n    // byte string (eight-byte uint64_t for n, and then n bytes follow)\n    BYTE_STRING_64, // 0x5b\n    ERROR, // 0x5c\n    ERROR, // 0x5d\n    ERROR, // 0x5e\n    // byte string, byte strings follow, terminated by \"break\"\n    BYTE_STRING_BREAK, // 0x5f\n    // UTF-8 string (0x00..0x17 bytes follow)\n    UTF8_STRING, // 0x60\n    UTF8_STRING, // 0x61\n    UTF8_STRING, // 0x62\n    UTF8_STRING, // 0x63\n    UTF8_STRING, // 0x64\n    UTF8_STRING, // 0x65\n    UTF8_STRING, // 0x66\n    UTF8_STRING, // 0x67\n    UTF8_STRING, // 0x68\n    UTF8_STRING, // 0x69\n    UTF8_STRING, // 0x6A\n    UTF8_STRING, // 0x6B\n    UTF8_STRING, // 0x6C\n    UTF8_STRING, // 0x6D\n    UTF8_STRING, // 0x6E\n    UTF8_STRING, // 0x6F\n    UTF8_STRING, // 0x70\n    UTF8_STRING, // 0x71\n    UTF8_STRING, // 0x72\n    UTF8_STRING, // 0x73\n    UTF8_STRING, // 0x74\n    UTF8_STRING, // 0x75\n    UTF8_STRING, // 0x76\n    UTF8_STRING, // 0x77\n    // UTF-8 string (one-byte uint8_t for n, and then n bytes follow)\n    UTF8_STRING_8, // 0x78\n    // UTF-8 string (two-byte uint16_t for n, and then n bytes follow)\n    UTF8_STRING_16, // 0x79\n    // UTF-8 string (four-byte uint32_t for n, and then n bytes follow)\n    UTF8_STRING_32, // 0x7a\n    // UTF-8 string (eight-byte uint64_t for n, and then n bytes follow)\n    UTF8_STRING_64, // 0x7b\n    // UTF-8 string, UTF-8 strings follow, terminated by \"break\"\n    ERROR, // 0x7c\n    ERROR, // 0x7d\n    ERROR, // 0x7e\n    UTF8_STRING_BREAK, // 0x7f\n    // array (0x00..0x17 data items follow)\n    ARRAY, // 0x80\n    ARRAY, // 0x81\n    ARRAY, // 0x82\n    ARRAY, // 0x83\n    ARRAY, // 0x84\n    ARRAY, // 0x85\n    ARRAY, // 0x86\n    ARRAY, // 0x87\n    ARRAY, // 0x88\n    ARRAY, // 0x89\n    ARRAY, // 0x8A\n    ARRAY, // 0x8B\n    ARRAY, // 0x8C\n    ARRAY, // 0x8D\n    ARRAY, // 0x8E\n    ARRAY, // 0x8F\n    ARRAY, // 0x90\n    ARRAY, // 0x91\n    ARRAY, // 0x92\n    ARRAY, // 0x93\n    ARRAY, // 0x94\n    ARRAY, // 0x95\n    ARRAY, // 0x96\n    ARRAY, // 0x97\n    // array (one-byte uint8_t fo, and then n data items follow)\n    ARRAY_8, // 0x98\n    // array (two-byte uint16_t for n, and then n data items follow)\n    ARRAY_16, // 0x99\n    // array (four-byte uint32_t for n, and then n data items follow)\n    ARRAY_32, // 0x9a\n    // array (eight-byte uint64_t for n, and then n data items follow)\n    ARRAY_64, // 0x9b\n    // array, data items follow, terminated by \"break\"\n    ERROR, // 0x9c\n    ERROR, // 0x9d\n    ERROR, // 0x9e\n    ARRAY_BREAK, // 0x9f\n    // map (0x00..0x17 pairs of data items follow)\n    MAP, // 0xa0\n    MAP, // 0xa1\n    MAP, // 0xa2\n    MAP, // 0xa3\n    MAP, // 0xa4\n    MAP, // 0xa5\n    MAP, // 0xa6\n    MAP, // 0xa7\n    MAP, // 0xa8\n    MAP, // 0xa9\n    MAP, // 0xaA\n    MAP, // 0xaB\n    MAP, // 0xaC\n    MAP, // 0xaD\n    MAP, // 0xaE\n    MAP, // 0xaF\n    MAP, // 0xb0\n    MAP, // 0xb1\n    MAP, // 0xb2\n    MAP, // 0xb3\n    MAP, // 0xb4\n    MAP, // 0xb5\n    MAP, // 0xb6\n    MAP, // 0xb7\n    // map (one-byte uint8_t for n, and then n pairs of data items follow)\n    MAP_8, // 0xb8\n    // map (two-byte uint16_t for n, and then n pairs of data items follow)\n    MAP_16, // 0xb9\n    // map (four-byte uint32_t for n, and then n pairs of data items follow)\n    MAP_32, // 0xba\n    // map (eight-byte uint64_t for n, and then n pairs of data items follow)\n    MAP_64, // 0xbb\n    ERROR, // 0xbc\n    ERROR, // 0xbd\n    ERROR, // 0xbe\n    // map, pairs of data items follow, terminated by \"break\"\n    MAP_BREAK, // 0xbf\n    // Text-based date/time (data item follows; see Section 2.4.1)\n    TAG_KNOWN, // 0xc0\n    // Epoch-based date/time (data item follows; see Section 2.4.1)\n    TAG_KNOWN, // 0xc1\n    // Positive bignum (data item \"byte string\" follows)\n    TAG_KNOWN, // 0xc2\n    // Negative bignum (data item \"byte string\" follows)\n    TAG_KNOWN, // 0xc3\n    // Decimal Fraction (data item \"array\" follows; see Section 2.4.3)\n    TAG_KNOWN, // 0xc4\n    // Bigfloat (data item \"array\" follows; see Section 2.4.3)\n    TAG_KNOWN, // 0xc5\n    // (tagged item)\n    TAG_UNASSIGNED, // 0xc6\n    TAG_UNASSIGNED, // 0xc7\n    TAG_UNASSIGNED, // 0xc8\n    TAG_UNASSIGNED, // 0xc9\n    TAG_UNASSIGNED, // 0xca\n    TAG_UNASSIGNED, // 0xcb\n    TAG_UNASSIGNED, // 0xcc\n    TAG_UNASSIGNED, // 0xcd\n    TAG_UNASSIGNED, // 0xce\n    TAG_UNASSIGNED, // 0xcf\n    TAG_UNASSIGNED, // 0xd0\n    TAG_UNASSIGNED, // 0xd1\n    TAG_UNASSIGNED, // 0xd2\n    TAG_UNASSIGNED, // 0xd3\n    TAG_UNASSIGNED, // 0xd4\n    // Expected Conversion (data item follows; see Section 2.4.4.2)\n    TAG_UNASSIGNED, // 0xd5\n    TAG_UNASSIGNED, // 0xd6\n    TAG_UNASSIGNED, // 0xd7\n    // (more tagged items, 1/2/4/8 bytes and then a data item follow)\n    TAG_MORE_1, // 0xd8\n    TAG_MORE_2, // 0xd9\n    TAG_MORE_4, // 0xda\n    TAG_MORE_8, // 0xdb\n    ERROR, // 0xdc\n    ERROR, // 0xdd\n    ERROR, // 0xde\n    ERROR, // 0xdf\n    // (simple value)\n    SIMPLE_UNASSIGNED, // 0xe0\n    SIMPLE_UNASSIGNED, // 0xe1\n    SIMPLE_UNASSIGNED, // 0xe2\n    SIMPLE_UNASSIGNED, // 0xe3\n    SIMPLE_UNASSIGNED, // 0xe4\n    SIMPLE_UNASSIGNED, // 0xe5\n    SIMPLE_UNASSIGNED, // 0xe6\n    SIMPLE_UNASSIGNED, // 0xe7\n    SIMPLE_UNASSIGNED, // 0xe8\n    SIMPLE_UNASSIGNED, // 0xe9\n    SIMPLE_UNASSIGNED, // 0xea\n    SIMPLE_UNASSIGNED, // 0xeb\n    SIMPLE_UNASSIGNED, // 0xec\n    SIMPLE_UNASSIGNED, // 0xed\n    SIMPLE_UNASSIGNED, // 0xee\n    SIMPLE_UNASSIGNED, // 0xef\n    SIMPLE_UNASSIGNED, // 0xf0\n    SIMPLE_UNASSIGNED, // 0xf1\n    SIMPLE_UNASSIGNED, // 0xf2\n    SIMPLE_UNASSIGNED, // 0xf3\n    // False\n    SIMPLE_FALSE, // 0xf4\n    // True\n    SIMPLE_TRUE, // 0xf5\n    // Null\n    SIMPLE_NULL, // 0xf6\n    // Undefined\n    SIMPLE_UNDEFINED, // 0xf7\n    // (simple value, one byte follows)\n    SIMPLE_BYTE, // 0xf8\n    // Half-Precision Float (two-byte IEEE 754)\n    SIMPLE_FLOAT_HALF, // 0xf9\n    // Single-Precision Float (four-byte IEEE 754)\n    SIMPLE_FLOAT_SINGLE, // 0xfa\n    // Double-Precision Float (eight-byte IEEE 754)\n    SIMPLE_FLOAT_DOUBLE, // 0xfb\n    ERROR, // 0xfc\n    ERROR, // 0xfd\n    ERROR, // 0xfe\n    // \"break\" stop code\n    BREAK // 0xff\n  ]\n\n  // --\n\n  return {\n    parse: parse\n  }\n}\n","'use strict';\n\nconst { URLWithLegacySupport, format } = require('./url');\n\nmodule.exports = (url, location = {}, protocolMap = {}, defaultProtocol) => {\n    let protocol = location.protocol ?\n        location.protocol.replace(':', '') :\n        'http';\n\n    // Check protocol map\n    protocol = (protocolMap[protocol] || defaultProtocol || protocol) + ':';\n    let urlParsed;\n\n    try {\n        urlParsed = new URLWithLegacySupport(url);\n    } catch (err) {\n        urlParsed = {};\n    }\n\n    const base = Object.assign({}, location, {\n        protocol: protocol || urlParsed.protocol,\n        host: location.host || urlParsed.host\n    });\n\n    return new URLWithLegacySupport(url, format(base)).toString();\n};\n","'use strict'\n\nconst { Buffer } = require('buffer')\nconst { URL } = require('iso-url')\nconst Bignumber = require('bignumber.js').BigNumber\n\nconst utils = require('./utils')\nconst constants = require('./constants')\nconst MT = constants.MT\nconst NUMBYTES = constants.NUMBYTES\nconst SHIFT32 = constants.SHIFT32\nconst SYMS = constants.SYMS\nconst TAG = constants.TAG\nconst HALF = (constants.MT.SIMPLE_FLOAT << 5) | constants.NUMBYTES.TWO\nconst FLOAT = (constants.MT.SIMPLE_FLOAT << 5) | constants.NUMBYTES.FOUR\nconst DOUBLE = (constants.MT.SIMPLE_FLOAT << 5) | constants.NUMBYTES.EIGHT\nconst TRUE = (constants.MT.SIMPLE_FLOAT << 5) | constants.SIMPLE.TRUE\nconst FALSE = (constants.MT.SIMPLE_FLOAT << 5) | constants.SIMPLE.FALSE\nconst UNDEFINED = (constants.MT.SIMPLE_FLOAT << 5) | constants.SIMPLE.UNDEFINED\nconst NULL = (constants.MT.SIMPLE_FLOAT << 5) | constants.SIMPLE.NULL\n\nconst MAXINT_BN = new Bignumber('0x20000000000000')\nconst BUF_NAN = Buffer.from('f97e00', 'hex')\nconst BUF_INF_NEG = Buffer.from('f9fc00', 'hex')\nconst BUF_INF_POS = Buffer.from('f97c00', 'hex')\n\nfunction toType (obj) {\n  // [object Type]\n  // --------8---1\n  return ({}).toString.call(obj).slice(8, -1)\n}\n\n/**\n * Transform JavaScript values into CBOR bytes\n *\n */\nclass Encoder {\n  /**\n   * @param {Object} [options={}]\n   * @param {function(Buffer)} options.stream\n   */\n  constructor (options) {\n    options = options || {}\n\n    this.streaming = typeof options.stream === 'function'\n    this.onData = options.stream\n\n    this.semanticTypes = [\n      [URL, this._pushUrl],\n      [Bignumber, this._pushBigNumber]\n    ]\n\n    const addTypes = options.genTypes || []\n    const len = addTypes.length\n    for (let i = 0; i < len; i++) {\n      this.addSemanticType(\n        addTypes[i][0],\n        addTypes[i][1]\n      )\n    }\n\n    this._reset()\n  }\n\n  addSemanticType (type, fun) {\n    const len = this.semanticTypes.length\n    for (let i = 0; i < len; i++) {\n      const typ = this.semanticTypes[i][0]\n      if (typ === type) {\n        const old = this.semanticTypes[i][1]\n        this.semanticTypes[i][1] = fun\n        return old\n      }\n    }\n    this.semanticTypes.push([type, fun])\n    return null\n  }\n\n  push (val) {\n    if (!val) {\n      return true\n    }\n\n    this.result[this.offset] = val\n    this.resultMethod[this.offset] = 0\n    this.resultLength[this.offset] = val.length\n    this.offset++\n\n    if (this.streaming) {\n      this.onData(this.finalize())\n    }\n\n    return true\n  }\n\n  pushWrite (val, method, len) {\n    this.result[this.offset] = val\n    this.resultMethod[this.offset] = method\n    this.resultLength[this.offset] = len\n    this.offset++\n\n    if (this.streaming) {\n      this.onData(this.finalize())\n    }\n\n    return true\n  }\n\n  _pushUInt8 (val) {\n    return this.pushWrite(val, 1, 1)\n  }\n\n  _pushUInt16BE (val) {\n    return this.pushWrite(val, 2, 2)\n  }\n\n  _pushUInt32BE (val) {\n    return this.pushWrite(val, 3, 4)\n  }\n\n  _pushDoubleBE (val) {\n    return this.pushWrite(val, 4, 8)\n  }\n\n  _pushNaN () {\n    return this.push(BUF_NAN)\n  }\n\n  _pushInfinity (obj) {\n    const half = (obj < 0) ? BUF_INF_NEG : BUF_INF_POS\n    return this.push(half)\n  }\n\n  _pushFloat (obj) {\n    const b2 = Buffer.allocUnsafe(2)\n\n    if (utils.writeHalf(b2, obj)) {\n      if (utils.parseHalf(b2) === obj) {\n        return this._pushUInt8(HALF) && this.push(b2)\n      }\n    }\n\n    const b4 = Buffer.allocUnsafe(4)\n    b4.writeFloatBE(obj, 0)\n    if (b4.readFloatBE(0) === obj) {\n      return this._pushUInt8(FLOAT) && this.push(b4)\n    }\n\n    return this._pushUInt8(DOUBLE) && this._pushDoubleBE(obj)\n  }\n\n  _pushInt (obj, mt, orig) {\n    const m = mt << 5\n    if (obj < 24) {\n      return this._pushUInt8(m | obj)\n    }\n\n    if (obj <= 0xff) {\n      return this._pushUInt8(m | NUMBYTES.ONE) && this._pushUInt8(obj)\n    }\n\n    if (obj <= 0xffff) {\n      return this._pushUInt8(m | NUMBYTES.TWO) && this._pushUInt16BE(obj)\n    }\n\n    if (obj <= 0xffffffff) {\n      return this._pushUInt8(m | NUMBYTES.FOUR) && this._pushUInt32BE(obj)\n    }\n\n    if (obj <= Number.MAX_SAFE_INTEGER) {\n      return this._pushUInt8(m | NUMBYTES.EIGHT) &&\n        this._pushUInt32BE(Math.floor(obj / SHIFT32)) &&\n        this._pushUInt32BE(obj % SHIFT32)\n    }\n\n    if (mt === MT.NEG_INT) {\n      return this._pushFloat(orig)\n    }\n\n    return this._pushFloat(obj)\n  }\n\n  _pushIntNum (obj) {\n    if (obj < 0) {\n      return this._pushInt(-obj - 1, MT.NEG_INT, obj)\n    } else {\n      return this._pushInt(obj, MT.POS_INT)\n    }\n  }\n\n  _pushNumber (obj) {\n    switch (false) {\n      case (obj === obj): // eslint-disable-line\n        return this._pushNaN(obj)\n      case isFinite(obj):\n        return this._pushInfinity(obj)\n      case ((obj % 1) !== 0):\n        return this._pushIntNum(obj)\n      default:\n        return this._pushFloat(obj)\n    }\n  }\n\n  _pushString (obj) {\n    const len = Buffer.byteLength(obj, 'utf8')\n    return this._pushInt(len, MT.UTF8_STRING) && this.pushWrite(obj, 5, len)\n  }\n\n  _pushBoolean (obj) {\n    return this._pushUInt8(obj ? TRUE : FALSE)\n  }\n\n  _pushUndefined (obj) {\n    return this._pushUInt8(UNDEFINED)\n  }\n\n  _pushArray (gen, obj) {\n    const len = obj.length\n    if (!gen._pushInt(len, MT.ARRAY)) {\n      return false\n    }\n    for (let j = 0; j < len; j++) {\n      if (!gen.pushAny(obj[j])) {\n        return false\n      }\n    }\n    return true\n  }\n\n  _pushTag (tag) {\n    return this._pushInt(tag, MT.TAG)\n  }\n\n  _pushDate (gen, obj) {\n    // Round date, to get seconds since 1970-01-01 00:00:00 as defined in\n    // Sec. 2.4.1 and get a possibly more compact encoding. Note that it is\n    // still allowed to encode fractions of seconds which can be achieved by\n    // changing overwriting the encode function for Date objects.\n    return gen._pushTag(TAG.DATE_EPOCH) && gen.pushAny(Math.round(obj / 1000))\n  }\n\n  _pushBuffer (gen, obj) {\n    return gen._pushInt(obj.length, MT.BYTE_STRING) && gen.push(obj)\n  }\n\n  _pushNoFilter (gen, obj) {\n    return gen._pushBuffer(gen, obj.slice())\n  }\n\n  _pushRegexp (gen, obj) {\n    return gen._pushTag(TAG.REGEXP) && gen.pushAny(obj.source)\n  }\n\n  _pushSet (gen, obj) {\n    if (!gen._pushInt(obj.size, MT.ARRAY)) {\n      return false\n    }\n    for (const x of obj) {\n      if (!gen.pushAny(x)) {\n        return false\n      }\n    }\n    return true\n  }\n\n  _pushUrl (gen, obj) {\n    return gen._pushTag(TAG.URI) && gen.pushAny(obj.format())\n  }\n\n  _pushBigint (obj) {\n    let tag = TAG.POS_BIGINT\n    if (obj.isNegative()) {\n      obj = obj.negated().minus(1)\n      tag = TAG.NEG_BIGINT\n    }\n    let str = obj.toString(16)\n    if (str.length % 2) {\n      str = '0' + str\n    }\n    const buf = Buffer.from(str, 'hex')\n    return this._pushTag(tag) && this._pushBuffer(this, buf)\n  }\n\n  _pushBigNumber (gen, obj) {\n    if (obj.isNaN()) {\n      return gen._pushNaN()\n    }\n    if (!obj.isFinite()) {\n      return gen._pushInfinity(obj.isNegative() ? -Infinity : Infinity)\n    }\n    if (obj.isInteger()) {\n      return gen._pushBigint(obj)\n    }\n    if (!(gen._pushTag(TAG.DECIMAL_FRAC) &&\n      gen._pushInt(2, MT.ARRAY))) {\n      return false\n    }\n\n    const dec = obj.decimalPlaces()\n    const slide = obj.multipliedBy(new Bignumber(10).pow(dec))\n    if (!gen._pushIntNum(-dec)) {\n      return false\n    }\n    if (slide.abs().isLessThan(MAXINT_BN)) {\n      return gen._pushIntNum(slide.toNumber())\n    } else {\n      return gen._pushBigint(slide)\n    }\n  }\n\n  _pushMap (gen, obj) {\n    if (!gen._pushInt(obj.size, MT.MAP)) {\n      return false\n    }\n\n    return this._pushRawMap(\n      obj.size,\n      Array.from(obj)\n    )\n  }\n\n  _pushObject (obj) {\n    if (!obj) {\n      return this._pushUInt8(NULL)\n    }\n\n    var len = this.semanticTypes.length\n    for (var i = 0; i < len; i++) {\n      if (obj instanceof this.semanticTypes[i][0]) {\n        return this.semanticTypes[i][1].call(obj, this, obj)\n      }\n    }\n\n    var f = obj.encodeCBOR\n    if (typeof f === 'function') {\n      return f.call(obj, this)\n    }\n\n    var keys = Object.keys(obj)\n    var keyLength = keys.length\n    if (!this._pushInt(keyLength, MT.MAP)) {\n      return false\n    }\n\n    return this._pushRawMap(\n      keyLength,\n      keys.map((k) => [k, obj[k]])\n    )\n  }\n\n  _pushRawMap (len, map) {\n    // Sort keys for canoncialization\n    // 1. encode key\n    // 2. shorter key comes before longer key\n    // 3. same length keys are sorted with lower\n    //    byte value before higher\n\n    map = map.map(function (a) {\n      a[0] = Encoder.encode(a[0])\n      return a\n    }).sort(utils.keySorter)\n\n    for (var j = 0; j < len; j++) {\n      if (!this.push(map[j][0])) {\n        return false\n      }\n\n      if (!this.pushAny(map[j][1])) {\n        return false\n      }\n    }\n\n    return true\n  }\n\n  /**\n   * Alias for `.pushAny`\n   *\n   * @param {*} obj\n   * @returns {boolean} true on success\n   */\n  write (obj) {\n    return this.pushAny(obj)\n  }\n\n  /**\n   * Push any supported type onto the encoded stream\n   *\n   * @param {any} obj\n   * @returns {boolean} true on success\n   */\n  pushAny (obj) {\n    var typ = toType(obj)\n\n    switch (typ) {\n      case 'Number':\n        return this._pushNumber(obj)\n      case 'String':\n        return this._pushString(obj)\n      case 'Boolean':\n        return this._pushBoolean(obj)\n      case 'Object':\n        return this._pushObject(obj)\n      case 'Array':\n        return this._pushArray(this, obj)\n      case 'Uint8Array':\n        return this._pushBuffer(this, Buffer.isBuffer(obj) ? obj : Buffer.from(obj))\n      case 'Null':\n        return this._pushUInt8(NULL)\n      case 'Undefined':\n        return this._pushUndefined(obj)\n      case 'Map':\n        return this._pushMap(this, obj)\n      case 'Set':\n        return this._pushSet(this, obj)\n      case 'URL':\n        return this._pushUrl(this, obj)\n      case 'BigNumber':\n        return this._pushBigNumber(this, obj)\n      case 'Date':\n        return this._pushDate(this, obj)\n      case 'RegExp':\n        return this._pushRegexp(this, obj)\n      case 'Symbol':\n        switch (obj) {\n          case SYMS.NULL:\n            return this._pushObject(null)\n          case SYMS.UNDEFINED:\n            return this._pushUndefined(undefined)\n          // TODO: Add pluggable support for other symbols\n          default:\n            throw new Error('Unknown symbol: ' + obj.toString())\n        }\n      default:\n        throw new Error('Unknown type: ' + typeof obj + ', ' + (obj ? obj.toString() : ''))\n    }\n  }\n\n  finalize () {\n    if (this.offset === 0) {\n      return null\n    }\n\n    var result = this.result\n    var resultLength = this.resultLength\n    var resultMethod = this.resultMethod\n    var offset = this.offset\n\n    // Determine the size of the buffer\n    var size = 0\n    var i = 0\n\n    for (; i < offset; i++) {\n      size += resultLength[i]\n    }\n\n    var res = Buffer.allocUnsafe(size)\n    var index = 0\n    var length = 0\n\n    // Write the content into the result buffer\n    for (i = 0; i < offset; i++) {\n      length = resultLength[i]\n\n      switch (resultMethod[i]) {\n        case 0:\n          result[i].copy(res, index)\n          break\n        case 1:\n          res.writeUInt8(result[i], index, true)\n          break\n        case 2:\n          res.writeUInt16BE(result[i], index, true)\n          break\n        case 3:\n          res.writeUInt32BE(result[i], index, true)\n          break\n        case 4:\n          res.writeDoubleBE(result[i], index, true)\n          break\n        case 5:\n          res.write(result[i], index, length, 'utf8')\n          break\n        default:\n          throw new Error('unkown method')\n      }\n\n      index += length\n    }\n\n    var tmp = res\n\n    this._reset()\n\n    return tmp\n  }\n\n  _reset () {\n    this.result = []\n    this.resultMethod = []\n    this.resultLength = []\n    this.offset = 0\n  }\n\n  /**\n   * Encode the given value\n   * @param {*} o\n   * @returns {Buffer}\n   */\n  static encode (o) {\n    const enc = new Encoder()\n    const ret = enc.pushAny(o)\n    if (!ret) {\n      throw new Error('Failed to encode input')\n    }\n\n    return enc.finalize()\n  }\n}\n\nmodule.exports = Encoder\n","/**\n * Implementation of the multicodec specification.\n *\n * @module multicodec\n * @example\n * const multicodec = require('multicodec')\n *\n * const prefixedProtobuf = multicodec.addPrefix('protobuf', protobufBuffer)\n * // prefixedProtobuf 0x50...\n *\n */\n'use strict'\n\n/** @typedef {import('./generated-types').CodecName} CodecName */\n/** @typedef {import('./generated-types').CodecCode} CodecCode */\n\nconst varint = require('varint')\nconst uint8ArrayConcat = require('uint8arrays/concat')\nconst util = require('./util')\nconst { nameToVarint, constantToCode, nameToCode, codeToName } = require('./maps')\n\n/**\n * Prefix a buffer with a multicodec-packed.\n *\n * @param {CodecName|Uint8Array} multicodecStrOrCode\n * @param {Uint8Array} data\n * @returns {Uint8Array}\n */\nfunction addPrefix (multicodecStrOrCode, data) {\n  let prefix\n\n  if (multicodecStrOrCode instanceof Uint8Array) {\n    prefix = util.varintUint8ArrayEncode(multicodecStrOrCode)\n  } else {\n    if (nameToVarint[multicodecStrOrCode]) {\n      prefix = nameToVarint[multicodecStrOrCode]\n    } else {\n      throw new Error('multicodec not recognized')\n    }\n  }\n\n  return uint8ArrayConcat([prefix, data], prefix.length + data.length)\n}\n\n/**\n * Decapsulate the multicodec-packed prefix from the data.\n *\n * @param {Uint8Array} data\n * @returns {Uint8Array}\n */\nfunction rmPrefix (data) {\n  varint.decode(/** @type {Buffer} */(data))\n  return data.slice(varint.decode.bytes)\n}\n\n/**\n * Get the codec name of the prefixed data.\n *\n * @param {Uint8Array} prefixedData\n * @returns {CodecName}\n */\nfunction getNameFromData (prefixedData) {\n  const code = /** @type {CodecCode} */(varint.decode(/** @type {Buffer} */(prefixedData)))\n  const name = codeToName[code]\n  if (name === undefined) {\n    throw new Error(`Code \"${code}\" not found`)\n  }\n  return name\n}\n\n/**\n * Get the codec name from a code.\n *\n * @param {CodecCode} codec\n * @returns {CodecName}\n */\nfunction getNameFromCode (codec) {\n  return codeToName[codec]\n}\n\n/**\n * Get the code of the codec\n *\n * @param {CodecName} name\n * @returns {CodecCode}\n */\nfunction getCodeFromName (name) {\n  const code = nameToCode[name]\n  if (code === undefined) {\n    throw new Error(`Codec \"${name}\" not found`)\n  }\n  return code\n}\n\n/**\n * Get the code of the prefixed data.\n *\n * @param {Uint8Array} prefixedData\n * @returns {CodecCode}\n */\nfunction getCodeFromData (prefixedData) {\n  return /** @type {CodecCode} */(varint.decode(/** @type {Buffer} */(prefixedData)))\n}\n\n/**\n * Get the code as varint of a codec name.\n *\n * @param {CodecName} name\n * @returns {Uint8Array}\n */\nfunction getVarintFromName (name) {\n  const code = nameToVarint[name]\n  if (code === undefined) {\n    throw new Error(`Codec \"${name}\" not found`)\n  }\n  return code\n}\n\n/**\n * Get the varint of a code.\n *\n * @param {CodecCode} code\n * @returns {Uint8Array}\n */\nfunction getVarintFromCode (code) {\n  return util.varintEncode(code)\n}\n\n/**\n * Get the codec name of the prefixed data.\n *\n * @deprecated use getNameFromData instead.\n * @param {Uint8Array} prefixedData\n * @returns {CodecName}\n */\nfunction getCodec (prefixedData) {\n  return getNameFromData(prefixedData)\n}\n\n/**\n * Get the codec name from a code.\n *\n * @deprecated use getNameFromCode instead.\n * @param {CodecCode} codec\n * @returns {CodecName}\n */\nfunction getName (codec) {\n  return getNameFromCode(codec)\n}\n\n/**\n * Get the code of the codec\n *\n * @deprecated use getCodeFromName instead.\n * @param {CodecName} name\n * @returns {CodecCode}\n */\nfunction getNumber (name) {\n  return getCodeFromName(name)\n}\n\n/**\n * Get the code of the prefixed data.\n *\n * @deprecated use getCodeFromData instead.\n * @param {Uint8Array} prefixedData\n * @returns {CodecCode}\n */\nfunction getCode (prefixedData) {\n  return getCodeFromData(prefixedData)\n}\n\n/**\n * Get the code as varint of a codec name.\n *\n * @deprecated use getVarintFromName instead.\n * @param {CodecName} name\n * @returns {Uint8Array}\n */\nfunction getCodeVarint (name) {\n  return getVarintFromName(name)\n}\n\n/**\n * Get the varint of a code.\n *\n * @deprecated use getVarintFromCode instead.\n * @param {CodecCode} code\n * @returns {Array.<number>}\n */\nfunction getVarint (code) {\n  return Array.from(getVarintFromCode(code))\n}\n\nmodule.exports = {\n  addPrefix,\n  rmPrefix,\n  getNameFromData,\n  getNameFromCode,\n  getCodeFromName,\n  getCodeFromData,\n  getVarintFromName,\n  getVarintFromCode,\n  // Deprecated\n  getCodec,\n  getName,\n  getNumber,\n  getCode,\n  getCodeVarint,\n  getVarint,\n  // Make the constants top-level constants\n  ...constantToCode,\n  // Export the maps\n  nameToVarint,\n  nameToCode,\n  codeToName\n}\n","'use strict'\n\nconst baseX = require('@multiformats/base-x')\nconst Base = require('./base.js')\nconst { rfc4648 } = require('./rfc4648')\nconst { decodeText, encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import('./types').Codec} Codec */\n/** @typedef {import('./types').BaseName} BaseName */\n/** @typedef {import('./types').BaseCode} BaseCode */\n\n/** @type {CodecFactory} */\nconst identity = () => {\n  return {\n    encode: decodeText,\n    decode: encodeText\n  }\n}\n\n/**\n *\n * name, code, implementation, alphabet\n *\n * @type {Array<[BaseName, BaseCode, CodecFactory, string]>}\n */\nconst constants = [\n  ['identity', '\\x00', identity, ''],\n  ['base2', '0', rfc4648(1), '01'],\n  ['base8', '7', rfc4648(3), '01234567'],\n  ['base10', '9', baseX, '0123456789'],\n  ['base16', 'f', rfc4648(4), '0123456789abcdef'],\n  ['base16upper', 'F', rfc4648(4), '0123456789ABCDEF'],\n  ['base32hex', 'v', rfc4648(5), '0123456789abcdefghijklmnopqrstuv'],\n  ['base32hexupper', 'V', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV'],\n  ['base32hexpad', 't', rfc4648(5), '0123456789abcdefghijklmnopqrstuv='],\n  ['base32hexpadupper', 'T', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV='],\n  ['base32', 'b', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567'],\n  ['base32upper', 'B', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'],\n  ['base32pad', 'c', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567='],\n  ['base32padupper', 'C', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567='],\n  ['base32z', 'h', rfc4648(5), 'ybndrfg8ejkmcpqxot1uwisza345h769'],\n  ['base36', 'k', baseX, '0123456789abcdefghijklmnopqrstuvwxyz'],\n  ['base36upper', 'K', baseX, '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'],\n  ['base58btc', 'z', baseX, '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'],\n  ['base58flickr', 'Z', baseX, '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'],\n  ['base64', 'm', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'],\n  ['base64pad', 'M', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/='],\n  ['base64url', 'u', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_'],\n  ['base64urlpad', 'U', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=']\n]\n\n/** @type {Record<BaseName,Base>} */\nconst names = constants.reduce((prev, tupple) => {\n  prev[tupple[0]] = new Base(tupple[0], tupple[1], tupple[2], tupple[3])\n  return prev\n}, /** @type {Record<BaseName,Base>} */({}))\n\n/** @type {Record<BaseCode,Base>} */\nconst codes = constants.reduce((prev, tupple) => {\n  prev[tupple[1]] = names[tupple[0]]\n  return prev\n}, /** @type {Record<BaseCode,Base>} */({}))\n\nmodule.exports = {\n  names,\n  codes\n}\n","'use strict'\n\nconst { encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import(\"./types\").BaseName} BaseName */\n/** @typedef {import(\"./types\").BaseCode} BaseCode */\n\n/**\n * Class to encode/decode in the supported Bases\n *\n */\nclass Base {\n  /**\n   * @param {BaseName} name\n   * @param {BaseCode} code\n   * @param {CodecFactory} factory\n   * @param {string} alphabet\n   */\n  constructor (name, code, factory, alphabet) {\n    this.name = name\n    this.code = code\n    this.codeBuf = encodeText(this.code)\n    this.alphabet = alphabet\n    this.codec = factory(alphabet)\n  }\n\n  /**\n   * @param {Uint8Array} buf\n   * @returns {string}\n   */\n  encode (buf) {\n    return this.codec.encode(buf)\n  }\n\n  /**\n   * @param {string} string\n   * @returns {Uint8Array}\n   */\n  decode (string) {\n    for (const char of string) {\n      if (this.alphabet && this.alphabet.indexOf(char) < 0) {\n        throw new Error(`invalid character '${char}' in '${string}'`)\n      }\n    }\n    return this.codec.decode(string)\n  }\n}\n\nmodule.exports = Base\n","'use strict'\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n\n/**\n * @param {string} string\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {Uint8Array}\n */\nconst decode = (string, alphabet, bitsPerChar) => {\n  // Build the character lookup table:\n  /** @type {Record<string, number>} */\n  const codes = {}\n  for (let i = 0; i < alphabet.length; ++i) {\n    codes[alphabet[i]] = i\n  }\n\n  // Count the padding bytes:\n  let end = string.length\n  while (string[end - 1] === '=') {\n    --end\n  }\n\n  // Allocate the output:\n  const out = new Uint8Array((end * bitsPerChar / 8) | 0)\n\n  // Parse the data:\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  let written = 0 // Next byte to write\n  for (let i = 0; i < end; ++i) {\n    // Read one character from the string:\n    const value = codes[string[i]]\n    if (value === undefined) {\n      throw new SyntaxError('Invalid character ' + string[i])\n    }\n\n    // Append the bits to the buffer:\n    buffer = (buffer << bitsPerChar) | value\n    bits += bitsPerChar\n\n    // Write out some bits if the buffer has a byte's worth:\n    if (bits >= 8) {\n      bits -= 8\n      out[written++] = 0xff & (buffer >> bits)\n    }\n  }\n\n  // Verify that we have received just enough bits:\n  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {\n    throw new SyntaxError('Unexpected end of data')\n  }\n\n  return out\n}\n\n/**\n * @param {Uint8Array} data\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {string}\n */\nconst encode = (data, alphabet, bitsPerChar) => {\n  const pad = alphabet[alphabet.length - 1] === '='\n  const mask = (1 << bitsPerChar) - 1\n  let out = ''\n\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  for (let i = 0; i < data.length; ++i) {\n    // Slurp data into the buffer:\n    buffer = (buffer << 8) | data[i]\n    bits += 8\n\n    // Write out as much as we can:\n    while (bits > bitsPerChar) {\n      bits -= bitsPerChar\n      out += alphabet[mask & (buffer >> bits)]\n    }\n  }\n\n  // Partial character:\n  if (bits) {\n    out += alphabet[mask & (buffer << (bitsPerChar - bits))]\n  }\n\n  // Add padding characters until we hit a byte boundary:\n  if (pad) {\n    while ((out.length * bitsPerChar) & 7) {\n      out += '='\n    }\n  }\n\n  return out\n}\n\n/**\n * RFC4648 Factory\n *\n * @param {number} bitsPerChar\n * @returns {CodecFactory}\n */\nconst rfc4648 = (bitsPerChar) => (alphabet) => {\n  return {\n    /**\n     * @param {Uint8Array} input\n     * @returns {string}\n     */\n    encode (input) {\n      return encode(input, alphabet, bitsPerChar)\n    },\n    /**\n     * @param {string} input\n     * @returns {Uint8Array}\n     */\n    decode (input) {\n      return decode(input, alphabet, bitsPerChar)\n    }\n  }\n}\n\nmodule.exports = { rfc4648 }\n","'use strict'\n\n/** @typedef {import('./generated-types').ConstantCodeMap} ConstantCodeMap */\n/** @typedef {import('./generated-types').NameUint8ArrayMap} NameUint8ArrayMap */\n/** @typedef {import('./generated-types').CodeNameMap} CodeNameMap */\n/** @typedef {import('./generated-types').CodecName} CodecName */\n/** @typedef {import('./generated-types').CodecConstant} CodecConstant */\n\nconst { baseTable } = require('./generated-table')\nconst varintEncode = require('./util').varintEncode\n\nconst nameToVarint = /** @type {NameUint8ArrayMap} */ ({})\nconst constantToCode = /** @type {ConstantCodeMap} */({})\nconst codeToName = /** @type {CodeNameMap} */({})\n\n// eslint-disable-next-line guard-for-in\nfor (const name in baseTable) {\n  const codecName = /** @type {CodecName} */(name)\n  const code = baseTable[codecName]\n  nameToVarint[codecName] = varintEncode(code)\n\n  const constant = /** @type {CodecConstant} */(codecName.toUpperCase().replace(/-/g, '_'))\n  constantToCode[constant] = code\n\n  if (!codeToName[code]) {\n    codeToName[code] = codecName\n  }\n}\n\nObject.freeze(nameToVarint)\nObject.freeze(constantToCode)\nObject.freeze(codeToName)\nconst nameToCode = Object.freeze(baseTable)\nmodule.exports = {\n  nameToVarint,\n  constantToCode,\n  nameToCode,\n  codeToName\n}\n","// DO NOT CHANGE THIS FILE. IT IS GENERATED BY tools/update-table.js\n/* eslint quote-props: off */\n'use strict'\n\n/**\n * @type {import('./generated-types').NameCodeMap}\n */\nconst baseTable = Object.freeze({\n  'identity': 0x00,\n  'cidv1': 0x01,\n  'cidv2': 0x02,\n  'cidv3': 0x03,\n  'ip4': 0x04,\n  'tcp': 0x06,\n  'sha1': 0x11,\n  'sha2-256': 0x12,\n  'sha2-512': 0x13,\n  'sha3-512': 0x14,\n  'sha3-384': 0x15,\n  'sha3-256': 0x16,\n  'sha3-224': 0x17,\n  'shake-128': 0x18,\n  'shake-256': 0x19,\n  'keccak-224': 0x1a,\n  'keccak-256': 0x1b,\n  'keccak-384': 0x1c,\n  'keccak-512': 0x1d,\n  'blake3': 0x1e,\n  'dccp': 0x21,\n  'murmur3-128': 0x22,\n  'murmur3-32': 0x23,\n  'ip6': 0x29,\n  'ip6zone': 0x2a,\n  'path': 0x2f,\n  'multicodec': 0x30,\n  'multihash': 0x31,\n  'multiaddr': 0x32,\n  'multibase': 0x33,\n  'dns': 0x35,\n  'dns4': 0x36,\n  'dns6': 0x37,\n  'dnsaddr': 0x38,\n  'protobuf': 0x50,\n  'cbor': 0x51,\n  'raw': 0x55,\n  'dbl-sha2-256': 0x56,\n  'rlp': 0x60,\n  'bencode': 0x63,\n  'dag-pb': 0x70,\n  'dag-cbor': 0x71,\n  'libp2p-key': 0x72,\n  'git-raw': 0x78,\n  'torrent-info': 0x7b,\n  'torrent-file': 0x7c,\n  'leofcoin-block': 0x81,\n  'leofcoin-tx': 0x82,\n  'leofcoin-pr': 0x83,\n  'sctp': 0x84,\n  'dag-jose': 0x85,\n  'dag-cose': 0x86,\n  'eth-block': 0x90,\n  'eth-block-list': 0x91,\n  'eth-tx-trie': 0x92,\n  'eth-tx': 0x93,\n  'eth-tx-receipt-trie': 0x94,\n  'eth-tx-receipt': 0x95,\n  'eth-state-trie': 0x96,\n  'eth-account-snapshot': 0x97,\n  'eth-storage-trie': 0x98,\n  'bitcoin-block': 0xb0,\n  'bitcoin-tx': 0xb1,\n  'bitcoin-witness-commitment': 0xb2,\n  'zcash-block': 0xc0,\n  'zcash-tx': 0xc1,\n  'docid': 0xce,\n  'stellar-block': 0xd0,\n  'stellar-tx': 0xd1,\n  'md4': 0xd4,\n  'md5': 0xd5,\n  'bmt': 0xd6,\n  'decred-block': 0xe0,\n  'decred-tx': 0xe1,\n  'ipld-ns': 0xe2,\n  'ipfs-ns': 0xe3,\n  'swarm-ns': 0xe4,\n  'ipns-ns': 0xe5,\n  'zeronet': 0xe6,\n  'secp256k1-pub': 0xe7,\n  'bls12_381-g1-pub': 0xea,\n  'bls12_381-g2-pub': 0xeb,\n  'x25519-pub': 0xec,\n  'ed25519-pub': 0xed,\n  'bls12_381-g1g2-pub': 0xee,\n  'dash-block': 0xf0,\n  'dash-tx': 0xf1,\n  'swarm-manifest': 0xfa,\n  'swarm-feed': 0xfb,\n  'udp': 0x0111,\n  'p2p-webrtc-star': 0x0113,\n  'p2p-webrtc-direct': 0x0114,\n  'p2p-stardust': 0x0115,\n  'p2p-circuit': 0x0122,\n  'dag-json': 0x0129,\n  'udt': 0x012d,\n  'utp': 0x012e,\n  'unix': 0x0190,\n  'thread': 0x0196,\n  'p2p': 0x01a5,\n  'ipfs': 0x01a5,\n  'https': 0x01bb,\n  'onion': 0x01bc,\n  'onion3': 0x01bd,\n  'garlic64': 0x01be,\n  'garlic32': 0x01bf,\n  'tls': 0x01c0,\n  'quic': 0x01cc,\n  'ws': 0x01dd,\n  'wss': 0x01de,\n  'p2p-websocket-star': 0x01df,\n  'http': 0x01e0,\n  'json': 0x0200,\n  'messagepack': 0x0201,\n  'libp2p-peer-record': 0x0301,\n  'sha2-256-trunc254-padded': 0x1012,\n  'ripemd-128': 0x1052,\n  'ripemd-160': 0x1053,\n  'ripemd-256': 0x1054,\n  'ripemd-320': 0x1055,\n  'x11': 0x1100,\n  'p256-pub': 0x1200,\n  'p384-pub': 0x1201,\n  'p521-pub': 0x1202,\n  'ed448-pub': 0x1203,\n  'x448-pub': 0x1204,\n  'ed25519-priv': 0x1300,\n  'kangarootwelve': 0x1d01,\n  'sm3-256': 0x534d,\n  'blake2b-8': 0xb201,\n  'blake2b-16': 0xb202,\n  'blake2b-24': 0xb203,\n  'blake2b-32': 0xb204,\n  'blake2b-40': 0xb205,\n  'blake2b-48': 0xb206,\n  'blake2b-56': 0xb207,\n  'blake2b-64': 0xb208,\n  'blake2b-72': 0xb209,\n  'blake2b-80': 0xb20a,\n  'blake2b-88': 0xb20b,\n  'blake2b-96': 0xb20c,\n  'blake2b-104': 0xb20d,\n  'blake2b-112': 0xb20e,\n  'blake2b-120': 0xb20f,\n  'blake2b-128': 0xb210,\n  'blake2b-136': 0xb211,\n  'blake2b-144': 0xb212,\n  'blake2b-152': 0xb213,\n  'blake2b-160': 0xb214,\n  'blake2b-168': 0xb215,\n  'blake2b-176': 0xb216,\n  'blake2b-184': 0xb217,\n  'blake2b-192': 0xb218,\n  'blake2b-200': 0xb219,\n  'blake2b-208': 0xb21a,\n  'blake2b-216': 0xb21b,\n  'blake2b-224': 0xb21c,\n  'blake2b-232': 0xb21d,\n  'blake2b-240': 0xb21e,\n  'blake2b-248': 0xb21f,\n  'blake2b-256': 0xb220,\n  'blake2b-264': 0xb221,\n  'blake2b-272': 0xb222,\n  'blake2b-280': 0xb223,\n  'blake2b-288': 0xb224,\n  'blake2b-296': 0xb225,\n  'blake2b-304': 0xb226,\n  'blake2b-312': 0xb227,\n  'blake2b-320': 0xb228,\n  'blake2b-328': 0xb229,\n  'blake2b-336': 0xb22a,\n  'blake2b-344': 0xb22b,\n  'blake2b-352': 0xb22c,\n  'blake2b-360': 0xb22d,\n  'blake2b-368': 0xb22e,\n  'blake2b-376': 0xb22f,\n  'blake2b-384': 0xb230,\n  'blake2b-392': 0xb231,\n  'blake2b-400': 0xb232,\n  'blake2b-408': 0xb233,\n  'blake2b-416': 0xb234,\n  'blake2b-424': 0xb235,\n  'blake2b-432': 0xb236,\n  'blake2b-440': 0xb237,\n  'blake2b-448': 0xb238,\n  'blake2b-456': 0xb239,\n  'blake2b-464': 0xb23a,\n  'blake2b-472': 0xb23b,\n  'blake2b-480': 0xb23c,\n  'blake2b-488': 0xb23d,\n  'blake2b-496': 0xb23e,\n  'blake2b-504': 0xb23f,\n  'blake2b-512': 0xb240,\n  'blake2s-8': 0xb241,\n  'blake2s-16': 0xb242,\n  'blake2s-24': 0xb243,\n  'blake2s-32': 0xb244,\n  'blake2s-40': 0xb245,\n  'blake2s-48': 0xb246,\n  'blake2s-56': 0xb247,\n  'blake2s-64': 0xb248,\n  'blake2s-72': 0xb249,\n  'blake2s-80': 0xb24a,\n  'blake2s-88': 0xb24b,\n  'blake2s-96': 0xb24c,\n  'blake2s-104': 0xb24d,\n  'blake2s-112': 0xb24e,\n  'blake2s-120': 0xb24f,\n  'blake2s-128': 0xb250,\n  'blake2s-136': 0xb251,\n  'blake2s-144': 0xb252,\n  'blake2s-152': 0xb253,\n  'blake2s-160': 0xb254,\n  'blake2s-168': 0xb255,\n  'blake2s-176': 0xb256,\n  'blake2s-184': 0xb257,\n  'blake2s-192': 0xb258,\n  'blake2s-200': 0xb259,\n  'blake2s-208': 0xb25a,\n  'blake2s-216': 0xb25b,\n  'blake2s-224': 0xb25c,\n  'blake2s-232': 0xb25d,\n  'blake2s-240': 0xb25e,\n  'blake2s-248': 0xb25f,\n  'blake2s-256': 0xb260,\n  'skein256-8': 0xb301,\n  'skein256-16': 0xb302,\n  'skein256-24': 0xb303,\n  'skein256-32': 0xb304,\n  'skein256-40': 0xb305,\n  'skein256-48': 0xb306,\n  'skein256-56': 0xb307,\n  'skein256-64': 0xb308,\n  'skein256-72': 0xb309,\n  'skein256-80': 0xb30a,\n  'skein256-88': 0xb30b,\n  'skein256-96': 0xb30c,\n  'skein256-104': 0xb30d,\n  'skein256-112': 0xb30e,\n  'skein256-120': 0xb30f,\n  'skein256-128': 0xb310,\n  'skein256-136': 0xb311,\n  'skein256-144': 0xb312,\n  'skein256-152': 0xb313,\n  'skein256-160': 0xb314,\n  'skein256-168': 0xb315,\n  'skein256-176': 0xb316,\n  'skein256-184': 0xb317,\n  'skein256-192': 0xb318,\n  'skein256-200': 0xb319,\n  'skein256-208': 0xb31a,\n  'skein256-216': 0xb31b,\n  'skein256-224': 0xb31c,\n  'skein256-232': 0xb31d,\n  'skein256-240': 0xb31e,\n  'skein256-248': 0xb31f,\n  'skein256-256': 0xb320,\n  'skein512-8': 0xb321,\n  'skein512-16': 0xb322,\n  'skein512-24': 0xb323,\n  'skein512-32': 0xb324,\n  'skein512-40': 0xb325,\n  'skein512-48': 0xb326,\n  'skein512-56': 0xb327,\n  'skein512-64': 0xb328,\n  'skein512-72': 0xb329,\n  'skein512-80': 0xb32a,\n  'skein512-88': 0xb32b,\n  'skein512-96': 0xb32c,\n  'skein512-104': 0xb32d,\n  'skein512-112': 0xb32e,\n  'skein512-120': 0xb32f,\n  'skein512-128': 0xb330,\n  'skein512-136': 0xb331,\n  'skein512-144': 0xb332,\n  'skein512-152': 0xb333,\n  'skein512-160': 0xb334,\n  'skein512-168': 0xb335,\n  'skein512-176': 0xb336,\n  'skein512-184': 0xb337,\n  'skein512-192': 0xb338,\n  'skein512-200': 0xb339,\n  'skein512-208': 0xb33a,\n  'skein512-216': 0xb33b,\n  'skein512-224': 0xb33c,\n  'skein512-232': 0xb33d,\n  'skein512-240': 0xb33e,\n  'skein512-248': 0xb33f,\n  'skein512-256': 0xb340,\n  'skein512-264': 0xb341,\n  'skein512-272': 0xb342,\n  'skein512-280': 0xb343,\n  'skein512-288': 0xb344,\n  'skein512-296': 0xb345,\n  'skein512-304': 0xb346,\n  'skein512-312': 0xb347,\n  'skein512-320': 0xb348,\n  'skein512-328': 0xb349,\n  'skein512-336': 0xb34a,\n  'skein512-344': 0xb34b,\n  'skein512-352': 0xb34c,\n  'skein512-360': 0xb34d,\n  'skein512-368': 0xb34e,\n  'skein512-376': 0xb34f,\n  'skein512-384': 0xb350,\n  'skein512-392': 0xb351,\n  'skein512-400': 0xb352,\n  'skein512-408': 0xb353,\n  'skein512-416': 0xb354,\n  'skein512-424': 0xb355,\n  'skein512-432': 0xb356,\n  'skein512-440': 0xb357,\n  'skein512-448': 0xb358,\n  'skein512-456': 0xb359,\n  'skein512-464': 0xb35a,\n  'skein512-472': 0xb35b,\n  'skein512-480': 0xb35c,\n  'skein512-488': 0xb35d,\n  'skein512-496': 0xb35e,\n  'skein512-504': 0xb35f,\n  'skein512-512': 0xb360,\n  'skein1024-8': 0xb361,\n  'skein1024-16': 0xb362,\n  'skein1024-24': 0xb363,\n  'skein1024-32': 0xb364,\n  'skein1024-40': 0xb365,\n  'skein1024-48': 0xb366,\n  'skein1024-56': 0xb367,\n  'skein1024-64': 0xb368,\n  'skein1024-72': 0xb369,\n  'skein1024-80': 0xb36a,\n  'skein1024-88': 0xb36b,\n  'skein1024-96': 0xb36c,\n  'skein1024-104': 0xb36d,\n  'skein1024-112': 0xb36e,\n  'skein1024-120': 0xb36f,\n  'skein1024-128': 0xb370,\n  'skein1024-136': 0xb371,\n  'skein1024-144': 0xb372,\n  'skein1024-152': 0xb373,\n  'skein1024-160': 0xb374,\n  'skein1024-168': 0xb375,\n  'skein1024-176': 0xb376,\n  'skein1024-184': 0xb377,\n  'skein1024-192': 0xb378,\n  'skein1024-200': 0xb379,\n  'skein1024-208': 0xb37a,\n  'skein1024-216': 0xb37b,\n  'skein1024-224': 0xb37c,\n  'skein1024-232': 0xb37d,\n  'skein1024-240': 0xb37e,\n  'skein1024-248': 0xb37f,\n  'skein1024-256': 0xb380,\n  'skein1024-264': 0xb381,\n  'skein1024-272': 0xb382,\n  'skein1024-280': 0xb383,\n  'skein1024-288': 0xb384,\n  'skein1024-296': 0xb385,\n  'skein1024-304': 0xb386,\n  'skein1024-312': 0xb387,\n  'skein1024-320': 0xb388,\n  'skein1024-328': 0xb389,\n  'skein1024-336': 0xb38a,\n  'skein1024-344': 0xb38b,\n  'skein1024-352': 0xb38c,\n  'skein1024-360': 0xb38d,\n  'skein1024-368': 0xb38e,\n  'skein1024-376': 0xb38f,\n  'skein1024-384': 0xb390,\n  'skein1024-392': 0xb391,\n  'skein1024-400': 0xb392,\n  'skein1024-408': 0xb393,\n  'skein1024-416': 0xb394,\n  'skein1024-424': 0xb395,\n  'skein1024-432': 0xb396,\n  'skein1024-440': 0xb397,\n  'skein1024-448': 0xb398,\n  'skein1024-456': 0xb399,\n  'skein1024-464': 0xb39a,\n  'skein1024-472': 0xb39b,\n  'skein1024-480': 0xb39c,\n  'skein1024-488': 0xb39d,\n  'skein1024-496': 0xb39e,\n  'skein1024-504': 0xb39f,\n  'skein1024-512': 0xb3a0,\n  'skein1024-520': 0xb3a1,\n  'skein1024-528': 0xb3a2,\n  'skein1024-536': 0xb3a3,\n  'skein1024-544': 0xb3a4,\n  'skein1024-552': 0xb3a5,\n  'skein1024-560': 0xb3a6,\n  'skein1024-568': 0xb3a7,\n  'skein1024-576': 0xb3a8,\n  'skein1024-584': 0xb3a9,\n  'skein1024-592': 0xb3aa,\n  'skein1024-600': 0xb3ab,\n  'skein1024-608': 0xb3ac,\n  'skein1024-616': 0xb3ad,\n  'skein1024-624': 0xb3ae,\n  'skein1024-632': 0xb3af,\n  'skein1024-640': 0xb3b0,\n  'skein1024-648': 0xb3b1,\n  'skein1024-656': 0xb3b2,\n  'skein1024-664': 0xb3b3,\n  'skein1024-672': 0xb3b4,\n  'skein1024-680': 0xb3b5,\n  'skein1024-688': 0xb3b6,\n  'skein1024-696': 0xb3b7,\n  'skein1024-704': 0xb3b8,\n  'skein1024-712': 0xb3b9,\n  'skein1024-720': 0xb3ba,\n  'skein1024-728': 0xb3bb,\n  'skein1024-736': 0xb3bc,\n  'skein1024-744': 0xb3bd,\n  'skein1024-752': 0xb3be,\n  'skein1024-760': 0xb3bf,\n  'skein1024-768': 0xb3c0,\n  'skein1024-776': 0xb3c1,\n  'skein1024-784': 0xb3c2,\n  'skein1024-792': 0xb3c3,\n  'skein1024-800': 0xb3c4,\n  'skein1024-808': 0xb3c5,\n  'skein1024-816': 0xb3c6,\n  'skein1024-824': 0xb3c7,\n  'skein1024-832': 0xb3c8,\n  'skein1024-840': 0xb3c9,\n  'skein1024-848': 0xb3ca,\n  'skein1024-856': 0xb3cb,\n  'skein1024-864': 0xb3cc,\n  'skein1024-872': 0xb3cd,\n  'skein1024-880': 0xb3ce,\n  'skein1024-888': 0xb3cf,\n  'skein1024-896': 0xb3d0,\n  'skein1024-904': 0xb3d1,\n  'skein1024-912': 0xb3d2,\n  'skein1024-920': 0xb3d3,\n  'skein1024-928': 0xb3d4,\n  'skein1024-936': 0xb3d5,\n  'skein1024-944': 0xb3d6,\n  'skein1024-952': 0xb3d7,\n  'skein1024-960': 0xb3d8,\n  'skein1024-968': 0xb3d9,\n  'skein1024-976': 0xb3da,\n  'skein1024-984': 0xb3db,\n  'skein1024-992': 0xb3dc,\n  'skein1024-1000': 0xb3dd,\n  'skein1024-1008': 0xb3de,\n  'skein1024-1016': 0xb3df,\n  'skein1024-1024': 0xb3e0,\n  'poseidon-bls12_381-a2-fc1': 0xb401,\n  'poseidon-bls12_381-a2-fc1-sc': 0xb402,\n  'zeroxcert-imprint-256': 0xce11,\n  'fil-commitment-unsealed': 0xf101,\n  'fil-commitment-sealed': 0xf102,\n  'holochain-adr-v0': 0x807124,\n  'holochain-adr-v1': 0x817124,\n  'holochain-key-v0': 0x947124,\n  'holochain-key-v1': 0x957124,\n  'holochain-sig-v0': 0xa27124,\n  'holochain-sig-v1': 0xa37124,\n  'skynet-ns': 0xb19910\n})\n\nmodule.exports = { baseTable }\n","'use strict'\n\nconst errcode = require('err-code')\nconst multihash = require('multihashes')\nconst crypto = require('./crypto')\nconst equals = require('uint8arrays/equals')\n\n/**\n * @typedef {import(\"./types\").Digest} Digest\n * @typedef {import(\"multihashes\").HashName} HashName\n */\n\n/**\n * Hash the given `bytes` using the algorithm specified by `alg`.\n *\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nasync function Multihashing (bytes, alg, length) {\n  const digest = await Multihashing.digest(bytes, alg, length)\n  return multihash.encode(digest, alg, length)\n}\n\n/**\n * Expose multihash itself, to avoid silly double requires.\n */\nMultihashing.multihash = multihash\n\n/**\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nMultihashing.digest = async (bytes, alg, length) => {\n  const hash = Multihashing.createHash(alg)\n  const digest = await hash(bytes)\n  return length ? digest.slice(0, length) : digest\n}\n\n/**\n * Creates a function that hashes with the given algorithm\n *\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @returns {Digest} - The hash function corresponding to `alg`\n */\nMultihashing.createHash = function (alg) {\n  if (!alg) {\n    const e = errcode(new Error('hash algorithm must be specified'), 'ERR_HASH_ALGORITHM_NOT_SPECIFIED')\n    throw e\n  }\n\n  const code = multihash.coerceCode(alg)\n  if (!Multihashing.functions[code]) {\n    throw errcode(new Error(`multihash function '${alg}' not yet supported`), 'ERR_HASH_ALGORITHM_NOT_SUPPORTED')\n  }\n\n  return Multihashing.functions[code]\n}\n\n/**\n * Mapping of multihash codes to their hashing functions.\n *\n * @type {Record<number, Digest>}\n */\n// @ts-ignore - most of those functions aren't typed\nMultihashing.functions = {\n  // identity\n  0x00: crypto.identity,\n  // sha1\n  0x11: crypto.sha1,\n  // sha2-256\n  0x12: crypto.sha2256,\n  // sha2-512\n  0x13: crypto.sha2512,\n  // sha3-512\n  0x14: crypto.sha3512,\n  // sha3-384\n  0x15: crypto.sha3384,\n  // sha3-256\n  0x16: crypto.sha3256,\n  // sha3-224\n  0x17: crypto.sha3224,\n  // shake-128\n  0x18: crypto.shake128,\n  // shake-256\n  0x19: crypto.shake256,\n  // keccak-224\n  0x1A: crypto.keccak224,\n  // keccak-256\n  0x1B: crypto.keccak256,\n  // keccak-384\n  0x1C: crypto.keccak384,\n  // keccak-512\n  0x1D: crypto.keccak512,\n  // murmur3-128\n  0x22: crypto.murmur3128,\n  // murmur3-32\n  0x23: crypto.murmur332,\n  // dbl-sha2-256\n  0x56: crypto.dblSha2256\n}\n\n// add blake functions\ncrypto.addBlake(Multihashing.functions)\n\n/**\n * @param {Uint8Array} bytes\n * @param {Uint8Array} hash\n * @returns {Promise<boolean>}\n */\nMultihashing.validate = async (bytes, hash) => {\n  const newHash = await Multihashing(bytes, multihash.decode(hash).name)\n\n  return equals(hash, newHash)\n}\n\nmodule.exports = Multihashing\n","'use strict';\n\n/**\n * @typedef {{ [key: string]: any }} Extensions\n * @typedef {Error} Err\n * @property {string} message\n */\n\n/**\n *\n * @param {Error} obj\n * @param {Extensions} props\n * @returns {Error & Extensions}\n */\nfunction assign(obj, props) {\n    for (const key in props) {\n        Object.defineProperty(obj, key, {\n            value: props[key],\n            enumerable: true,\n            configurable: true,\n        });\n    }\n\n    return obj;\n}\n\n/**\n *\n * @param {any} err - An Error\n * @param {string|Extensions} code - A string code or props to set on the error\n * @param {Extensions} [props] - Props to set on the error\n * @returns {Error & Extensions}\n */\nfunction createError(err, code, props) {\n    if (!err || typeof err === 'string') {\n        throw new TypeError('Please pass an Error to err-code');\n    }\n\n    if (!props) {\n        props = {};\n    }\n\n    if (typeof code === 'object') {\n        props = code;\n        code = '';\n    }\n\n    if (code) {\n        props.code = code;\n    }\n\n    try {\n        return assign(err, props);\n    } catch (_) {\n        props.message = err.message;\n        props.stack = err.stack;\n\n        const ErrClass = function () {};\n\n        ErrClass.prototype = Object.create(Object.getPrototypeOf(err));\n\n        // @ts-ignore\n        const output = assign(new ErrClass(), props);\n\n        return output;\n    }\n}\n\nmodule.exports = createError;\n","/* eslint quote-props: off */\n'use strict'\n\n/**\n * Names for all available hashes\n *\n * @typedef { \"identity\" | \"sha1\" | \"sha2-256\" | \"sha2-512\" | \"sha3-512\" | \"sha3-384\" | \"sha3-256\" | \"sha3-224\" | \"shake-128\" | \"shake-256\" | \"keccak-224\" | \"keccak-256\" | \"keccak-384\" | \"keccak-512\" | \"blake3\" | \"murmur3-128\" | \"murmur3-32\" | \"dbl-sha2-256\" | \"md4\" | \"md5\" | \"bmt\" | \"sha2-256-trunc254-padded\" | \"ripemd-128\" | \"ripemd-160\" | \"ripemd-256\" | \"ripemd-320\" | \"x11\" | \"kangarootwelve\" | \"sm3-256\" | \"blake2b-8\" | \"blake2b-16\" | \"blake2b-24\" | \"blake2b-32\" | \"blake2b-40\" | \"blake2b-48\" | \"blake2b-56\" | \"blake2b-64\" | \"blake2b-72\" | \"blake2b-80\" | \"blake2b-88\" | \"blake2b-96\" | \"blake2b-104\" | \"blake2b-112\" | \"blake2b-120\" | \"blake2b-128\" | \"blake2b-136\" | \"blake2b-144\" | \"blake2b-152\" | \"blake2b-160\" | \"blake2b-168\" | \"blake2b-176\" | \"blake2b-184\" | \"blake2b-192\" | \"blake2b-200\" | \"blake2b-208\" | \"blake2b-216\" | \"blake2b-224\" | \"blake2b-232\" | \"blake2b-240\" | \"blake2b-248\" | \"blake2b-256\" | \"blake2b-264\" | \"blake2b-272\" | \"blake2b-280\" | \"blake2b-288\" | \"blake2b-296\" | \"blake2b-304\" | \"blake2b-312\" | \"blake2b-320\" | \"blake2b-328\" | \"blake2b-336\" | \"blake2b-344\" | \"blake2b-352\" | \"blake2b-360\" | \"blake2b-368\" | \"blake2b-376\" | \"blake2b-384\" | \"blake2b-392\" | \"blake2b-400\" | \"blake2b-408\" | \"blake2b-416\" | \"blake2b-424\" | \"blake2b-432\" | \"blake2b-440\" | \"blake2b-448\" | \"blake2b-456\" | \"blake2b-464\" | \"blake2b-472\" | \"blake2b-480\" | \"blake2b-488\" | \"blake2b-496\" | \"blake2b-504\" | \"blake2b-512\" | \"blake2s-8\" | \"blake2s-16\" | \"blake2s-24\" | \"blake2s-32\" | \"blake2s-40\" | \"blake2s-48\" | \"blake2s-56\" | \"blake2s-64\" | \"blake2s-72\" | \"blake2s-80\" | \"blake2s-88\" | \"blake2s-96\" | \"blake2s-104\" | \"blake2s-112\" | \"blake2s-120\" | \"blake2s-128\" | \"blake2s-136\" | \"blake2s-144\" | \"blake2s-152\" | \"blake2s-160\" | \"blake2s-168\" | \"blake2s-176\" | \"blake2s-184\" | \"blake2s-192\" | \"blake2s-200\" | \"blake2s-208\" | \"blake2s-216\" | \"blake2s-224\" | \"blake2s-232\" | \"blake2s-240\" | \"blake2s-248\" | \"blake2s-256\" | \"skein256-8\" | \"skein256-16\" | \"skein256-24\" | \"skein256-32\" | \"skein256-40\" | \"skein256-48\" | \"skein256-56\" | \"skein256-64\" | \"skein256-72\" | \"skein256-80\" | \"skein256-88\" | \"skein256-96\" | \"skein256-104\" | \"skein256-112\" | \"skein256-120\" | \"skein256-128\" | \"skein256-136\" | \"skein256-144\" | \"skein256-152\" | \"skein256-160\" | \"skein256-168\" | \"skein256-176\" | \"skein256-184\" | \"skein256-192\" | \"skein256-200\" | \"skein256-208\" | \"skein256-216\" | \"skein256-224\" | \"skein256-232\" | \"skein256-240\" | \"skein256-248\" | \"skein256-256\" | \"skein512-8\" | \"skein512-16\" | \"skein512-24\" | \"skein512-32\" | \"skein512-40\" | \"skein512-48\" | \"skein512-56\" | \"skein512-64\" | \"skein512-72\" | \"skein512-80\" | \"skein512-88\" | \"skein512-96\" | \"skein512-104\" | \"skein512-112\" | \"skein512-120\" | \"skein512-128\" | \"skein512-136\" | \"skein512-144\" | \"skein512-152\" | \"skein512-160\" | \"skein512-168\" | \"skein512-176\" | \"skein512-184\" | \"skein512-192\" | \"skein512-200\" | \"skein512-208\" | \"skein512-216\" | \"skein512-224\" | \"skein512-232\" | \"skein512-240\" | \"skein512-248\" | \"skein512-256\" | \"skein512-264\" | \"skein512-272\" | \"skein512-280\" | \"skein512-288\" | \"skein512-296\" | \"skein512-304\" | \"skein512-312\" | \"skein512-320\" | \"skein512-328\" | \"skein512-336\" | \"skein512-344\" | \"skein512-352\" | \"skein512-360\" | \"skein512-368\" | \"skein512-376\" | \"skein512-384\" | \"skein512-392\" | \"skein512-400\" | \"skein512-408\" | \"skein512-416\" | \"skein512-424\" | \"skein512-432\" | \"skein512-440\" | \"skein512-448\" | \"skein512-456\" | \"skein512-464\" | \"skein512-472\" | \"skein512-480\" | \"skein512-488\" | \"skein512-496\" | \"skein512-504\" | \"skein512-512\" | \"skein1024-8\" | \"skein1024-16\" | \"skein1024-24\" | \"skein1024-32\" | \"skein1024-40\" | \"skein1024-48\" | \"skein1024-56\" | \"skein1024-64\" | \"skein1024-72\" | \"skein1024-80\" | \"skein1024-88\" | \"skein1024-96\" | \"skein1024-104\" | \"skein1024-112\" | \"skein1024-120\" | \"skein1024-128\" | \"skein1024-136\" | \"skein1024-144\" | \"skein1024-152\" | \"skein1024-160\" | \"skein1024-168\" | \"skein1024-176\" | \"skein1024-184\" | \"skein1024-192\" | \"skein1024-200\" | \"skein1024-208\" | \"skein1024-216\" | \"skein1024-224\" | \"skein1024-232\" | \"skein1024-240\" | \"skein1024-248\" | \"skein1024-256\" | \"skein1024-264\" | \"skein1024-272\" | \"skein1024-280\" | \"skein1024-288\" | \"skein1024-296\" | \"skein1024-304\" | \"skein1024-312\" | \"skein1024-320\" | \"skein1024-328\" | \"skein1024-336\" | \"skein1024-344\" | \"skein1024-352\" | \"skein1024-360\" | \"skein1024-368\" | \"skein1024-376\" | \"skein1024-384\" | \"skein1024-392\" | \"skein1024-400\" | \"skein1024-408\" | \"skein1024-416\" | \"skein1024-424\" | \"skein1024-432\" | \"skein1024-440\" | \"skein1024-448\" | \"skein1024-456\" | \"skein1024-464\" | \"skein1024-472\" | \"skein1024-480\" | \"skein1024-488\" | \"skein1024-496\" | \"skein1024-504\" | \"skein1024-512\" | \"skein1024-520\" | \"skein1024-528\" | \"skein1024-536\" | \"skein1024-544\" | \"skein1024-552\" | \"skein1024-560\" | \"skein1024-568\" | \"skein1024-576\" | \"skein1024-584\" | \"skein1024-592\" | \"skein1024-600\" | \"skein1024-608\" | \"skein1024-616\" | \"skein1024-624\" | \"skein1024-632\" | \"skein1024-640\" | \"skein1024-648\" | \"skein1024-656\" | \"skein1024-664\" | \"skein1024-672\" | \"skein1024-680\" | \"skein1024-688\" | \"skein1024-696\" | \"skein1024-704\" | \"skein1024-712\" | \"skein1024-720\" | \"skein1024-728\" | \"skein1024-736\" | \"skein1024-744\" | \"skein1024-752\" | \"skein1024-760\" | \"skein1024-768\" | \"skein1024-776\" | \"skein1024-784\" | \"skein1024-792\" | \"skein1024-800\" | \"skein1024-808\" | \"skein1024-816\" | \"skein1024-824\" | \"skein1024-832\" | \"skein1024-840\" | \"skein1024-848\" | \"skein1024-856\" | \"skein1024-864\" | \"skein1024-872\" | \"skein1024-880\" | \"skein1024-888\" | \"skein1024-896\" | \"skein1024-904\" | \"skein1024-912\" | \"skein1024-920\" | \"skein1024-928\" | \"skein1024-936\" | \"skein1024-944\" | \"skein1024-952\" | \"skein1024-960\" | \"skein1024-968\" | \"skein1024-976\" | \"skein1024-984\" | \"skein1024-992\" | \"skein1024-1000\" | \"skein1024-1008\" | \"skein1024-1016\" | \"skein1024-1024\" | \"poseidon-bls12_381-a2-fc1\" | \"poseidon-bls12_381-a2-fc1-sc\" } HashName\n */\n/**\n * Codes for all available hashes\n *\n * @typedef { 0x00 | 0x11 | 0x12 | 0x13 | 0x14 | 0x15 | 0x16 | 0x17 | 0x18 | 0x19 | 0x1a | 0x1b | 0x1c | 0x1d | 0x1e | 0x22 | 0x23 | 0x56 | 0xd4 | 0xd5 | 0xd6 | 0x1012 | 0x1052 | 0x1053 | 0x1054 | 0x1055 | 0x1100 | 0x1d01 | 0x534d | 0xb201 | 0xb202 | 0xb203 | 0xb204 | 0xb205 | 0xb206 | 0xb207 | 0xb208 | 0xb209 | 0xb20a | 0xb20b | 0xb20c | 0xb20d | 0xb20e | 0xb20f | 0xb210 | 0xb211 | 0xb212 | 0xb213 | 0xb214 | 0xb215 | 0xb216 | 0xb217 | 0xb218 | 0xb219 | 0xb21a | 0xb21b | 0xb21c | 0xb21d | 0xb21e | 0xb21f | 0xb220 | 0xb221 | 0xb222 | 0xb223 | 0xb224 | 0xb225 | 0xb226 | 0xb227 | 0xb228 | 0xb229 | 0xb22a | 0xb22b | 0xb22c | 0xb22d | 0xb22e | 0xb22f | 0xb230 | 0xb231 | 0xb232 | 0xb233 | 0xb234 | 0xb235 | 0xb236 | 0xb237 | 0xb238 | 0xb239 | 0xb23a | 0xb23b | 0xb23c | 0xb23d | 0xb23e | 0xb23f | 0xb240 | 0xb241 | 0xb242 | 0xb243 | 0xb244 | 0xb245 | 0xb246 | 0xb247 | 0xb248 | 0xb249 | 0xb24a | 0xb24b | 0xb24c | 0xb24d | 0xb24e | 0xb24f | 0xb250 | 0xb251 | 0xb252 | 0xb253 | 0xb254 | 0xb255 | 0xb256 | 0xb257 | 0xb258 | 0xb259 | 0xb25a | 0xb25b | 0xb25c | 0xb25d | 0xb25e | 0xb25f | 0xb260 | 0xb301 | 0xb302 | 0xb303 | 0xb304 | 0xb305 | 0xb306 | 0xb307 | 0xb308 | 0xb309 | 0xb30a | 0xb30b | 0xb30c | 0xb30d | 0xb30e | 0xb30f | 0xb310 | 0xb311 | 0xb312 | 0xb313 | 0xb314 | 0xb315 | 0xb316 | 0xb317 | 0xb318 | 0xb319 | 0xb31a | 0xb31b | 0xb31c | 0xb31d | 0xb31e | 0xb31f | 0xb320 | 0xb321 | 0xb322 | 0xb323 | 0xb324 | 0xb325 | 0xb326 | 0xb327 | 0xb328 | 0xb329 | 0xb32a | 0xb32b | 0xb32c | 0xb32d | 0xb32e | 0xb32f | 0xb330 | 0xb331 | 0xb332 | 0xb333 | 0xb334 | 0xb335 | 0xb336 | 0xb337 | 0xb338 | 0xb339 | 0xb33a | 0xb33b | 0xb33c | 0xb33d | 0xb33e | 0xb33f | 0xb340 | 0xb341 | 0xb342 | 0xb343 | 0xb344 | 0xb345 | 0xb346 | 0xb347 | 0xb348 | 0xb349 | 0xb34a | 0xb34b | 0xb34c | 0xb34d | 0xb34e | 0xb34f | 0xb350 | 0xb351 | 0xb352 | 0xb353 | 0xb354 | 0xb355 | 0xb356 | 0xb357 | 0xb358 | 0xb359 | 0xb35a | 0xb35b | 0xb35c | 0xb35d | 0xb35e | 0xb35f | 0xb360 | 0xb361 | 0xb362 | 0xb363 | 0xb364 | 0xb365 | 0xb366 | 0xb367 | 0xb368 | 0xb369 | 0xb36a | 0xb36b | 0xb36c | 0xb36d | 0xb36e | 0xb36f | 0xb370 | 0xb371 | 0xb372 | 0xb373 | 0xb374 | 0xb375 | 0xb376 | 0xb377 | 0xb378 | 0xb379 | 0xb37a | 0xb37b | 0xb37c | 0xb37d | 0xb37e | 0xb37f | 0xb380 | 0xb381 | 0xb382 | 0xb383 | 0xb384 | 0xb385 | 0xb386 | 0xb387 | 0xb388 | 0xb389 | 0xb38a | 0xb38b | 0xb38c | 0xb38d | 0xb38e | 0xb38f | 0xb390 | 0xb391 | 0xb392 | 0xb393 | 0xb394 | 0xb395 | 0xb396 | 0xb397 | 0xb398 | 0xb399 | 0xb39a | 0xb39b | 0xb39c | 0xb39d | 0xb39e | 0xb39f | 0xb3a0 | 0xb3a1 | 0xb3a2 | 0xb3a3 | 0xb3a4 | 0xb3a5 | 0xb3a6 | 0xb3a7 | 0xb3a8 | 0xb3a9 | 0xb3aa | 0xb3ab | 0xb3ac | 0xb3ad | 0xb3ae | 0xb3af | 0xb3b0 | 0xb3b1 | 0xb3b2 | 0xb3b3 | 0xb3b4 | 0xb3b5 | 0xb3b6 | 0xb3b7 | 0xb3b8 | 0xb3b9 | 0xb3ba | 0xb3bb | 0xb3bc | 0xb3bd | 0xb3be | 0xb3bf | 0xb3c0 | 0xb3c1 | 0xb3c2 | 0xb3c3 | 0xb3c4 | 0xb3c5 | 0xb3c6 | 0xb3c7 | 0xb3c8 | 0xb3c9 | 0xb3ca | 0xb3cb | 0xb3cc | 0xb3cd | 0xb3ce | 0xb3cf | 0xb3d0 | 0xb3d1 | 0xb3d2 | 0xb3d3 | 0xb3d4 | 0xb3d5 | 0xb3d6 | 0xb3d7 | 0xb3d8 | 0xb3d9 | 0xb3da | 0xb3db | 0xb3dc | 0xb3dd | 0xb3de | 0xb3df | 0xb3e0 | 0xb401 | 0xb402 } HashCode\n */\n\n/**\n * @type { Record<HashName,HashCode> }\n */\nconst names = Object.freeze({\n  'identity': 0x00,\n  'sha1': 0x11,\n  'sha2-256': 0x12,\n  'sha2-512': 0x13,\n  'sha3-512': 0x14,\n  'sha3-384': 0x15,\n  'sha3-256': 0x16,\n  'sha3-224': 0x17,\n  'shake-128': 0x18,\n  'shake-256': 0x19,\n  'keccak-224': 0x1a,\n  'keccak-256': 0x1b,\n  'keccak-384': 0x1c,\n  'keccak-512': 0x1d,\n  'blake3': 0x1e,\n  'murmur3-128': 0x22,\n  'murmur3-32': 0x23,\n  'dbl-sha2-256': 0x56,\n  'md4': 0xd4,\n  'md5': 0xd5,\n  'bmt': 0xd6,\n  'sha2-256-trunc254-padded': 0x1012,\n  'ripemd-128': 0x1052,\n  'ripemd-160': 0x1053,\n  'ripemd-256': 0x1054,\n  'ripemd-320': 0x1055,\n  'x11': 0x1100,\n  'kangarootwelve': 0x1d01,\n  'sm3-256': 0x534d,\n  'blake2b-8': 0xb201,\n  'blake2b-16': 0xb202,\n  'blake2b-24': 0xb203,\n  'blake2b-32': 0xb204,\n  'blake2b-40': 0xb205,\n  'blake2b-48': 0xb206,\n  'blake2b-56': 0xb207,\n  'blake2b-64': 0xb208,\n  'blake2b-72': 0xb209,\n  'blake2b-80': 0xb20a,\n  'blake2b-88': 0xb20b,\n  'blake2b-96': 0xb20c,\n  'blake2b-104': 0xb20d,\n  'blake2b-112': 0xb20e,\n  'blake2b-120': 0xb20f,\n  'blake2b-128': 0xb210,\n  'blake2b-136': 0xb211,\n  'blake2b-144': 0xb212,\n  'blake2b-152': 0xb213,\n  'blake2b-160': 0xb214,\n  'blake2b-168': 0xb215,\n  'blake2b-176': 0xb216,\n  'blake2b-184': 0xb217,\n  'blake2b-192': 0xb218,\n  'blake2b-200': 0xb219,\n  'blake2b-208': 0xb21a,\n  'blake2b-216': 0xb21b,\n  'blake2b-224': 0xb21c,\n  'blake2b-232': 0xb21d,\n  'blake2b-240': 0xb21e,\n  'blake2b-248': 0xb21f,\n  'blake2b-256': 0xb220,\n  'blake2b-264': 0xb221,\n  'blake2b-272': 0xb222,\n  'blake2b-280': 0xb223,\n  'blake2b-288': 0xb224,\n  'blake2b-296': 0xb225,\n  'blake2b-304': 0xb226,\n  'blake2b-312': 0xb227,\n  'blake2b-320': 0xb228,\n  'blake2b-328': 0xb229,\n  'blake2b-336': 0xb22a,\n  'blake2b-344': 0xb22b,\n  'blake2b-352': 0xb22c,\n  'blake2b-360': 0xb22d,\n  'blake2b-368': 0xb22e,\n  'blake2b-376': 0xb22f,\n  'blake2b-384': 0xb230,\n  'blake2b-392': 0xb231,\n  'blake2b-400': 0xb232,\n  'blake2b-408': 0xb233,\n  'blake2b-416': 0xb234,\n  'blake2b-424': 0xb235,\n  'blake2b-432': 0xb236,\n  'blake2b-440': 0xb237,\n  'blake2b-448': 0xb238,\n  'blake2b-456': 0xb239,\n  'blake2b-464': 0xb23a,\n  'blake2b-472': 0xb23b,\n  'blake2b-480': 0xb23c,\n  'blake2b-488': 0xb23d,\n  'blake2b-496': 0xb23e,\n  'blake2b-504': 0xb23f,\n  'blake2b-512': 0xb240,\n  'blake2s-8': 0xb241,\n  'blake2s-16': 0xb242,\n  'blake2s-24': 0xb243,\n  'blake2s-32': 0xb244,\n  'blake2s-40': 0xb245,\n  'blake2s-48': 0xb246,\n  'blake2s-56': 0xb247,\n  'blake2s-64': 0xb248,\n  'blake2s-72': 0xb249,\n  'blake2s-80': 0xb24a,\n  'blake2s-88': 0xb24b,\n  'blake2s-96': 0xb24c,\n  'blake2s-104': 0xb24d,\n  'blake2s-112': 0xb24e,\n  'blake2s-120': 0xb24f,\n  'blake2s-128': 0xb250,\n  'blake2s-136': 0xb251,\n  'blake2s-144': 0xb252,\n  'blake2s-152': 0xb253,\n  'blake2s-160': 0xb254,\n  'blake2s-168': 0xb255,\n  'blake2s-176': 0xb256,\n  'blake2s-184': 0xb257,\n  'blake2s-192': 0xb258,\n  'blake2s-200': 0xb259,\n  'blake2s-208': 0xb25a,\n  'blake2s-216': 0xb25b,\n  'blake2s-224': 0xb25c,\n  'blake2s-232': 0xb25d,\n  'blake2s-240': 0xb25e,\n  'blake2s-248': 0xb25f,\n  'blake2s-256': 0xb260,\n  'skein256-8': 0xb301,\n  'skein256-16': 0xb302,\n  'skein256-24': 0xb303,\n  'skein256-32': 0xb304,\n  'skein256-40': 0xb305,\n  'skein256-48': 0xb306,\n  'skein256-56': 0xb307,\n  'skein256-64': 0xb308,\n  'skein256-72': 0xb309,\n  'skein256-80': 0xb30a,\n  'skein256-88': 0xb30b,\n  'skein256-96': 0xb30c,\n  'skein256-104': 0xb30d,\n  'skein256-112': 0xb30e,\n  'skein256-120': 0xb30f,\n  'skein256-128': 0xb310,\n  'skein256-136': 0xb311,\n  'skein256-144': 0xb312,\n  'skein256-152': 0xb313,\n  'skein256-160': 0xb314,\n  'skein256-168': 0xb315,\n  'skein256-176': 0xb316,\n  'skein256-184': 0xb317,\n  'skein256-192': 0xb318,\n  'skein256-200': 0xb319,\n  'skein256-208': 0xb31a,\n  'skein256-216': 0xb31b,\n  'skein256-224': 0xb31c,\n  'skein256-232': 0xb31d,\n  'skein256-240': 0xb31e,\n  'skein256-248': 0xb31f,\n  'skein256-256': 0xb320,\n  'skein512-8': 0xb321,\n  'skein512-16': 0xb322,\n  'skein512-24': 0xb323,\n  'skein512-32': 0xb324,\n  'skein512-40': 0xb325,\n  'skein512-48': 0xb326,\n  'skein512-56': 0xb327,\n  'skein512-64': 0xb328,\n  'skein512-72': 0xb329,\n  'skein512-80': 0xb32a,\n  'skein512-88': 0xb32b,\n  'skein512-96': 0xb32c,\n  'skein512-104': 0xb32d,\n  'skein512-112': 0xb32e,\n  'skein512-120': 0xb32f,\n  'skein512-128': 0xb330,\n  'skein512-136': 0xb331,\n  'skein512-144': 0xb332,\n  'skein512-152': 0xb333,\n  'skein512-160': 0xb334,\n  'skein512-168': 0xb335,\n  'skein512-176': 0xb336,\n  'skein512-184': 0xb337,\n  'skein512-192': 0xb338,\n  'skein512-200': 0xb339,\n  'skein512-208': 0xb33a,\n  'skein512-216': 0xb33b,\n  'skein512-224': 0xb33c,\n  'skein512-232': 0xb33d,\n  'skein512-240': 0xb33e,\n  'skein512-248': 0xb33f,\n  'skein512-256': 0xb340,\n  'skein512-264': 0xb341,\n  'skein512-272': 0xb342,\n  'skein512-280': 0xb343,\n  'skein512-288': 0xb344,\n  'skein512-296': 0xb345,\n  'skein512-304': 0xb346,\n  'skein512-312': 0xb347,\n  'skein512-320': 0xb348,\n  'skein512-328': 0xb349,\n  'skein512-336': 0xb34a,\n  'skein512-344': 0xb34b,\n  'skein512-352': 0xb34c,\n  'skein512-360': 0xb34d,\n  'skein512-368': 0xb34e,\n  'skein512-376': 0xb34f,\n  'skein512-384': 0xb350,\n  'skein512-392': 0xb351,\n  'skein512-400': 0xb352,\n  'skein512-408': 0xb353,\n  'skein512-416': 0xb354,\n  'skein512-424': 0xb355,\n  'skein512-432': 0xb356,\n  'skein512-440': 0xb357,\n  'skein512-448': 0xb358,\n  'skein512-456': 0xb359,\n  'skein512-464': 0xb35a,\n  'skein512-472': 0xb35b,\n  'skein512-480': 0xb35c,\n  'skein512-488': 0xb35d,\n  'skein512-496': 0xb35e,\n  'skein512-504': 0xb35f,\n  'skein512-512': 0xb360,\n  'skein1024-8': 0xb361,\n  'skein1024-16': 0xb362,\n  'skein1024-24': 0xb363,\n  'skein1024-32': 0xb364,\n  'skein1024-40': 0xb365,\n  'skein1024-48': 0xb366,\n  'skein1024-56': 0xb367,\n  'skein1024-64': 0xb368,\n  'skein1024-72': 0xb369,\n  'skein1024-80': 0xb36a,\n  'skein1024-88': 0xb36b,\n  'skein1024-96': 0xb36c,\n  'skein1024-104': 0xb36d,\n  'skein1024-112': 0xb36e,\n  'skein1024-120': 0xb36f,\n  'skein1024-128': 0xb370,\n  'skein1024-136': 0xb371,\n  'skein1024-144': 0xb372,\n  'skein1024-152': 0xb373,\n  'skein1024-160': 0xb374,\n  'skein1024-168': 0xb375,\n  'skein1024-176': 0xb376,\n  'skein1024-184': 0xb377,\n  'skein1024-192': 0xb378,\n  'skein1024-200': 0xb379,\n  'skein1024-208': 0xb37a,\n  'skein1024-216': 0xb37b,\n  'skein1024-224': 0xb37c,\n  'skein1024-232': 0xb37d,\n  'skein1024-240': 0xb37e,\n  'skein1024-248': 0xb37f,\n  'skein1024-256': 0xb380,\n  'skein1024-264': 0xb381,\n  'skein1024-272': 0xb382,\n  'skein1024-280': 0xb383,\n  'skein1024-288': 0xb384,\n  'skein1024-296': 0xb385,\n  'skein1024-304': 0xb386,\n  'skein1024-312': 0xb387,\n  'skein1024-320': 0xb388,\n  'skein1024-328': 0xb389,\n  'skein1024-336': 0xb38a,\n  'skein1024-344': 0xb38b,\n  'skein1024-352': 0xb38c,\n  'skein1024-360': 0xb38d,\n  'skein1024-368': 0xb38e,\n  'skein1024-376': 0xb38f,\n  'skein1024-384': 0xb390,\n  'skein1024-392': 0xb391,\n  'skein1024-400': 0xb392,\n  'skein1024-408': 0xb393,\n  'skein1024-416': 0xb394,\n  'skein1024-424': 0xb395,\n  'skein1024-432': 0xb396,\n  'skein1024-440': 0xb397,\n  'skein1024-448': 0xb398,\n  'skein1024-456': 0xb399,\n  'skein1024-464': 0xb39a,\n  'skein1024-472': 0xb39b,\n  'skein1024-480': 0xb39c,\n  'skein1024-488': 0xb39d,\n  'skein1024-496': 0xb39e,\n  'skein1024-504': 0xb39f,\n  'skein1024-512': 0xb3a0,\n  'skein1024-520': 0xb3a1,\n  'skein1024-528': 0xb3a2,\n  'skein1024-536': 0xb3a3,\n  'skein1024-544': 0xb3a4,\n  'skein1024-552': 0xb3a5,\n  'skein1024-560': 0xb3a6,\n  'skein1024-568': 0xb3a7,\n  'skein1024-576': 0xb3a8,\n  'skein1024-584': 0xb3a9,\n  'skein1024-592': 0xb3aa,\n  'skein1024-600': 0xb3ab,\n  'skein1024-608': 0xb3ac,\n  'skein1024-616': 0xb3ad,\n  'skein1024-624': 0xb3ae,\n  'skein1024-632': 0xb3af,\n  'skein1024-640': 0xb3b0,\n  'skein1024-648': 0xb3b1,\n  'skein1024-656': 0xb3b2,\n  'skein1024-664': 0xb3b3,\n  'skein1024-672': 0xb3b4,\n  'skein1024-680': 0xb3b5,\n  'skein1024-688': 0xb3b6,\n  'skein1024-696': 0xb3b7,\n  'skein1024-704': 0xb3b8,\n  'skein1024-712': 0xb3b9,\n  'skein1024-720': 0xb3ba,\n  'skein1024-728': 0xb3bb,\n  'skein1024-736': 0xb3bc,\n  'skein1024-744': 0xb3bd,\n  'skein1024-752': 0xb3be,\n  'skein1024-760': 0xb3bf,\n  'skein1024-768': 0xb3c0,\n  'skein1024-776': 0xb3c1,\n  'skein1024-784': 0xb3c2,\n  'skein1024-792': 0xb3c3,\n  'skein1024-800': 0xb3c4,\n  'skein1024-808': 0xb3c5,\n  'skein1024-816': 0xb3c6,\n  'skein1024-824': 0xb3c7,\n  'skein1024-832': 0xb3c8,\n  'skein1024-840': 0xb3c9,\n  'skein1024-848': 0xb3ca,\n  'skein1024-856': 0xb3cb,\n  'skein1024-864': 0xb3cc,\n  'skein1024-872': 0xb3cd,\n  'skein1024-880': 0xb3ce,\n  'skein1024-888': 0xb3cf,\n  'skein1024-896': 0xb3d0,\n  'skein1024-904': 0xb3d1,\n  'skein1024-912': 0xb3d2,\n  'skein1024-920': 0xb3d3,\n  'skein1024-928': 0xb3d4,\n  'skein1024-936': 0xb3d5,\n  'skein1024-944': 0xb3d6,\n  'skein1024-952': 0xb3d7,\n  'skein1024-960': 0xb3d8,\n  'skein1024-968': 0xb3d9,\n  'skein1024-976': 0xb3da,\n  'skein1024-984': 0xb3db,\n  'skein1024-992': 0xb3dc,\n  'skein1024-1000': 0xb3dd,\n  'skein1024-1008': 0xb3de,\n  'skein1024-1016': 0xb3df,\n  'skein1024-1024': 0xb3e0,\n  'poseidon-bls12_381-a2-fc1': 0xb401,\n  'poseidon-bls12_381-a2-fc1-sc': 0xb402\n})\n\nmodule.exports = { names }\n","'use strict'\n\nconst sha3 = require('js-sha3')\n// @ts-ignore - no types available\nconst mur = require('murmurhash3js-revisited')\nconst { factory: sha } = require('./sha')\nconst { fromNumberTo32BitBuf } = require('./utils')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\n// Note that although this function doesn't do any asynchronous work, we mark\n// the function as async because it must return a Promise to match the API\n// for other functions that do perform asynchronous work (see sha.browser.js)\n// eslint-disable-next-line\n/**\n * @param {string} algorithm\n * @returns {import('./types').Digest}\n */\nconst hash = (algorithm) => async (data) => {\n  switch (algorithm) {\n    case 'sha3-224':\n      return new Uint8Array(sha3.sha3_224.arrayBuffer(data))\n    case 'sha3-256':\n      return new Uint8Array(sha3.sha3_256.arrayBuffer(data))\n    case 'sha3-384':\n      return new Uint8Array(sha3.sha3_384.arrayBuffer(data))\n    case 'sha3-512':\n      return new Uint8Array(sha3.sha3_512.arrayBuffer(data))\n    case 'shake-128':\n      return new Uint8Array(sha3.shake128.create(128).update(data).arrayBuffer())\n    case 'shake-256':\n      return new Uint8Array(sha3.shake256.create(256).update(data).arrayBuffer())\n    case 'keccak-224':\n      return new Uint8Array(sha3.keccak224.arrayBuffer(data))\n    case 'keccak-256':\n      return new Uint8Array(sha3.keccak256.arrayBuffer(data))\n    case 'keccak-384':\n      return new Uint8Array(sha3.keccak384.arrayBuffer(data))\n    case 'keccak-512':\n      return new Uint8Array(sha3.keccak512.arrayBuffer(data))\n    case 'murmur3-128':\n      return uint8ArrayFromString(mur.x64.hash128(data), 'base16')\n    case 'murmur3-32':\n      return fromNumberTo32BitBuf(mur.x86.hash32(data))\n\n    default:\n      throw new TypeError(`${algorithm} is not a supported algorithm`)\n  }\n}\n\n/** @type {import('./types').Digest} */\nconst identity = data => data\n\nmodule.exports = {\n  identity,\n  sha1: sha('sha1'),\n  sha2256: sha('sha2-256'),\n  sha2512: sha('sha2-512'),\n  dblSha2256: sha('dbl-sha2-256'),\n  sha3224: hash('sha3-224'),\n  sha3256: hash('sha3-256'),\n  sha3384: hash('sha3-384'),\n  sha3512: hash('sha3-512'),\n  shake128: hash('shake-128'),\n  shake256: hash('shake-256'),\n  keccak224: hash('keccak-224'),\n  keccak256: hash('keccak-256'),\n  keccak384: hash('keccak-384'),\n  keccak512: hash('keccak-512'),\n  murmur3128: hash('murmur3-128'),\n  murmur332: hash('murmur3-32'),\n  addBlake: require('./blake')\n}\n","/* eslint-disable require-await */\n'use strict'\n\nconst multihash = require('multihashes')\n/**\n * @typedef {import('multihashes').HashName} HashName\n * @typedef {import('./types').Digest} Digest\n */\n\n/**\n * @type {Crypto}\n */\nconst crypto =\n  self.crypto ||\n  /** @type {typeof window.crypto} */\n  // @ts-ignore - unknown property\n  (self.msCrypto)\n\n/**\n *\n * @param {Uint8Array} data\n * @param {HashName} alg\n * @returns {Promise<Uint8Array>}\n */\nconst digest = async (data, alg) => {\n  if (typeof self === 'undefined' || !crypto) {\n    throw new Error(\n      'Please use a browser with webcrypto support and ensure the code has been delivered securely via HTTPS/TLS and run within a Secure Context'\n    )\n  }\n  switch (alg) {\n    case 'sha1':\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-1' }, data))\n    case 'sha2-256':\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-256' }, data))\n    case 'sha2-512':\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-512' }, data))\n    case 'dbl-sha2-256': {\n      const d = await crypto.subtle.digest({ name: 'SHA-256' }, data)\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-256' }, d))\n    }\n    default:\n      throw new Error(`${alg} is not a supported algorithm`)\n  }\n}\n\nmodule.exports = {\n  /**\n   * @param {HashName} alg\n   * @returns {Digest}\n   */\n  factory: (alg) => async (data) => {\n    return digest(data, alg)\n  },\n  digest,\n  /**\n   * @param {Uint8Array} buf\n   * @param {HashName} alg\n   * @param {number} [length]\n   */\n  multihashing: async (buf, alg, length) => {\n    const h = await digest(buf, alg)\n    return multihash.encode(h, alg, length)\n  }\n}\n","'use strict'\n\n/**\n * @param {number} number\n * @returns {Uint8Array}\n */\nconst fromNumberTo32BitBuf = (number) => {\n  const bytes = new Uint8Array(4)\n\n  for (let i = 0; i < 4; i++) {\n    bytes[i] = number & 0xff\n    number = number >> 8\n  }\n\n  return bytes\n}\n\nmodule.exports = {\n  fromNumberTo32BitBuf\n}\n","'use strict'\n\n// @ts-ignore - no types available\nconst blake = require('blakejs')\n\nconst minB = 0xb201\nconst minS = 0xb241\n\nconst blake2b = {\n  init: blake.blake2bInit,\n  update: blake.blake2bUpdate,\n  digest: blake.blake2bFinal\n}\n\nconst blake2s = {\n  init: blake.blake2sInit,\n  update: blake.blake2sUpdate,\n  digest: blake.blake2sFinal\n}\n\n// Note that although this function doesn't do any asynchronous work, we mark\n// the function as async because it must return a Promise to match the API\n// for other functions that do perform asynchronous work (see sha.browser.js)\n// eslint-disable-next-line\n\n/**\n * @param {number} size\n * @param {any} hf\n * @returns {import('./types').Digest}\n */\nconst makeB2Hash = (size, hf) => async (data) => {\n  const ctx = hf.init(size, null)\n  hf.update(ctx, data)\n  return hf.digest(ctx)\n}\n\n/**\n * @param {Record<number, import('./types').Digest>} table\n */\nmodule.exports = (table) => {\n  for (let i = 0; i < 64; i++) {\n    table[minB + i] = makeB2Hash(i + 1, blake2b)\n  }\n  for (let i = 0; i < 32; i++) {\n    table[minS + i] = makeB2Hash(i + 1, blake2s)\n  }\n}\n","'use strict'\n\n/**\n * Returns true if the two passed Uint8Arrays have the same content\n *\n * @param {Uint8Array} a\n * @param {Uint8Array} b\n */\nfunction equals (a, b) {\n  if (a === b) {\n    return true\n  }\n\n  if (a.byteLength !== b.byteLength) {\n    return false\n  }\n\n  for (let i = 0; i < a.byteLength; i++) {\n    if (a[i] !== b[i]) {\n      return false\n    }\n  }\n\n  return true\n}\n\nmodule.exports = equals\n","module.exports = Node\n\n/**\n * a linked-list node\n * @class\n * @param {any} value - node's value\n * @param {Node} next - next node\n */\nfunction Node (value, next) {\n  this.value = value\n  this.next = next\n}\n\n/**\n * checks if this node or any of its children has the value\n * @param {any} value - value to check if linked-list contains\n * @return {boolean} true if the list contains the value; false if not\n */\nNode.prototype.contains = function (value) {\n  var cursor = this\n\n  while (cursor) {\n    if (cursor.value === value) return true\n    cursor = cursor.next\n  }\n\n  return false\n}\n","'use strict'\n\nconst CID = require('cids')\nconst util = require('./util')\n\n/**\n * Resolves a path within a CBOR block.\n *\n * Returns the value or a link and the partial mising path. This way the\n * IPLD Resolver can fetch the link and continue to resolve.\n *\n * @param {Uint8Array} binaryBlob - Binary representation of a CBOR block\n * @param {string} [path='/'] - Path that should be resolved\n */\nexports.resolve = (binaryBlob, path) => {\n  let node = util.deserialize(binaryBlob)\n\n  const parts = path.split('/').filter(Boolean)\n  while (parts.length) {\n    const key = parts.shift()\n    if (node[key] === undefined) {\n      throw new Error(`Object has no property '${key}'`)\n    }\n\n    node = node[key]\n    if (CID.isCID(node)) {\n      return {\n        value: node,\n        remainderPath: parts.join('/')\n      }\n    }\n  }\n\n  return {\n    value: node,\n    remainderPath: ''\n  }\n}\n\nconst traverse = function * (node, path) {\n  // Traverse only objects and arrays\n  if (node instanceof Uint8Array || CID.isCID(node) || typeof node === 'string' ||\n      node === null) {\n    return\n  }\n  for (const item of Object.keys(node)) {\n    const nextpath = path === undefined ? item : path + '/' + item\n    yield nextpath\n    yield * traverse(node[item], nextpath)\n  }\n}\n\n/**\n * Return all available paths of a block.\n *\n * @generator\n * @param {Uint8Array} binaryBlob - Binary representation of a CBOR block\n * @yields {string} - A single path\n */\nexports.tree = function * (binaryBlob) {\n  const node = util.deserialize(binaryBlob)\n\n  yield * traverse(node)\n}\n","'use strict'\nconst CID = require('cids')\nconst multihashing = require('multihashing-async')\nconst multicodec = require('multicodec')\n\n// binary resolver\nmodule.exports = {\n  codec: multicodec.RAW,\n  defaultHashAlg: multicodec.SHA2_256,\n  resolver: {\n    /**\n     * Resolves a path within a Raw block.\n     *\n     * Always returns the raw data as value without any remainderPath.\n     *\n     * @param {Buffer} binaryBlob - Binary representation of a PB block\n     * @param {string} [path='/'] - Path that should be resolved.  Must be '/' or an exception is thrown\n     * @returns {Object} result - Result of the path it it was resolved successfully\n     * @returns {*} result.value - The raw data\n     * @returns {string} result.remainderPath - An empty string\n     */\n    resolve: (binaryBlob, path) => {\n      if (path !== '/') {\n        throw new Error('Only the root path / may be resolved')\n      }\n\n      return {\n        value: binaryBlob,\n        remainderPath: ''\n      }\n    },\n    /**\n     * Return all available paths of a block.\n     *\n     * @generator\n     * @param {Buffer} binaryBlob - The raw data\n     * @returns {Object} - Finished generator with `done: true`\n     */\n    tree: (binaryBlob) => {\n      return {\n        done: true\n      }\n    }\n  },\n  util: {\n    deserialize: (data) => {\n      return data\n    },\n    serialize: (data) => {\n      return data\n    },\n    /**\n     * Calculate the CID of the binary blob.\n     *\n     * @param {Object} binaryBlob - Encoded IPLD Node\n     * @param {Object} [userOptions] - Options to create the CID\n     * @param {number} [userOptions.cidVersion=1] - CID version number\n     * @param {string} [UserOptions.hashAlg] - Defaults to the defaultHashAlg of the format\n     * @returns {Promise.<CID>}\n     */\n    cid: async (binaryBlob, userOptions) => {\n      const defaultOptions = { cidVersion: 1, hashAlg: module.exports.defaultHashAlg }\n      const options = Object.assign(defaultOptions, userOptions)\n\n      const multihash = await multihashing(binaryBlob, options.hashAlg)\n      const codecName = multicodec.print[module.exports.codec]\n      const cid = new CID(options.cidVersion, codecName, multihash)\n\n      return cid\n    }\n  }\n}\n","'use strict'\n\nconst errcode = require('err-code')\nconst multihash = require('multihashes')\nconst crypto = require('./crypto')\nconst equals = require('uint8arrays/equals')\n\n/**\n * @typedef {import(\"./types\").Digest} Digest\n * @typedef {import(\"multihashes\").HashName} HashName\n */\n\n/**\n * Hash the given `bytes` using the algorithm specified by `alg`.\n *\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nasync function Multihashing (bytes, alg, length) {\n  const digest = await Multihashing.digest(bytes, alg, length)\n  return multihash.encode(digest, alg, length)\n}\n\n/**\n * Expose multihash itself, to avoid silly double requires.\n */\nMultihashing.multihash = multihash\n\n/**\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nMultihashing.digest = async (bytes, alg, length) => {\n  const hash = Multihashing.createHash(alg)\n  const digest = await hash(bytes)\n  return length ? digest.slice(0, length) : digest\n}\n\n/**\n * Creates a function that hashes with the given algorithm\n *\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @returns {Digest} - The hash function corresponding to `alg`\n */\nMultihashing.createHash = function (alg) {\n  if (!alg) {\n    const e = errcode(new Error('hash algorithm must be specified'), 'ERR_HASH_ALGORITHM_NOT_SPECIFIED')\n    throw e\n  }\n\n  const code = multihash.coerceCode(alg)\n  if (!Multihashing.functions[code]) {\n    throw errcode(new Error(`multihash function '${alg}' not yet supported`), 'ERR_HASH_ALGORITHM_NOT_SUPPORTED')\n  }\n\n  return Multihashing.functions[code]\n}\n\n/**\n * Mapping of multihash codes to their hashing functions.\n *\n * @type {Record<number, Digest>}\n */\n// @ts-ignore - most of those functions aren't typed\nMultihashing.functions = {\n  // identity\n  0x00: crypto.identity,\n  // sha1\n  0x11: crypto.sha1,\n  // sha2-256\n  0x12: crypto.sha2256,\n  // sha2-512\n  0x13: crypto.sha2512,\n  // sha3-512\n  0x14: crypto.sha3512,\n  // sha3-384\n  0x15: crypto.sha3384,\n  // sha3-256\n  0x16: crypto.sha3256,\n  // sha3-224\n  0x17: crypto.sha3224,\n  // shake-128\n  0x18: crypto.shake128,\n  // shake-256\n  0x19: crypto.shake256,\n  // keccak-224\n  0x1A: crypto.keccak224,\n  // keccak-256\n  0x1B: crypto.keccak256,\n  // keccak-384\n  0x1C: crypto.keccak384,\n  // keccak-512\n  0x1D: crypto.keccak512,\n  // murmur3-128\n  0x22: crypto.murmur3128,\n  // murmur3-32\n  0x23: crypto.murmur332,\n  // dbl-sha2-256\n  0x56: crypto.dblSha2256\n}\n\n// add blake functions\ncrypto.addBlake(Multihashing.functions)\n\n/**\n * @param {Uint8Array} bytes\n * @param {Uint8Array} hash\n * @returns {Promise<boolean>}\n */\nMultihashing.validate = async (bytes, hash) => {\n  const newHash = await Multihashing(bytes, multihash.decode(hash).name)\n\n  return equals(hash, newHash)\n}\n\nmodule.exports = Multihashing\n","'use strict';\n\n/**\n * @typedef {{ [key: string]: any }} Extensions\n * @typedef {Error} Err\n * @property {string} message\n */\n\n/**\n *\n * @param {Error} obj\n * @param {Extensions} props\n * @returns {Error & Extensions}\n */\nfunction assign(obj, props) {\n    for (const key in props) {\n        Object.defineProperty(obj, key, {\n            value: props[key],\n            enumerable: true,\n            configurable: true,\n        });\n    }\n\n    return obj;\n}\n\n/**\n *\n * @param {any} err - An Error\n * @param {string|Extensions} code - A string code or props to set on the error\n * @param {Extensions} [props] - Props to set on the error\n * @returns {Error & Extensions}\n */\nfunction createError(err, code, props) {\n    if (!err || typeof err === 'string') {\n        throw new TypeError('Please pass an Error to err-code');\n    }\n\n    if (!props) {\n        props = {};\n    }\n\n    if (typeof code === 'object') {\n        props = code;\n        code = '';\n    }\n\n    if (code) {\n        props.code = code;\n    }\n\n    try {\n        return assign(err, props);\n    } catch (_) {\n        props.message = err.message;\n        props.stack = err.stack;\n\n        const ErrClass = function () {};\n\n        ErrClass.prototype = Object.create(Object.getPrototypeOf(err));\n\n        // @ts-ignore\n        const output = assign(new ErrClass(), props);\n\n        return output;\n    }\n}\n\nmodule.exports = createError;\n","'use strict'\n\nconst baseX = require('@multiformats/base-x')\nconst Base = require('./base.js')\nconst { rfc4648 } = require('./rfc4648')\nconst { decodeText, encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import('./types').Codec} Codec */\n/** @typedef {import('./types').BaseName} BaseName */\n/** @typedef {import('./types').BaseCode} BaseCode */\n\n/** @type {CodecFactory} */\nconst identity = () => {\n  return {\n    encode: decodeText,\n    decode: encodeText\n  }\n}\n\n/**\n *\n * name, code, implementation, alphabet\n *\n * @type {Array<[BaseName, BaseCode, CodecFactory, string]>}\n */\nconst constants = [\n  ['identity', '\\x00', identity, ''],\n  ['base2', '0', rfc4648(1), '01'],\n  ['base8', '7', rfc4648(3), '01234567'],\n  ['base10', '9', baseX, '0123456789'],\n  ['base16', 'f', rfc4648(4), '0123456789abcdef'],\n  ['base16upper', 'F', rfc4648(4), '0123456789ABCDEF'],\n  ['base32hex', 'v', rfc4648(5), '0123456789abcdefghijklmnopqrstuv'],\n  ['base32hexupper', 'V', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV'],\n  ['base32hexpad', 't', rfc4648(5), '0123456789abcdefghijklmnopqrstuv='],\n  ['base32hexpadupper', 'T', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV='],\n  ['base32', 'b', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567'],\n  ['base32upper', 'B', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'],\n  ['base32pad', 'c', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567='],\n  ['base32padupper', 'C', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567='],\n  ['base32z', 'h', rfc4648(5), 'ybndrfg8ejkmcpqxot1uwisza345h769'],\n  ['base36', 'k', baseX, '0123456789abcdefghijklmnopqrstuvwxyz'],\n  ['base36upper', 'K', baseX, '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'],\n  ['base58btc', 'z', baseX, '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'],\n  ['base58flickr', 'Z', baseX, '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'],\n  ['base64', 'm', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'],\n  ['base64pad', 'M', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/='],\n  ['base64url', 'u', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_'],\n  ['base64urlpad', 'U', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=']\n]\n\n/** @type {Record<BaseName,Base>} */\nconst names = constants.reduce((prev, tupple) => {\n  prev[tupple[0]] = new Base(tupple[0], tupple[1], tupple[2], tupple[3])\n  return prev\n}, /** @type {Record<BaseName,Base>} */({}))\n\n/** @type {Record<BaseCode,Base>} */\nconst codes = constants.reduce((prev, tupple) => {\n  prev[tupple[1]] = names[tupple[0]]\n  return prev\n}, /** @type {Record<BaseCode,Base>} */({}))\n\nmodule.exports = {\n  names,\n  codes\n}\n","'use strict'\n\nconst { encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import(\"./types\").BaseName} BaseName */\n/** @typedef {import(\"./types\").BaseCode} BaseCode */\n\n/**\n * Class to encode/decode in the supported Bases\n *\n */\nclass Base {\n  /**\n   * @param {BaseName} name\n   * @param {BaseCode} code\n   * @param {CodecFactory} factory\n   * @param {string} alphabet\n   */\n  constructor (name, code, factory, alphabet) {\n    this.name = name\n    this.code = code\n    this.codeBuf = encodeText(this.code)\n    this.alphabet = alphabet\n    this.codec = factory(alphabet)\n  }\n\n  /**\n   * @param {Uint8Array} buf\n   * @returns {string}\n   */\n  encode (buf) {\n    return this.codec.encode(buf)\n  }\n\n  /**\n   * @param {string} string\n   * @returns {Uint8Array}\n   */\n  decode (string) {\n    for (const char of string) {\n      if (this.alphabet && this.alphabet.indexOf(char) < 0) {\n        throw new Error(`invalid character '${char}' in '${string}'`)\n      }\n    }\n    return this.codec.decode(string)\n  }\n}\n\nmodule.exports = Base\n","'use strict'\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n\n/**\n * @param {string} string\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {Uint8Array}\n */\nconst decode = (string, alphabet, bitsPerChar) => {\n  // Build the character lookup table:\n  /** @type {Record<string, number>} */\n  const codes = {}\n  for (let i = 0; i < alphabet.length; ++i) {\n    codes[alphabet[i]] = i\n  }\n\n  // Count the padding bytes:\n  let end = string.length\n  while (string[end - 1] === '=') {\n    --end\n  }\n\n  // Allocate the output:\n  const out = new Uint8Array((end * bitsPerChar / 8) | 0)\n\n  // Parse the data:\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  let written = 0 // Next byte to write\n  for (let i = 0; i < end; ++i) {\n    // Read one character from the string:\n    const value = codes[string[i]]\n    if (value === undefined) {\n      throw new SyntaxError('Invalid character ' + string[i])\n    }\n\n    // Append the bits to the buffer:\n    buffer = (buffer << bitsPerChar) | value\n    bits += bitsPerChar\n\n    // Write out some bits if the buffer has a byte's worth:\n    if (bits >= 8) {\n      bits -= 8\n      out[written++] = 0xff & (buffer >> bits)\n    }\n  }\n\n  // Verify that we have received just enough bits:\n  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {\n    throw new SyntaxError('Unexpected end of data')\n  }\n\n  return out\n}\n\n/**\n * @param {Uint8Array} data\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {string}\n */\nconst encode = (data, alphabet, bitsPerChar) => {\n  const pad = alphabet[alphabet.length - 1] === '='\n  const mask = (1 << bitsPerChar) - 1\n  let out = ''\n\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  for (let i = 0; i < data.length; ++i) {\n    // Slurp data into the buffer:\n    buffer = (buffer << 8) | data[i]\n    bits += 8\n\n    // Write out as much as we can:\n    while (bits > bitsPerChar) {\n      bits -= bitsPerChar\n      out += alphabet[mask & (buffer >> bits)]\n    }\n  }\n\n  // Partial character:\n  if (bits) {\n    out += alphabet[mask & (buffer << (bitsPerChar - bits))]\n  }\n\n  // Add padding characters until we hit a byte boundary:\n  if (pad) {\n    while ((out.length * bitsPerChar) & 7) {\n      out += '='\n    }\n  }\n\n  return out\n}\n\n/**\n * RFC4648 Factory\n *\n * @param {number} bitsPerChar\n * @returns {CodecFactory}\n */\nconst rfc4648 = (bitsPerChar) => (alphabet) => {\n  return {\n    /**\n     * @param {Uint8Array} input\n     * @returns {string}\n     */\n    encode (input) {\n      return encode(input, alphabet, bitsPerChar)\n    },\n    /**\n     * @param {string} input\n     * @returns {Uint8Array}\n     */\n    decode (input) {\n      return decode(input, alphabet, bitsPerChar)\n    }\n  }\n}\n\nmodule.exports = { rfc4648 }\n","module.exports = {\n    encode: require('./encode.js')\n  , decode: require('./decode.js')\n  , encodingLength: require('./length.js')\n}\n","module.exports = encode\n\nvar MSB = 0x80\n  , REST = 0x7F\n  , MSBALL = ~REST\n  , INT = Math.pow(2, 31)\n\nfunction encode(num, out, offset) {\n  out = out || []\n  offset = offset || 0\n  var oldOffset = offset\n\n  while(num >= INT) {\n    out[offset++] = (num & 0xFF) | MSB\n    num /= 128\n  }\n  while(num & MSBALL) {\n    out[offset++] = (num & 0xFF) | MSB\n    num >>>= 7\n  }\n  out[offset] = num | 0\n  \n  encode.bytes = offset - oldOffset + 1\n  \n  return out\n}\n","module.exports = read\n\nvar MSB = 0x80\n  , REST = 0x7F\n\nfunction read(buf, offset) {\n  var res    = 0\n    , offset = offset || 0\n    , shift  = 0\n    , counter = offset\n    , b\n    , l = buf.length\n\n  do {\n    if (counter >= l) {\n      read.bytes = 0\n      throw new RangeError('Could not decode varint')\n    }\n    b = buf[counter++]\n    res += shift < 28\n      ? (b & REST) << shift\n      : (b & REST) * Math.pow(2, shift)\n    shift += 7\n  } while (b >= MSB)\n\n  read.bytes = counter - offset\n\n  return res\n}\n","\nvar N1 = Math.pow(2,  7)\nvar N2 = Math.pow(2, 14)\nvar N3 = Math.pow(2, 21)\nvar N4 = Math.pow(2, 28)\nvar N5 = Math.pow(2, 35)\nvar N6 = Math.pow(2, 42)\nvar N7 = Math.pow(2, 49)\nvar N8 = Math.pow(2, 56)\nvar N9 = Math.pow(2, 63)\n\nmodule.exports = function (value) {\n  return (\n    value < N1 ? 1\n  : value < N2 ? 2\n  : value < N3 ? 3\n  : value < N4 ? 4\n  : value < N5 ? 5\n  : value < N6 ? 6\n  : value < N7 ? 7\n  : value < N8 ? 8\n  : value < N9 ? 9\n  :              10\n  )\n}\n","/* eslint quote-props: off */\n'use strict'\n\n/**\n * Names for all availab
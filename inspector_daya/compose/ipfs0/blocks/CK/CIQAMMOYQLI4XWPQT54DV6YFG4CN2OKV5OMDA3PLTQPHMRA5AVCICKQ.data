     w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener =\n    function prependListener(type, listener) {\n      return _addListener(this, type, listener, true);\n    };\n\nfunction onceWrapper() {\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    if (arguments.length === 0)\n      return this.listener.call(this.target);\n    return this.listener.apply(this.target, arguments);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  checkListener(listener);\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener =\n    function prependOnceListener(type, listener) {\n      checkListener(listener);\n      this.prependListener(type, _onceWrap(this, type, listener));\n      return this;\n    };\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener =\n    function removeListener(type, listener) {\n      var list, events, position, i, originalListener;\n\n      checkListener(listener);\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      list = events[type];\n      if (list === undefined)\n        return this;\n\n      if (list === listener || list.listener === listener) {\n        if (--this._eventsCount === 0)\n          this._events = Object.create(null);\n        else {\n          delete events[type];\n          if (events.removeListener)\n            this.emit('removeListener', type, list.listener || listener);\n        }\n      } else if (typeof list !== 'function') {\n        position = -1;\n\n        for (i = list.length - 1; i >= 0; i--) {\n          if (list[i] === listener || list[i].listener === listener) {\n            originalListener = list[i].listener;\n            position = i;\n            break;\n          }\n        }\n\n        if (position < 0)\n          return this;\n\n        if (position === 0)\n          list.shift();\n        else {\n          spliceOne(list, position);\n        }\n\n        if (list.length === 1)\n          events[type] = list[0];\n\n        if (events.removeListener !== undefined)\n          this.emit('removeListener', type, originalListener || listener);\n      }\n\n      return this;\n    };\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners =\n    function removeAllListeners(type) {\n      var listeners, events, i;\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      // not listening for removeListener, no need to emit\n      if (events.removeListener === undefined) {\n        if (arguments.length === 0) {\n          this._events = Object.create(null);\n          this._eventsCount = 0;\n        } else if (events[type] !== undefined) {\n          if (--this._eventsCount === 0)\n            this._events = Object.create(null);\n          else\n            delete events[type];\n        }\n        return this;\n      }\n\n      // emit removeListener for all listeners on all events\n      if (arguments.length === 0) {\n        var keys = Object.keys(events);\n        var key;\n        for (i = 0; i < keys.length; ++i) {\n          key = keys[i];\n          if (key === 'removeListener') continue;\n          this.removeAllListeners(key);\n        }\n        this.removeAllListeners('removeListener');\n        this._events = Object.create(null);\n        this._eventsCount = 0;\n        return this;\n      }\n\n      listeners = events[type];\n\n      if (typeof listeners === 'function') {\n        this.removeListener(type, listeners);\n      } else if (listeners !== undefined) {\n        // LIFO order\n        for (i = listeners.length - 1; i >= 0; i--) {\n          this.removeListener(type, listeners[i]);\n        }\n      }\n\n      return this;\n    };\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined)\n    return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined)\n    return [];\n\n  if (typeof evlistener === 'function')\n    return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ?\n    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i)\n    copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++)\n    list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n\nfunction once(emitter, name) {\n  return new Promise(function (resolve, reject) {\n    function errorListener(err) {\n      emitter.removeListener(name, resolver);\n      reject(err);\n    }\n\n    function resolver() {\n      if (typeof emitter.removeListener === 'function') {\n        emitter.removeListener('error', errorListener);\n      }\n      resolve([].slice.call(arguments));\n    };\n\n    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });\n    if (name !== 'error') {\n      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });\n    }\n  });\n}\n\nfunction addErrorHandlerIfEventEmitter(emitter, handler, flags) {\n  if (typeof emitter.on === 'function') {\n    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);\n  }\n}\n\nfunction eventTargetAgnosticAddListener(emitter, name, listener, flags) {\n  if (typeof emitter.on === 'function') {\n    if (flags.once) {\n      emitter.once(name, listener);\n    } else {\n      emitter.on(name, listener);\n    }\n  } else if (typeof emitter.addEventListener === 'function') {\n    // EventTarget does not have `error` event semantics like Node\n    // EventEmitters, we do not listen for `error` events here.\n    emitter.addEventListener(name, function wrapListener(arg) {\n      // IE does not have builtin `{ once: true }` support so we\n      // have to do it manually.\n      if (flags.once) {\n        emitter.removeEventListener(name, wrapListener);\n      }\n      listener(arg);\n    });\n  } else {\n    throw new TypeError('The \"emitter\" argument must be of type EventEmitter. Received type ' + typeof emitter);\n  }\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}","'use strict'\nconst CID = require('cids')\nconst multicodec = require('multicodec')\nconst createUtil = require('../util/createUtil')\n\nconst createResolver = (codec, deserialize) => {\n  const util = createUtil(codec, deserialize)\n\n  /**\n   * Resolves a path within a Ethereum block.\n   *\n   * Returns the value or a link and the partial mising path. This way the\n   * IPLD Resolver can fetch the link and continue to resolve.\n   *\n   * @param {Uint8Array} binaryBlob - Binary representation of a Ethereum block\n   * @param {string} [path='/'] - Path that should be resolved\n   * @returns {Object} result - Result of the path it it was resolved successfully\n   * @returns {*} result.value - Value the path resolves to\n   * @returns {string} result.remainderPath - If the path resolves half-way to a\n   *   link, then the `remainderPath` is the part after the link that can be used\n   *   for further resolving\n   */\n  const resolve = (binaryBlob, path) => {\n    let node = util.deserialize(binaryBlob)\n\n    const parts = path.split('/').filter((x) => x)\n    while (parts.length) {\n      const key = parts.shift()\n      if (node[key] === undefined) {\n        throw new Error(`Object has no property '${key}'`)\n      }\n\n      node = node[key]\n      if (CID.isCID(node)) {\n        return {\n          value: node,\n          remainderPath: parts.join('/')\n        }\n      }\n    }\n\n    return {\n      value: node,\n      remainderPath: ''\n    }\n  }\n\n  const _traverse = function * (node, path) {\n    // Traverse only objects and arrays\n    if (node instanceof Uint8Array || CID.isCID(node) || typeof node === 'string' ||\n        node === null) {\n      return\n    }\n    for (const item of Object.keys(node)) {\n      const nextpath = path === undefined ? item : path + '/' + item\n      yield nextpath\n      yield * _traverse(node[item], nextpath)\n    }\n  }\n\n  /**\n   * Return all available paths of a block.\n   *\n   * @generator\n   * @param {Uint8Array} binaryBlob - Binary representation of a Bitcoin block\n   * @yields {string} - A single path\n   */\n  const tree = function * (binaryBlob) {\n    const node = util.deserialize(binaryBlob)\n\n    yield * _traverse(node)\n  }\n\n  return {\n    codec: codec,\n    defaultHashAlg: multicodec.KECCAK_256,\n    resolver: {\n      resolve: resolve,\n      tree: tree,\n    },\n    util: util,\n  }\n}\n\nmodule.exports = createResolver\n","'use strict'\n\nconst multihash = require('multihashing-async').multihash\nconst CID = require('cids')\nconst strftime = require('strftime')\nconst { Buffer } = require('buffer')\n\nconst SHA1_LENGTH = 20\n\nfunction find (buf, byte) {\n  for (let i = 0; i < buf.length; i++) {\n    if (buf[i] === byte) {\n      return i\n    }\n  }\n  return -1\n}\n\nconst ISO_8601_STRICT = '%FT%T%:z'\nconst TIMESTAMP_WITH_OFFSET = '%s %z'\n\nconst timestampWithOffsetToISOStrict = (timestamp, offset) => strftime.timezone(offset)(ISO_8601_STRICT, new Date(timestamp * 1000))\n\nconst isoStrictToTimestampWithOffset = (isoString) => {\n  const matched = isoString.match(/([+-]\\d{2}:\\d{2})/)\n  const offset = matched === null ? '+0000' : (matched[0].slice(0, 3) + matched[0].slice(4))\n  return strftime.timezone(offset)(TIMESTAMP_WITH_OFFSET, new Date(isoString))\n}\n\nfunction parsePersonLine (line) {\n  const matched = line.match(/^(([^<]+)\\s)?\\s?<([^>]+)>\\s?(?:(\\d+)\\s([+-]\\d+))?$/)\n  if (matched === null) {\n    return null\n  }\n\n  return {\n    name: matched[2],\n    email: matched[3],\n    date: matched[4] && matched[5] && timestampWithOffsetToISOStrict(parseInt(matched[4]), matched[5])\n  }\n}\n\nfunction serializePersonLine (node) {\n  const parts = []\n  if (node.name) {\n    parts.push(node.name)\n  }\n  parts.push('<' + node.email + '>')\n  if (node.date) {\n    parts.push(isoStrictToTimestampWithOffset(node.date))\n  }\n\n  return parts.join(' ')\n}\n\nfunction shaToCid (buf) {\n  const mh = multihash.encode(buf, 'sha1')\n  return new CID(1, 'git-raw', mh)\n}\n\nfunction cidToSha (cid) {\n  const mh = multihash.decode(cid.multihash)\n  if (mh.name !== 'sha1') {\n    return null\n  }\n\n  return Buffer.from(mh.digest.buffer, mh.digest.byteOffset, mh.digest.byteLength)\n}\n\nmodule.exports = {\n  SHA1_LENGTH,\n  find,\n  parsePersonLine,\n  serializePersonLine,\n  shaToCid,\n  cidToSha\n}\n","'use strict';\n\nvar elliptic = exports;\n\nelliptic.version = require('../package.json').version;\nelliptic.utils = require('./elliptic/utils');\nelliptic.rand = require('brorand');\nelliptic.curve = require('./elliptic/curve');\nelliptic.curves = require('./elliptic/curves');\n\n// Protocols\nelliptic.ec = require('./elliptic/ec');\nelliptic.eddsa = require('./elliptic/eddsa');\n","'use strict';\n\nvar BN = require('bn.js');\nvar utils = require('../utils');\nvar getNAF = utils.getNAF;\nvar getJSF = utils.getJSF;\nvar assert = utils.assert;\n\nfunction BaseCurve(type, conf) {\n  this.type = type;\n  this.p = new BN(conf.p, 16);\n\n  // Use Montgomery, when there is no fast reduction for the prime\n  this.red = conf.prime ? BN.red(conf.prime) : BN.mont(this.p);\n\n  // Useful for many curves\n  this.zero = new BN(0).toRed(this.red);\n  this.one = new BN(1).toRed(this.red);\n  this.two = new BN(2).toRed(this.red);\n\n  // Curve configuration, optional\n  this.n = conf.n && new BN(conf.n, 16);\n  this.g = conf.g && this.pointFromJSON(conf.g, conf.gRed);\n\n  // Temporary arrays\n  this._wnafT1 = new Array(4);\n  this._wnafT2 = new Array(4);\n  this._wnafT3 = new Array(4);\n  this._wnafT4 = new Array(4);\n\n  this._bitLength = this.n ? this.n.bitLength() : 0;\n\n  // Generalized Greg Maxwell's trick\n  var adjustCount = this.n && this.p.div(this.n);\n  if (!adjustCount || adjustCount.cmpn(100) > 0) {\n    this.redN = null;\n  } else {\n    this._maxwellTrick = true;\n    this.redN = this.n.toRed(this.red);\n  }\n}\nmodule.exports = BaseCurve;\n\nBaseCurve.prototype.point = function point() {\n  throw new Error('Not implemented');\n};\n\nBaseCurve.prototype.validate = function validate() {\n  throw new Error('Not implemented');\n};\n\nBaseCurve.prototype._fixedNafMul = function _fixedNafMul(p, k) {\n  assert(p.precomputed);\n  var doubles = p._getDoubles();\n\n  var naf = getNAF(k, 1, this._bitLength);\n  var I = (1 << (doubles.step + 1)) - (doubles.step % 2 === 0 ? 2 : 1);\n  I /= 3;\n\n  // Translate into more windowed form\n  var repr = [];\n  var j;\n  var nafW;\n  for (j = 0; j < naf.length; j += doubles.step) {\n    nafW = 0;\n    for (var l = j + doubles.step - 1; l >= j; l--)\n      nafW = (nafW << 1) + naf[l];\n    repr.push(nafW);\n  }\n\n  var a = this.jpoint(null, null, null);\n  var b = this.jpoint(null, null, null);\n  for (var i = I; i > 0; i--) {\n    for (j = 0; j < repr.length; j++) {\n      nafW = repr[j];\n      if (nafW === i)\n        b = b.mixedAdd(doubles.points[j]);\n      else if (nafW === -i)\n        b = b.mixedAdd(doubles.points[j].neg());\n    }\n    a = a.add(b);\n  }\n  return a.toP();\n};\n\nBaseCurve.prototype._wnafMul = function _wnafMul(p, k) {\n  var w = 4;\n\n  // Precompute window\n  var nafPoints = p._getNAFPoints(w);\n  w = nafPoints.wnd;\n  var wnd = nafPoints.points;\n\n  // Get NAF form\n  var naf = getNAF(k, w, this._bitLength);\n\n  // Add `this`*(N+1) for every w-NAF index\n  var acc = this.jpoint(null, null, null);\n  for (var i = naf.length - 1; i >= 0; i--) {\n    // Count zeroes\n    for (var l = 0; i >= 0 && naf[i] === 0; i--)\n      l++;\n    if (i >= 0)\n      l++;\n    acc = acc.dblp(l);\n\n    if (i < 0)\n      break;\n    var z = naf[i];\n    assert(z !== 0);\n    if (p.type === 'affine') {\n      // J +- P\n      if (z > 0)\n        acc = acc.mixedAdd(wnd[(z - 1) >> 1]);\n      else\n        acc = acc.mixedAdd(wnd[(-z - 1) >> 1].neg());\n    } else {\n      // J +- J\n      if (z > 0)\n        acc = acc.add(wnd[(z - 1) >> 1]);\n      else\n        acc = acc.add(wnd[(-z - 1) >> 1].neg());\n    }\n  }\n  return p.type === 'affine' ? acc.toP() : acc;\n};\n\nBaseCurve.prototype._wnafMulAdd = function _wnafMulAdd(defW,\n  points,\n  coeffs,\n  len,\n  jacobianResult) {\n  var wndWidth = this._wnafT1;\n  var wnd = this._wnafT2;\n  var naf = this._wnafT3;\n\n  // Fill all arrays\n  var max = 0;\n  var i;\n  var j;\n  var p;\n  for (i = 0; i < len; i++) {\n    p = points[i];\n    var nafPoints = p._getNAFPoints(defW);\n    wndWidth[i] = nafPoints.wnd;\n    wnd[i] = nafPoints.points;\n  }\n\n  // Comb small window NAFs\n  for (i = len - 1; i >= 1; i -= 2) {\n    var a = i - 1;\n    var b = i;\n    if (wndWidth[a] !== 1 || wndWidth[b] !== 1) {\n      naf[a] = getNAF(coeffs[a], wndWidth[a], this._bitLength);\n      naf[b] = getNAF(coeffs[b], wndWidth[b], this._bitLength);\n      max = Math.max(naf[a].length, max);\n      max = Math.max(naf[b].length, max);\n      continue;\n    }\n\n    var comb = [\n      points[a], /* 1 */\n      null, /* 3 */\n      null, /* 5 */\n      points[b], /* 7 */\n    ];\n\n    // Try to avoid Projective points, if possible\n    if (points[a].y.cmp(points[b].y) === 0) {\n      comb[1] = points[a].add(points[b]);\n      comb[2] = points[a].toJ().mixedAdd(points[b].neg());\n    } else if (points[a].y.cmp(points[b].y.redNeg()) === 0) {\n      comb[1] = points[a].toJ().mixedAdd(points[b]);\n      comb[2] = points[a].add(points[b].neg());\n    } else {\n      comb[1] = points[a].toJ().mixedAdd(points[b]);\n      comb[2] = points[a].toJ().mixedAdd(points[b].neg());\n    }\n\n    var index = [\n      -3, /* -1 -1 */\n      -1, /* -1 0 */\n      -5, /* -1 1 */\n      -7, /* 0 -1 */\n      0, /* 0 0 */\n      7, /* 0 1 */\n      5, /* 1 -1 */\n      1, /* 1 0 */\n      3,  /* 1 1 */\n    ];\n\n    var jsf = getJSF(coeffs[a], coeffs[b]);\n    max = Math.max(jsf[0].length, max);\n    naf[a] = new Array(max);\n    naf[b] = new Array(max);\n    for (j = 0; j < max; j++) {\n      var ja = jsf[0][j] | 0;\n      var jb = jsf[1][j] | 0;\n\n      naf[a][j] = index[(ja + 1) * 3 + (jb + 1)];\n      naf[b][j] = 0;\n      wnd[a] = comb;\n    }\n  }\n\n  var acc = this.jpoint(null, null, null);\n  var tmp = this._wnafT4;\n  for (i = max; i >= 0; i--) {\n    var k = 0;\n\n    while (i >= 0) {\n      var zero = true;\n      for (j = 0; j < len; j++) {\n        tmp[j] = naf[j][i] | 0;\n        if (tmp[j] !== 0)\n          zero = false;\n      }\n      if (!zero)\n        break;\n      k++;\n      i--;\n    }\n    if (i >= 0)\n      k++;\n    acc = acc.dblp(k);\n    if (i < 0)\n      break;\n\n    for (j = 0; j < len; j++) {\n      var z = tmp[j];\n      p;\n      if (z === 0)\n        continue;\n      else if (z > 0)\n        p = wnd[j][(z - 1) >> 1];\n      else if (z < 0)\n        p = wnd[j][(-z - 1) >> 1].neg();\n\n      if (p.type === 'affine')\n        acc = acc.mixedAdd(p);\n      else\n        acc = acc.add(p);\n    }\n  }\n  // Zeroify references\n  for (i = 0; i < len; i++)\n    wnd[i] = null;\n\n  if (jacobianResult)\n    return acc;\n  else\n    return acc.toP();\n};\n\nfunction BasePoint(curve, type) {\n  this.curve = curve;\n  this.type = type;\n  this.precomputed = null;\n}\nBaseCurve.BasePoint = BasePoint;\n\nBasePoint.prototype.eq = function eq(/*other*/) {\n  throw new Error('Not implemented');\n};\n\nBasePoint.prototype.validate = function validate() {\n  return this.curve.validate(this);\n};\n\nBaseCurve.prototype.decodePoint = function decodePoint(bytes, enc) {\n  bytes = utils.toArray(bytes, enc);\n\n  var len = this.p.byteLength();\n\n  // uncompressed, hybrid-odd, hybrid-even\n  if ((bytes[0] === 0x04 || bytes[0] === 0x06 || bytes[0] === 0x07) &&\n      bytes.length - 1 === 2 * len) {\n    if (bytes[0] === 0x06)\n      assert(bytes[bytes.length - 1] % 2 === 0);\n    else if (bytes[0] === 0x07)\n      assert(bytes[bytes.length - 1] % 2 === 1);\n\n    var res =  this.point(bytes.slice(1, 1 + len),\n      bytes.slice(1 + len, 1 + 2 * len));\n\n    return res;\n  } else if ((bytes[0] === 0x02 || bytes[0] === 0x03) &&\n              bytes.length - 1 === len) {\n    return this.pointFromX(bytes.slice(1, 1 + len), bytes[0] === 0x03);\n  }\n  throw new Error('Unknown point format');\n};\n\nBasePoint.prototype.encodeCompressed = function encodeCompressed(enc) {\n  return this.encode(enc, true);\n};\n\nBasePoint.prototype._encode = function _encode(compact) {\n  var len = this.curve.p.byteLength();\n  var x = this.getX().toArray('be', len);\n\n  if (compact)\n    return [ this.getY().isEven() ? 0x02 : 0x03 ].concat(x);\n\n  return [ 0x04 ].concat(x, this.getY().toArray('be', len));\n};\n\nBasePoint.prototype.encode = function encode(enc, compact) {\n  return utils.encode(this._encode(compact), enc);\n};\n\nBasePoint.prototype.precompute = function precompute(power) {\n  if (this.precomputed)\n    return this;\n\n  var precomputed = {\n    doubles: null,\n    naf: null,\n    beta: null,\n  };\n  precomputed.naf = this._getNAFPoints(8);\n  precomputed.doubles = this._getDoubles(4, power);\n  precomputed.beta = this._getBeta();\n  this.precomputed = precomputed;\n\n  return this;\n};\n\nBasePoint.prototype._hasDoubles = function _hasDoubles(k) {\n  if (!this.precomputed)\n    return false;\n\n  var doubles = this.precomputed.doubles;\n  if (!doubles)\n    return false;\n\n  return doubles.points.length >= Math.ceil((k.bitLength() + 1) / doubles.step);\n};\n\nBasePoint.prototype._getDoubles = function _getDoubles(step, power) {\n  if (this.precomputed && this.precomputed.doubles)\n    return this.precomputed.doubles;\n\n  var doubles = [ this ];\n  var acc = this;\n  for (var i = 0; i < power; i += step) {\n    for (var j = 0; j < step; j++)\n      acc = acc.dbl();\n    doubles.push(acc);\n  }\n  return {\n    step: step,\n    points: doubles,\n  };\n};\n\nBasePoint.prototype._getNAFPoints = function _getNAFPoints(wnd) {\n  if (this.precomputed && this.precomputed.naf)\n    return this.precomputed.naf;\n\n  var res = [ this ];\n  var max = (1 << wnd) - 1;\n  var dbl = max === 1 ? null : this.dbl();\n  for (var i = 1; i < max; i++)\n    res[i] = res[i - 1].add(dbl);\n  return {\n    wnd: wnd,\n    points: res,\n  };\n};\n\nBasePoint.prototype._getBeta = function _getBeta() {\n  return null;\n};\n\nBasePoint.prototype.dblp = function dblp(k) {\n  var r = this;\n  for (var i = 0; i < k; i++)\n    r = r.dbl();\n  return r;\n};\n","'use strict';\n\nvar objectAssign = require('object-assign');\n\n// compare and isBuffer taken from https://github.com/feross/buffer/blob/680e9e5e488f22aac27599a57dc844a6315928dd/index.js\n// original notice:\n\n/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>\n * @license  MIT\n */\nfunction compare(a, b) {\n  if (a === b) {\n    return 0;\n  }\n\n  var x = a.length;\n  var y = b.length;\n\n  for (var i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i];\n      y = b[i];\n      break;\n    }\n  }\n\n  if (x < y) {\n    return -1;\n  }\n  if (y < x) {\n    return 1;\n  }\n  return 0;\n}\nfunction isBuffer(b) {\n  if (global.Buffer && typeof global.Buffer.isBuffer === 'function') {\n    return global.Buffer.isBuffer(b);\n  }\n  return !!(b != null && b._isBuffer);\n}\n\n// based on node assert, original notice:\n// NB: The URL to the CommonJS spec is kept just for tradition.\n//     node-assert has evolved a lot since then, both in API and behavior.\n\n// http://wiki.commonjs.org/wiki/Unit_Testing/1.0\n//\n// THIS IS NOT TESTED NOR LIKELY TO WORK OUTSIDE V8!\n//\n// Originally from narwhal.js (http://narwhaljs.org)\n// Copyright (c) 2009 Thomas Robinson <280north.com>\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the 'Software'), to\n// deal in the Software without restriction, including without limitation the\n// rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n// sell copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n// ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n// WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar util = require('util/');\nvar hasOwn = Object.prototype.hasOwnProperty;\nvar pSlice = Array.prototype.slice;\nvar functionsHaveNames = (function () {\n  return function foo() {}.name === 'foo';\n}());\nfunction pToString (obj) {\n  return Object.prototype.toString.call(obj);\n}\nfunction isView(arrbuf) {\n  if (isBuffer(arrbuf)) {\n    return false;\n  }\n  if (typeof global.ArrayBuffer !== 'function') {\n    return false;\n  }\n  if (typeof ArrayBuffer.isView === 'function') {\n    return ArrayBuffer.isView(arrbuf);\n  }\n  if (!arrbuf) {\n    return false;\n  }\n  if (arrbuf instanceof DataView) {\n    return true;\n  }\n  if (arrbuf.buffer && arrbuf.buffer instanceof ArrayBuffer) {\n    return true;\n  }\n  return false;\n}\n// 1. The assert module provides functions that throw\n// AssertionError's when particular conditions are not met. The\n// assert module must conform to the following interface.\n\nvar assert = module.exports = ok;\n\n// 2. The AssertionError is defined in assert.\n// new assert.AssertionError({ message: message,\n//                             actual: actual,\n//                             expected: expected })\n\nvar regex = /\\s*function\\s+([^\\(\\s]*)\\s*/;\n// based on https://github.com/ljharb/function.prototype.name/blob/adeeeec8bfcc6068b187d7d9fb3d5bb1d3a30899/implementation.js\nfunction getName(func) {\n  if (!util.isFunction(func)) {\n    return;\n  }\n  if (functionsHaveNames) {\n    return func.name;\n  }\n  var str = func.toString();\n  var match = str.match(regex);\n  return match && match[1];\n}\nassert.AssertionError = function AssertionError(options) {\n  this.name = 'AssertionError';\n  this.actual = options.actual;\n  this.expected = options.expected;\n  this.operator = options.operator;\n  if (options.message) {\n    this.message = options.message;\n    this.generatedMessage = false;\n  } else {\n    this.message = getMessage(this);\n    this.generatedMessage = true;\n  }\n  var stackStartFunction = options.stackStartFunction || fail;\n  if (Error.captureStackTrace) {\n    Error.captureStackTrace(this, stackStartFunction);\n  } else {\n    // non v8 browsers so we can have a stacktrace\n    var err = new Error();\n    if (err.stack) {\n      var out = err.stack;\n\n      // try to strip useless frames\n      var fn_name = getName(stackStartFunction);\n      var idx = out.indexOf('\\n' + fn_name);\n      if (idx >= 0) {\n        // once we have located the function frame\n        // we need to strip out everything before it (and its line)\n        var next_line = out.indexOf('\\n', idx + 1);\n        out = out.substring(next_line + 1);\n      }\n\n      this.stack = out;\n    }\n  }\n};\n\n// assert.AssertionError instanceof Error\nutil.inherits(assert.AssertionError, Error);\n\nfunction truncate(s, n) {\n  if (typeof s === 'string') {\n    return s.length < n ? s : s.slice(0, n);\n  } else {\n    return s;\n  }\n}\nfunction inspect(something) {\n  if (functionsHaveNames || !util.isFunction(something)) {\n    return util.inspect(something);\n  }\n  var rawname = getName(something);\n  var name = rawname ? ': ' + rawname : '';\n  return '[Function' +  name + ']';\n}\nfunction getMessage(self) {\n  return truncate(inspect(self.actual), 128) + ' ' +\n         self.operator + ' ' +\n         truncate(inspect(self.expected), 128);\n}\n\n// At present only the three keys mentioned above are used and\n// understood by the spec. Implementations or sub modules can pass\n// other keys to the AssertionError's constructor - they will be\n// ignored.\n\n// 3. All of the following functions must throw an AssertionError\n// when a corresponding condition is not met, with a message that\n// may be undefined if not provided.  All assertion methods provide\n// both the actual and expected values to the assertion error for\n// display purposes.\n\nfunction fail(actual, expected, message, operator, stackStartFunction) {\n  throw new assert.AssertionError({\n    message: message,\n    actual: actual,\n    expected: expected,\n    operator: operator,\n    stackStartFunction: stackStartFunction\n  });\n}\n\n// EXTENSION! allows for well behaved errors defined elsewhere.\nassert.fail = fail;\n\n// 4. Pure assertion tests whether a value is truthy, as determined\n// by !!guard.\n// assert.ok(guard, message_opt);\n// This statement is equivalent to assert.equal(true, !!guard,\n// message_opt);. To test strictly for the value true, use\n// assert.strictEqual(true, guard, message_opt);.\n\nfunction ok(value, message) {\n  if (!value) fail(value, true, message, '==', assert.ok);\n}\nassert.ok = ok;\n\n// 5. The equality assertion tests shallow, coercive equality with\n// ==.\n// assert.equal(actual, expected, message_opt);\n\nassert.equal = function equal(actual, expected, message) {\n  if (actual != expected) fail(actual, expected, message, '==', assert.equal);\n};\n\n// 6. The non-equality assertion tests for whether two objects are not equal\n// with != assert.notEqual(actual, expected, message_opt);\n\nassert.notEqual = function notEqual(actual, expected, message) {\n  if (actual == expected) {\n    fail(actual, expected, message, '!=', assert.notEqual);\n  }\n};\n\n// 7. The equivalence assertion tests a deep equality relation.\n// assert.deepEqual(actual, expected, message_opt);\n\nassert.deepEqual = function deepEqual(actual, expected, message) {\n  if (!_deepEqual(actual, expected, false)) {\n    fail(actual, expected, message, 'deepEqual', assert.deepEqual);\n  }\n};\n\nassert.deepStrictEqual = function deepStrictEqual(actual, expected, message) {\n  if (!_deepEqual(actual, expected, true)) {\n    fail(actual, expected, message, 'deepStrictEqual', assert.deepStrictEqual);\n  }\n};\n\nfunction _deepEqual(actual, expected, strict, memos) {\n  // 7.1. All identical values are equivalent, as determined by ===.\n  if (actual === expected) {\n    return true;\n  } else if (isBuffer(actual) && isBuffer(expected)) {\n    return compare(actual, expected) === 0;\n\n  // 7.2. If the expected value is a Date object, the actual value is\n  // equivalent if it is also a Date object that refers to the same time.\n  } else if (util.isDate(actual) && util.isDate(expected)) {\n    return actual.getTime() === expected.getTime();\n\n  // 7.3 If the expected value is a RegExp object, the actual value is\n  // equivalent if it is also a RegExp object with the same source and\n  // properties (`global`, `multiline`, `lastIndex`, `ignoreCase`).\n  } else if (util.isRegExp(actual) && util.isRegExp(expected)) {\n    return actual.source === expected.source &&\n           actual.global === expected.global &&\n           actual.multiline === expected.multiline &&\n           actual.lastIndex === expected.lastIndex &&\n           actual.ignoreCase === expected.ignoreCase;\n\n  // 7.4. Other pairs that do not both pass typeof value == 'object',\n  // equivalence is determined by ==.\n  } else if ((actual === null || typeof actual !== 'object') &&\n             (expected === null || typeof expected !== 'object')) {\n    return strict ? actual === expected : actual == expected;\n\n  // If both values are instances of typed arrays, wrap their underlying\n  // ArrayBuffers in a Buffer each to increase performance\n  // This optimization requires the arrays to have the same type as checked by\n  // Object.prototype.toString (aka pToString). Never perform binary\n  // comparisons for Float*Arrays, though, since e.g. +0 === -0 but their\n  // bit patterns are not identical.\n  } else if (isView(actual) && isView(expected) &&\n             pToString(actual) === pToString(expected) &&\n             !(actual instanceof Float32Array ||\n               actual instanceof Float64Array)) {\n    return compare(new Uint8Array(actual.buffer),\n                   new Uint8Array(expected.buffer)) === 0;\n\n  // 7.5 For all other Object pairs, including Array objects, equivalence is\n  // determined by having the same number of owned properties (as verified\n  // with Object.prototype.hasOwnProperty.call), the same set of keys\n  // (although not necessarily the same order), equivalent values for every\n  // corresponding key, and an identical 'prototype' property. Note: this\n  // accounts for both named and indexed properties on Arrays.\n  } else if (isBuffer(actual) !== isBuffer(expected)) {\n    return false;\n  } else {\n    memos = memos || {actual: [], expected: []};\n\n    var actualIndex = memos.actual.indexOf(actual);\n    if (actualIndex !== -1) {\n      if (actualIndex === memos.expected.indexOf(expected)) {\n        return true;\n      }\n    }\n\n    memos.actual.push(actual);\n    memos.expected.push(expected);\n\n    return objEquiv(actual, expected, strict, memos);\n  }\n}\n\nfunction isArguments(object) {\n  return Object.prototype.toString.call(object) == '[object Arguments]';\n}\n\nfunction objEquiv(a, b, strict, actualVisitedObjects) {\n  if (a === null || a === undefined || b === null || b === undefined)\n    return false;\n  // if one is a primitive, the other must be same\n  if (util.isPrimitive(a) || util.isPrimitive(b))\n    return a === b;\n  if (strict && Object.getPrototypeOf(a) !== Object.getPrototypeOf(b))\n    return false;\n  var aIsArgs = isArguments(a);\n  var bIsArgs = isArguments(b);\n  if ((aIsArgs && !bIsArgs) || (!aIsArgs && bIsArgs))\n    return false;\n  if (aIsArgs) {\n    a = pSlice.call(a);\n    b = pSlice.call(b);\n    return _deepEqual(a, b, strict);\n  }\n  var ka = objectKeys(a);\n  var kb = objectKeys(b);\n  var key, i;\n  // having the same number of owned properties (keys incorporates\n  // hasOwnProperty)\n  if (ka.length !== kb.length)\n    return false;\n  //the same set of keys (although not necessarily the same order),\n  ka.sort();\n  kb.sort();\n  //~~~cheap key test\n  for (i = ka.length - 1; i >= 0; i--) {\n    if (ka[i] !== kb[i])\n      return false;\n  }\n  //equivalent values for every corresponding key, and\n  //~~~possibly expensive deep test\n  for (i = ka.length - 1; i >= 0; i--) {\n    key = ka[i];\n    if (!_deepEqual(a[key], b[key], strict, actualVisitedObjects))\n      return false;\n  }\n  return true;\n}\n\n// 8. The non-equivalence assertion tests for any deep inequality.\n// assert.notDeepEqual(actual, expected, message_opt);\n\nassert.notDeepEqual = function notDeepEqual(actual, expected, message) {\n  if (_deepEqual(actual, expected, false)) {\n    fail(actual, expected, message, 'notDeepEqual', assert.notDeepEqual);\n  }\n};\n\nassert.notDeepStrictEqual = notDeepStrictEqual;\nfunction notDeepStrictEqual(actual, expected, message) {\n  if (_deepEqual(actual, expected, true)) {\n    fail(actual, expected, message, 'notDeepStrictEqual', notDeepStrictEqual);\n  }\n}\n\n\n// 9. The strict equality assertion tests strict equality, as determined by ===.\n// assert.strictEqual(actual, expected, message_opt);\n\nassert.strictEqual = function strictEqual(actual, expected, message) {\n  if (actual !== expected) {\n    fail(actual, expected, message, '===', assert.strictEqual);\n  }\n};\n\n// 10. The strict non-equality assertion tests for strict inequality, as\n// determined by !==.  assert.notStrictEqual(actual, expected, message_opt);\n\nassert.notStrictEqual = function notStrictEqual(actual, expected, message) {\n  if (actual === expected) {\n    fail(actual, expected, message, '!==', assert.notStrictEqual);\n  }\n};\n\nfunction expectedException(actual, expected) {\n  if (!actual || !expected) {\n    return false;\n  }\n\n  if (Object.prototype.toString.call(expected) == '[object RegExp]') {\n    return expected.test(actual);\n  }\n\n  try {\n    if (actual instanceof expected) {\n      return true;\n    }\n  } catch (e) {\n    // Ignore.  The instanceof check doesn't work for arrow functions.\n  }\n\n  if (Error.isPrototypeOf(expected)) {\n    return false;\n  }\n\n  return expected.call({}, actual) === true;\n}\n\nfunction _tryBlock(block) {\n  var error;\n  try {\n    block();\n  } catch (e) {\n    error = e;\n  }\n  return error;\n}\n\nfunction _throws(shouldThrow, block, expected, message) {\n  var actual;\n\n  if (typeof block !== 'function') {\n    throw new TypeError('\"block\" argument must be a function');\n  }\n\n  if (typeof expected === 'string') {\n    message = expected;\n    expected = null;\n  }\n\n  actual = _tryBlock(block);\n\n  message = (expected && expected.name ? ' (' + expected.name + ').' : '.') +\n            (message ? ' ' + message : '.');\n\n  if (shouldThrow && !actual) {\n    fail(actual, expected, 'Missing expected exception' + message);\n  }\n\n  var userProvidedMessage = typeof message === 'string';\n  var isUnwantedException = !shouldThrow && util.isError(actual);\n  var isUnexpectedException = !shouldThrow && actual && !expected;\n\n  if ((isUnwantedException &&\n      userProvidedMessage &&\n      expectedException(actual, expected)) ||\n      isUnexpectedException) {\n    fail(actual, expected, 'Got unwanted exception' + message);\n  }\n\n  if ((shouldThrow && actual && expected &&\n      !expectedException(actual, expected)) || (!shouldThrow && actual)) {\n    throw actual;\n  }\n}\n\n// 11. Expected to throw an error:\n// assert.throws(block, Error_opt, message_opt);\n\nassert.throws = function(block, /*optional*/error, /*optional*/message) {\n  _throws(true, block, error, message);\n};\n\n// EXTENSION! This is annoying to write outside this module.\nassert.doesNotThrow = function(block, /*optional*/error, /*optional*/message) {\n  _throws(false, block, error, message);\n};\n\nassert.ifError = function(err) { if (err) throw err; };\n\n// Expose a strict only variant of assert\nfunction strict(value, message) {\n  if (!value) fail(value, true, message, '==', strict);\n}\nassert.strict = objectAssign(strict, assert, {\n  equal: assert.strictEqual,\n  deepEqual: assert.deepStrictEqual,\n  notEqual: assert.notStrictEqual,\n  notDeepEqual: assert.notDeepStrictEqual\n});\nassert.strict.strict = assert.strict;\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    if (hasOwn.call(obj, key)) keys.push(key);\n  }\n  return keys;\n};\n","'use strict';\n\nif (typeof process === 'undefined' ||\n    !process.version ||\n    process.version.indexOf('v0.') === 0 ||\n    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {\n  module.exports = { nextTick: nextTick };\n} else {\n  module.exports = process\n}\n\nfunction nextTick(fn, arg1, arg2, arg3) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('\"callback\" argument must be a function');\n  }\n  var len = arguments.length;\n  var args, i;\n  switch (len) {\n  case 0:\n  case 1:\n    return process.nextTick(fn);\n  case 2:\n    return process.nextTick(function afterTickOne() {\n      fn.call(null, arg1);\n    });\n  case 3:\n    return process.nextTick(function afterTickTwo() {\n      fn.call(null, arg1, arg2);\n    });\n  case 4:\n    return process.nextTick(function afterTickThree() {\n      fn.call(null, arg1, arg2, arg3);\n    });\n  default:\n    args = new Array(len - 1);\n    i = 0;\n    while (i < args.length) {\n      args[i++] = arguments[i];\n    }\n    return process.nextTick(function afterTick() {\n      fn.apply(null, args);\n    });\n  }\n}\n\n","var scope = (typeof global !== \"undefined\" && global) ||\n            (typeof self !== \"undefined\" && self) ||\n            window;\nvar apply = Function.prototype.apply;\n\n// DOM APIs, for completeness\n\nexports.setTimeout = function() {\n  return new Timeout(apply.call(setTimeout, scope, arguments), clearTimeout);\n};\nexports.setInterval = function() {\n  return new Timeout(apply.call(setInterval, scope, arguments), clearInterval);\n};\nexports.clearTimeout =\nexports.clearInterval = function(timeout) {\n  if (timeout) {\n    timeout.close();\n  }\n};\n\nfunction Timeout(id, clearFn) {\n  this._id = id;\n  this._clearFn = clearFn;\n}\nTimeout.prototype.unref = Timeout.prototype.ref = function() {};\nTimeout.prototype.close = function() {\n  this._clearFn.call(scope, this._id);\n};\n\n// Does not start the time, just sets up the members needed.\nexports.enroll = function(item, msecs) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = msecs;\n};\n\nexports.unenroll = function(item) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = -1;\n};\n\nexports._unrefActive = exports.active = function(item) {\n  clearTimeout(item._idleTimeoutId);\n\n  var msecs = item._idleTimeout;\n  if (msecs >= 0) {\n    item._idleTimeoutId = setTimeout(function onTimeout() {\n      if (item._onTimeout)\n        item._onTimeout();\n    }, msecs);\n  }\n};\n\n// setimmediate attaches itself to the global object\nrequire(\"setimmediate\");\n// On some exotic environments, it's not clear which object `setimmediate` was\n// able to install onto.  Search each possibility in the same order as the\n// `setimmediate` library.\nexports.setImmediate = (typeof self !== \"undefined\" && self.setImmediate) ||\n                       (typeof global !== \"undefined\" && global.setImmediate) ||\n                       (this && this.setImmediate);\nexports.clearImmediate = (typeof self !== \"undefined\" && self.clearImmediate) ||\n                         (typeof global !== \"undefined\" && global.clearImmediate) ||\n                         (this && this.clearImmediate);\n","(function (global, undefined) {\n    \"use strict\";\n\n    if (global.setImmediate) {\n        return;\n    }\n\n    var nextHandle = 1; // Spec says greater than zero\n    var tasksByHandle = {};\n    var currentlyRunningATask = false;\n    var doc = global.document;\n    var registerImmediate;\n\n    function setImmediate(callback) {\n      // Callback can either be a function or a string\n      if (typeof callback !== \"function\") {\n        callback = new Function(\"\" + callback);\n      }\n      // Copy function arguments\n      var args = new Array(arguments.length - 1);\n      for (var i = 0; i < args.length; i++) {\n          args[i] = arguments[i + 1];\n      }\n      // Store and register the task\n      var task = { callback: callback, args: args };\n      tasksByHandle[nextHandle] = task;\n      registerImmediate(nextHandle);\n      return nextHandle++;\n    }\n\n    function clearImmediate(handle) {\n        delete tasksByHandle[handle];\n    }\n\n    function run(task) {\n        var callback = task.callback;\n        var args = task.args;\n        switch (args.length) {\n        case 0:\n            callback();\n            break;\n        case 1:\n            callback(args[0]);\n            break;\n        case 2:\n            callback(args[0], args[1]);\n            break;\n        case 3:\n            callback(args[0], args[1], args[2]);\n            break;\n        default:\n            callback.apply(undefined, args);\n            break;\n        }\n    }\n\n    function runIfPresent(handle) {\n        // From the spec: \"Wait until any invocations of this algorithm started before this one have completed.\"\n        // So if we're currently running a task, we'll need to delay this invocation.\n        if (currentlyRunningATask) {\n            // Delay by doing a setTimeout. setImmediate was tried instead, but in Firefox 7 it generated a\n            // \"too much recursion\" error.\n            setTimeout(runIfPresent, 0, handle);\n        } else {\n            var task = tasksByHandle[handle];\n            if (task) {\n                currentlyRunningATask = true;\n                try {\n                    run(task);\n                } finally {\n                    clearImmediate(handle);\n                    currentlyRunningATask = false;\n                }\n            }\n        }\n    }\n\n    function installNextTickImplementation() {\n        registerImmediate = function(handle) {\n            process.nextTick(function () { runIfPresent(handle); });\n        };\n    }\n\n    function canUsePostMessage() {\n        // The test against `importScripts` prevents this implementation from being installed inside a web worker,\n        // where `global.postMessage` means something completely different and can't be used for this purpose.\n        if (global.postMessage && !global.importScripts) {\n            var postMessageIsAsynchronous = true;\n            var oldOnMessage = global.onmessage;\n            global.onmessage = function() {\n                postMessageIsAsynchronous = false;\n            };\n            global.postMessage(\"\", \"*\");\n            global.onmessage = oldOnMessage;\n            return postMessageIsAsynchronous;\n        }\n    }\n\n    function installPostMessageImplementation() {\n        // Installs an event handler on `global` for the `message` event: see\n        // * https://developer.mozilla.org/en/DOM/window.postMessage\n        // * http://www.whatwg.org/specs/web-apps/current-work/multipage/comms.html#crossDocumentMessages\n\n        var messagePrefix = \"setImmediate$\" + Math.random() + \"$\";\n        var onGlobalMessage = function(event) {\n            if (event.source === global &&\n                typeof event.data === \"string\" &&\n                event.data.indexOf(messagePrefix) === 0) {\n                runIfPresent(+event.data.slice(messagePrefix.length));\n            }\n        };\n\n        if (global.addEventListener) {\n            global.addEventListener(\"message\", onGlobalMessage, false);\n        } else {\n            global.attachEvent(\"onmessage\", onGlobalMessage);\n        }\n\n        registerImmediate = function(handle) {\n            global.postMessage(messagePrefix + handle, \"*\");\n        };\n    }\n\n    function installMessageChannelImplementation() {\n        var channel = new MessageChannel();\n        channel.port1.onmessage = function(event) {\n            var handle = event.data;\n            runIfPresent(handle);\n        };\n\n        registerImmediate = function(handle) {\n            channel.port2.postMessage(handle);\n        };\n    }\n\n    function installReadyStateChangeImplementation() {\n        var html = doc.documentElement;\n        registerImmediate = function(handle) {\n            // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n            // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n            var script = doc.createElement(\"script\");\n            script.onreadystatechange = function () {\n                runIfPresent(handle);\n                script.onreadystatechange = null;\n                html.removeChild(script);\n                script = null;\n            };\n            html.appendChild(script);\n        };\n    }\n\n    function installSetTimeoutImplementation() {\n        registerImmediate = function(handle) {\n            setTimeout(runIfPresent, 0, handle);\n        };\n    }\n\n    // If supported, we should attach to the prototype of global, since that is where setTimeout et al. live.\n    var attachTo = Object.getPrototypeOf && Object.getPrototypeOf(global);\n    attachTo = attachTo && attachTo.setTimeout ? attachTo : global;\n\n    // Don't get fooled by e.g. browserify environments.\n    if ({}.toString.call(global.process) === \"[object process]\") {\n        // For Node.js before 0.9\n        installNextTickImplementation();\n\n    } else if (canUsePostMessage()) {\n        // For non-IE10 modern browsers\n        installPostMessageImplementation();\n\n    } else if (global.MessageChannel) {\n        // For web workers, where supported\n        installMessageChannelImplementation();\n\n    } else if (doc && \"onreadystatechange\" in doc.createElement(\"script\")) {\n        // For IE 68\n        installReadyStateChangeImplementation();\n\n    } else {\n        // For older browsers\n        installSetTimeoutImplementation();\n    }\n\n    attachTo.setImmediate = setImmediate;\n    attachTo.clearImmediate = clearImmediate;\n}(typeof self === \"undefined\" ? typeof global === \"undefined\" ? this : global : self));\n","/**\n * Implementation of the multicodec specification.\n *\n * @module multicodec\n * @example\n * const multicodec = require('multicodec')\n *\n * const prefixedProtobuf = multicodec.addPrefix('protobuf', protobufBuffer)\n * // prefixedProtobuf 0x50...\n *\n */\n'use strict'\n\n/** @typedef {import('./generated-types').CodecName} CodecName */\n/** @typedef {import('./generated-types').CodecCode} CodecCode */\n\nconst varint = require('varint')\nconst uint8ArrayConcat = require('uint8arrays/concat')\nconst util = require('./util')\nconst { nameToVarint, constantToCode, nameToCode, codeToName } = require('./maps')\n\n/**\n * Prefix a buffer with a multicodec-packed.\n *\n * @param {CodecName|Uint8Array} multicodecStrOrCode\n * @param {Uint8Array} data\n * @returns {Uint8Array}\n */\nfunction addPrefix (multicodecStrOrCode, data) {\n  let prefix\n\n  if (multicodecStrOrCode instanceof Uint8Array) {\n    prefix = util.varintUint8ArrayEncode(multicodecStrOrCode)\n  } else {\n    if (nameToVarint[multicodecStrOrCode]) {\n      prefix = nameToVarint[multicodecStrOrCode]\n    } else {\n      throw new Error('multicodec not recognized')\n    }\n  }\n\n  return uint8ArrayConcat([prefix, data], prefix.length + data.length)\n}\n\n/**\n * Decapsulate the multicodec-packed prefix from the data.\n *\n * @param {Uint8Array} data\n * @returns {Uint8Array}\n */\nfunction rmPrefix (data) {\n  varint.decode(/** @type {Buffer} */(data))\n  return data.slice(varint.decode.bytes)\n}\n\n/**\n * Get the codec name of the prefixed data.\n *\n * @param {Uint8Array} prefixedData\n * @returns {CodecName}\n */\nfunction getNameFromData (prefixedData) {\n  const code = /** @type {CodecCode} */(varint.decode(/** @type {Buffer} */(prefixedData)))\n  const name = codeToName[code]\n  if (name === undefined) {\n    throw new Error(`Code \"${code}\" not found`)\n  }\n  return name\n}\n\n/**\n * Get the codec name from a code.\n *\n * @param {CodecCode} codec\n * @returns {CodecName}\n */\nfunction getNameFromCode (codec) {\n  return codeToName[codec]\n}\n\n/**\n * Get the code of the codec\n *\n * @param {CodecName} name\n * @returns {CodecCode}\n */\nfunction getCodeFromName (name) {\n  const code = nameToCode[name]\n  if (code === undefined) {\n    throw new Error(`Codec \"${name}\" not found`)\n  }\n  return code\n}\n\n/**\n * Get the code of the prefixed data.\n *\n * @param {Uint8Array} prefixedData\n * @returns {CodecCode}\n */\nfunction getCodeFromData (prefixedData) {\n  return /** @type {CodecCode} */(varint.decode(/** @type {Buffer} */(prefixedData)))\n}\n\n/**\n * Get the code as varint of a codec name.\n *\n * @param {CodecName} name\n * @returns {Uint8Array}\n */\nfunction getVarintFromName (name) {\n  const code = nameToVarint[name]\n  if (code === undefined) {\n    throw new Error(`Codec \"${name}\" not found`)\n  }\n  return code\n}\n\n/**\n * Get the varint of a code.\n *\n * @param {CodecCode} code\n * @returns {Uint8Array}\n */\nfunction getVarintFromCode (code) {\n  return util.varintEncode(code)\n}\n\n/**\n * Get the codec name of the prefixed data.\n *\n * @deprecated use getNameFromData instead.\n * @param {Uint8Array} prefixedData\n * @returns {CodecName}\n */\nfunction getCodec (prefixedData) {\n  return getNameFromData(prefixedData)\n}\n\n/**\n * Get the codec name from a code.\n *\n * @deprecated use getNameFromCode instead.\n * @param {CodecCode} codec\n * @returns {CodecName}\n */\nfunction getName (codec) {\n  return getNameFromCode(codec)\n}\n\n/**\n * Get the code of the codec\n *\n * @deprecated use getCodeFromName instead.\n * @param {CodecName} name\n * @returns {CodecCode}\n */\nfunction getNumber (name) {\n  return getCodeFromName(name)\n}\n\n/**\n * Get the code of the prefixed data.\n *\n * @deprecated use getCodeFromData instead.\n * @param {Uint8Array} prefixedData\n * @returns {CodecCode}\n */\nfunction getCode (prefixedData) {\n  return getCodeFromData(prefixedData)\n}\n\n/**\n * Get the code as varint of a codec name.\n *\n * @deprecated use getVarintFromName instead.\n * @param {CodecName} name\n * @returns {Uint8Array}\n */\nfunction getCodeVarint (name) {\n  return getVarintFromName(name)\n}\n\n/**\n * Get the varint of a code.\n *\n * @deprecated use getVarintFromCode instead.\n * @param {CodecCode} code\n * @returns {Array.<number>}\n */\nfunction getVarint (code) {\n  return Array.from(getVarintFromCode(code))\n}\n\nmodule.exports = {\n  addPrefix,\n  rmPrefix,\n  getNameFromData,\n  getNameFromCode,\n  getCodeFromName,\n  getCodeFromData,\n  getVarintFromName,\n  getVarintFromCode,\n  // Deprecated\n  getCodec,\n  getName,\n  getNumber,\n  getCode,\n  getCodeVarint,\n  getVarint,\n  // Make the constants top-level constants\n  ...constantToCode,\n  // Export the maps\n  nameToVarint,\n  nameToCode,\n  codeToName\n}\n","'use strict'\n\n/**\n * Returns a new Uint8Array created by concatenating the passed ArrayLikes\n *\n * @param {Array<ArrayLike<number>>} arrays\n * @param {number} [length]\n */\nfunction concat (arrays, length) {\n  if (!length) {\n    length = arrays.reduce((acc, curr) => acc + curr.length, 0)\n  }\n\n  const output = new Uint8Array(length)\n  let offset = 0\n\n  for (const arr of arrays) {\n    output.set(arr, offset)\n    offset += arr.length\n  }\n\n  return output\n}\n\nmodule.exports = concat\n","'use strict'\n\nconst { encoding: getCodec } = require('multibase')\nconst utf8Decoder = new TextDecoder('utf8')\n\n/**\n * @typedef {import('multibase/src/types').BaseName} BaseName\n */\n\n/**\n * Turns a Uint8Array of bytes into a string with each\n * character being the char code of the corresponding byte\n *\n * @param {Uint8Array} array - The array to turn into a string\n */\nfunction uint8ArrayToAsciiString (array) {\n  let string = ''\n\n  for (let i = 0; i < array.length; i++) {\n    string += String.fromCharCode(array[i])\n  }\n  return string\n}\n\n/**\n * Turns a `Uint8Array` into a string.\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {Uint8Array} array - The array to turn into a string\n * @param {BaseName | 'utf8' | 'utf-8' | 'ascii'} [encoding=utf8] - The encoding to use\n * @returns {string}\n */\nfunction toString (array, encoding = 'utf8') {\n  if (encoding === 'utf8' || encoding === 'utf-8') {\n    return utf8Decoder.decode(array)\n  }\n\n  if (encoding === 'ascii') {\n    return uint8ArrayToAsciiString(array)\n  }\n\n  return getCodec(encoding).encode(array)\n}\n\nmodule.exports = toString\n","/**\n * Implementation of the [multibase](https://github.com/multiformats/multibase) specification.\n *\n */\n'use strict'\n\nconst constants = require('./constants')\nconst { encodeText, decodeText, concat } = require('./util')\n\n/** @typedef {import('./base')} Base */\n/** @typedef {import(\"./types\").BaseNameOrCode} BaseNameOrCode */\n/** @typedef {import(\"./types\").BaseCode} BaseCode */\n/** @typedef {import(\"./types\").BaseName} BaseName */\n\n/**\n * Create a new Uint8Array with the multibase varint+code.\n *\n * @param {BaseNameOrCode} nameOrCode - The multibase name or code number.\n * @param {Uint8Array} buf - The data to be prefixed with multibase.\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction multibase (nameOrCode, buf) {\n  if (!buf) {\n    throw new Error('requires an encoded Uint8Array')\n  }\n  const { name, codeBuf } = encoding(nameOrCode)\n  validEncode(name, buf)\n\n  return concat([codeBuf, buf], codeBuf.length + buf.length)\n}\n\n/**\n * Encode data with the specified base and add the multibase prefix.\n *\n * @param {BaseNameOrCode} nameOrCode - The multibase name or code number.\n * @param {Uint8Array} buf - The data to be encoded.\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n *\n */\nfunction encode (nameOrCode, buf) {\n  const enc = encoding(nameOrCode)\n  const data = encodeText(enc.encode(buf))\n\n  return concat([enc.codeBuf, data], enc.codeBuf.length + data.length)\n}\n\n/**\n * Takes a Uint8Array or string encoded with multibase header, decodes it and\n * returns the decoded buffer\n *\n * @param {Uint8Array|string} data\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n *\n */\nfunction decode (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n  const prefix = data[0]\n\n  // Make all encodings case-insensitive except the ones that include upper and lower chars in the alphabet\n  if (['f', 'F', 'v', 'V', 't', 'T', 'b', 'B', 'c', 'C', 'h', 'k', 'K'].includes(prefix)) {\n    data = data.toLowerCase()\n  }\n  const enc = encoding(/** @type {BaseCode} */(data[0]))\n  return enc.decode(data.substring(1))\n}\n\n/**\n * Is the given data multibase encoded?\n *\n * @param {Uint8Array|string} data\n */\nfunction isEncoded (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n\n  // Ensure bufOrString is a string\n  if (Object.prototype.toString.call(data) !== '[object String]') {\n    return false\n  }\n\n  try {\n    const enc = encoding(/** @type {BaseCode} */(data[0]))\n    return enc.name\n  } catch (err) {\n    return false\n  }\n}\n\n/**\n * Validate encoded data\n *\n * @param {BaseNameOrCode} name\n * @param {Uint8Array} buf\n * @returns {void}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction validEncode (name, buf) {\n  const enc = encoding(name)\n  enc.decode(decodeText(buf))\n}\n\n/**\n * Get the encoding by name or code\n *\n * @param {BaseNameOrCode} nameOrCode\n * @returns {Base}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction encoding (nameOrCode) {\n  if (Object.prototype.hasOwnProperty.call(constants.names, /** @type {BaseName} */(nameOrCode))) {\n    return constants.names[/** @type {BaseName} */(nameOrCode)]\n  } else if (Object.prototype.hasOwnProperty.call(constants.codes, /** @type {BaseCode} */(nameOrCode))) {\n    return constants.codes[/** @type {BaseCode} */(nameOrCode)]\n  } else {\n    throw new Error(`Unsupported encoding: ${nameOrCode}`)\n  }\n}\n\n/**\n * Get encoding from data\n *\n * @param {string|Uint8Array} data\n * @returns {Base}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction encodingFromData (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n\n  return encoding(/** @type {BaseCode} */(data[0]))\n}\n\nexports = module.exports = multibase\nexports.encode = encode\nexports.decode = decode\nexports.isEncoded = isEncoded\nexports.encoding = encoding\nexports.encodingFromData = encodingFromData\nconst names = Object.freeze(constants.names)\nconst codes = Object.freeze(constants.codes)\nexports.names = names\nexports.codes = codes\n","'use strict'\n\nconst textDecoder = new TextDecoder()\n/**\n * @param {ArrayBufferView|ArrayBuffer} bytes\n * @returns {string}\n */\nconst decodeText = (bytes) => textDecoder.decode(bytes)\n\nconst textEncoder = new TextEncoder()\n/**\n * @param {string} text\n * @returns {Uint8Array}\n */\nconst encodeText = (text) => textEncoder.encode(text)\n\n/**\n * Returns a new Uint8Array created by concatenating the passed Arrays\n *\n * @param {Array<ArrayLike<number>>} arrs\n * @param {number} length\n * @returns {Uint8Array}\n */\nfunction concat (arrs, length) {\n  const output = new Uint8Array(length)\n  let offset = 0\n\n  for (const arr of arrs) {\n    output.set(arr, offset)\n    offset += arr.length\n  }\n\n  return output\n}\n\nmodule.exports = { decodeText, encodeText, concat }\n","/**\n * Implementation of the [multibase](https://github.com/multiformats/multibase) specification.\n *\n */\n'use strict'\n\nconst constants = require('./constants')\nconst { encodeText, decodeText, concat } = require('./util')\n\n/** @typedef {import('./base')} Base */\n/** @typedef {import(\"./types\").BaseNameOrCode} BaseNameOrCode */\n/** @typedef {import(\"./types\").BaseCode} BaseCode */\n/** @typedef {import(\"./types\").BaseName} BaseName */\n\n/**\n * Create a new Uint8Array with the multibase varint+code.\n *\n * @param {BaseNameOrCode} nameOrCode - The multibase name or code number.\n * @param {Uint8Array} buf - The data to be prefixed with multibase.\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction multibase (nameOrCode, buf) {\n  if (!buf) {\n    throw new Error('requires an encoded Uint8Array')\n  }\n  const { name, codeBuf } = encoding(nameOrCode)\n  validEncode(name, buf)\n\n  return concat([codeBuf, buf], codeBuf.length + buf.length)\n}\n\n/**\n * Encode data with the specified base and add the multibase prefix.\n *\n * @param {BaseNameOrCode} nameOrCode - The multibase name or code number.\n * @param {Uint8Array} buf - The data to be encoded.\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n *\n */\nfunction encode (nameOrCode, buf) {\n  const enc = encoding(nameOrCode)\n  const data = encodeText(enc.encode(buf))\n\n  return concat([enc.codeBuf, data], enc.codeBuf.length + data.length)\n}\n\n/**\n * Takes a Uint8Array or string encoded with multibase header, decodes it and\n * returns the decoded buffer\n *\n * @param {Uint8Array|string} data\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n *\n */\nfunction decode (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n  const prefix = data[0]\n\n  // Make all encodings case-insensitive except the ones that include upper and lower chars in the alphabet\n  if (['f', 'F', 'v', 'V', 't', 'T', 'b', 'B', 'c', 'C', 'h', 'k', 'K'].includes(prefix)) {\n    data = data.toLowerCase()\n  }\n  const enc = encoding(/** @type {BaseCode} */(data[0]))\n  return enc.decode(data.substring(1))\n}\n\n/**\n * Is the given data multibase encoded?\n *\n * @param {Uint8Array|string} data\n */\nfunction isEncoded (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n\n  // Ensure bufOrString is a string\n  if (Object.prototype.toString.call(data) !== '[object String]') {\n    return false\n  }\n\n  try {\n    const enc = encoding(/** @type {BaseCode} */(data[0]))\n    return enc.name\n  } catch (err) {\n    return false\n  }\n}\n\n/**\n * Validate encoded data\n *\n * @param {BaseNameOrCode} name\n * @param {Uint8Array} buf\n * @returns {void}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction validEncode (name, buf) {\n  const enc = encoding(name)\n  enc.decode(decodeText(buf))\n}\n\n/**\n * Get the encoding by name or code\n *\n * @param {BaseNameOrCode} nameOrCode\n * @returns {Base}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction encoding (nameOrCode) {\n  if (Object.prototype.hasOwnProperty.call(constants.names, /** @type {BaseName} */(nameOrCode))) {\n    return constants.names[/** @type {BaseName} */(nameOrCode)]\n  } else if (Object.prototype.hasOwnProperty.call(constants.codes, /** @type {BaseCode} */(nameOrCode))) {\n    return constants.codes[/** @type {BaseCode} */(nameOrCode)]\n  } else {\n    throw new Error(`Unsupported encoding: ${nameOrCode}`)\n  }\n}\n\n/**\n * Get encoding from data\n *\n * @param {string|Uint8Array} data\n * @returns {Base}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction encodingFromData (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n\n  return encoding(/** @type {BaseCode} */(data[0]))\n}\n\nexports = module.exports = multibase\nexports.encode = encode\nexports.decode = decode\nexports.isEncoded = isEncoded\nexports.encoding = encoding\nexports.encodingFromData = encodingFromData\nconst names = Object.freeze(constants.names)\nconst codes = Object.freeze(constants.codes)\nexports.names = names\nexports.codes = codes\n","'use strict'\n\nconst textDecoder = new TextDecoder()\n/**\n * @param {ArrayBufferView|ArrayBuffer} bytes\n * @returns {string}\n */\nconst decodeText = (bytes) => textDecoder.decode(bytes)\n\nconst textEncoder = new TextEncoder()\n/**\n * @param {string} text\n * @returns {Uint8Array}\n */\nconst encodeText = (text) => textEncoder.encode(text)\n\n/**\n * Returns a new Uint8Array created by concatenating the passed Arrays\n *\n * @param {Array<ArrayLike<number>>} arrs\n * @param {number} length\n * @returns {Uint8Array}\n */\nfunction concat (arrs, length) {\n  const output = new Uint8Array(length)\n  let offset = 0\n\n  for (const arr of arrs) {\n    output.set(arr, offset)\n    offset += arr.length\n  }\n\n  return output\n}\n\nmodule.exports = { decodeText, encodeText, concat }\n","'use strict'\n\nconst { encoding: getCodec } = require('multibase')\nconst utf8Encoder = new TextEncoder()\n\n/**\n * @typedef {import('multibase/src/types').BaseName} BaseName\n */\n\n/**\n * Interprets each character in a string as a byte and\n * returns a Uint8Array of those bytes.\n *\n * @param {string} string - The string to turn into an array\n */\nfunction asciiStringToUint8Array (string) {\n  const array = new Uint8Array(string.length)\n\n  for (let i = 0; i < string.length; i++) {\n    array[i] = string.charCodeAt(i)\n  }\n\n  return array\n}\n\n/**\n * Create a `Uint8Array` from the passed string\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {string} string\n * @param {BaseName | 'utf8' | 'utf-8' | 'ascii'} [encoding=utf8] - utf8, base16, base64, base64urlpad, etc\n * @returns {Uint8Array}\n */\nfunction fromString (string, encoding = 'utf8') {\n  if (encoding === 'utf8' || encoding === 'utf-8') {\n    return utf8Encoder.encode(string)\n  }\n\n  if (encoding === 'ascii') {\n    return asciiStringToUint8Array(string)\n  }\n\n  return getCodec(encoding).decode(string)\n}\n\nmodule.exports = fromString\n","/**\n * Implementation of the [multibase](https://github.com/multiformats/multibase) specification.\n *\n */\n'use strict'\n\nconst constants = require('./constants')\nconst { encodeText, decodeText, concat } = require('./util')\n\n/** @typedef {import('./base')} Base */\n/** @typedef {import(\"./types\").BaseNameOrCode} BaseNameOrCode */\n/** @typedef {import(\"./types\").BaseCode} BaseCode */\n/** @typedef {import(\"./types\").BaseName} BaseName */\n\n/**\n * Create a new Uint8Array with the multibase varint+code.\n *\n * @param {BaseNameOrCode} nameOrCode - The multibase name or code number.\n * @param {Uint8Array} buf - The data to be prefixed with multibase.\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction multibase (nameOrCode, buf) {\n  if (!buf) {\n    throw new Error('requires an encoded Uint8Array')\n  }\n  const { name, codeBuf } = encoding(nameOrCode)\n  validEncode(name, buf)\n\n  return concat([codeBuf, buf], codeBuf.length + buf.length)\n}\n\n/**\n * Encode data with the specified base and add the multibase prefix.\n *\n * @param {BaseNameOrCode} nameOrCode - The multibase name or code number.\n * @param {Uint8Array} buf - The data to be encoded.\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n *\n */\nfunction encode (nameOrCode, buf) {\n  const enc = encoding(nameOrCode)\n  const data = encodeText(enc.encode(buf))\n\n  return concat([enc.codeBuf, data], enc.codeBuf.length + data.length)\n}\n\n/**\n * Takes a Uint8Array or string encoded with multibase header, decodes it and\n * returns the decoded buffer\n *\n * @param {Uint8Array|string} data\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n *\n */\nfunction decode (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n  const prefix = data[0]\n\n  // Make all encodings case-insensitive except the ones that include upper and lower chars in the alphabet\n  if (['f', 'F', 'v', 'V', 't', 'T', 'b', 'B', 'c', 'C', 'h', 'k', 'K'].includes(prefix)) {\n    data = data.toLowerCase()\n  }\n  const enc = encoding(/** @type {BaseCode} */(data[0]))\n  return enc.decode(data.substring(1))\n}\n\n/**\n * Is the given data multibase encoded?\n *\n * @param {Uint8Array|string} data\n * @returns {false | string}\n */\nfunction isEncoded (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n\n  // Ensure bufOrString is a string\n  if (Object.prototype.toString.call(data) !== '[object String]') {\n    return false\n  }\n\n  try {\n    const enc = encoding(/** @type {BaseCode} */(data[0]))\n    return enc.name\n  } catch (err) {\n    return false\n  }\n}\n\n/**\n * Validate encoded data\n *\n * @param {BaseNameOrCode} name\n * @param {Uint8Array} buf\n * @returns {void}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction validEncode (name, buf) {\n  const enc = encoding(name)\n  enc.decode(decodeText(buf))\n}\n\n/**\n * Get the encoding by name or code\n *\n * @param {BaseNameOrCode} nameOrCode\n * @returns {Base}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction encoding (nameOrCode) {\n  if (Object.prototype.hasOwnProperty.call(constants.names, /** @type {BaseName} */(nameOrCode))) {\n    return constants.names[/** @type {BaseName} */(nameOrCode)]\n  } else if (Object.prototype.hasOwnProperty.call(constants.codes, /** @type {BaseCode} */(nameOrCode))) {\n    return constants.codes[/** @type {BaseCode} */(nameOrCode)]\n  } else {\n    throw new Error(`Unsupported encoding: ${nameOrCode}`)\n  }\n}\n\n/**\n * Get encoding from data\n *\n * @param {string|Uint8Array} data\n * @returns {Base}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction encodingFromData (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n\n  return encoding(/** @type {BaseCode} */(data[0]))\n}\n\nexports = module.exports = multibase\nexports.encode = encode\nexports.decode = decode\nexports.isEncoded = isEncoded\nexports.encoding = encoding\nexports.encodingFromData = encodingFromData\nconst names = Object.freeze(constants.names)\nconst codes = Object.freeze(constants.codes)\nexports.names = names\nexports.codes = codes\n","'use strict'\n\n// @ts-ignore\nconst { TextEncoder, TextDecoder } = require('web-encoding')\n\nconst textDecoder = new TextDecoder()\n/**\n * @param {ArrayBufferView|ArrayBuffer} bytes\n * @returns {string}\n */\nconst decodeText = (bytes) => textDecoder.decode(bytes)\n\nconst textEncoder = new TextEncoder()\n/**\n * @param {string} text\n * @returns {Uint8Array}\n */\nconst encodeText = (text) => textEncoder.encode(text)\n\n/**\n * Returns a new Uint8Array created by concatenating the passed Arrays\n *\n * @param {Array<ArrayLike<number>>} arrs\n * @param {number} length\n * @returns {Uint8Array}\n */\nfunction concat (arrs, length) {\n  const output = new Uint8Array(length)\n  let offset = 0\n\n  for (const arr of arrs) {\n    output.set(arr, offset)\n    offset += arr.length\n  }\n\n  return output\n}\n\nmodule.exports = { decodeText, encodeText, concat }\n","'use strict'\n\nconst { encoding: getCodec } = require('multibase')\nconst { TextDecoder } = require('web-encoding')\nconst utf8Decoder = new TextDecoder('utf8')\n\n/**\n * @typedef {import('multibase/src/types').BaseName} BaseName\n */\n\n/**\n * Turns a Uint8Array of bytes into a string with each\n * character being the char code of the corresponding byte\n *\n * @param {Uint8Array} array - The array to turn into a string\n */\nfunction uint8ArrayToAsciiString (array) {\n  let string = ''\n\n  for (let i = 0; i < array.length; i++) {\n    string += String.fromCharCode(array[i])\n  }\n  return string\n}\n\n/**\n * Turns a `Uint8Array` into a string.\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {Uint8Array} array - The array to turn into a string\n * @param {BaseName | 'utf8' | 'utf-8' | 'ascii'} [encoding=utf8] - The encoding to use\n * @returns {string}\n */\nfunction toString (array, encoding = 'utf8') {\n  if (encoding === 'utf8' || encoding === 'utf-8') {\n    return utf8Decoder.decode(array)\n  }\n\n  if (encoding === 'ascii') {\n    return uint8ArrayToAsciiString(array)\n  }\n\n  return getCodec(encoding).encode(array)\n}\n\nmodule.exports = toString\n","'use strict'\n\nconst { encoding: getCodec } = require('multibase')\nconst { TextEncoder } = require('web-encoding')\nconst utf8Encoder = new TextEncoder()\n\n/**\n * @typedef {import('multibase/src/types').BaseName} BaseName\n */\n\n/**\n * Interprets each character in a string as a byte and\n * returns a Uint8Array of those bytes.\n *\n * @param {string} string - The string to turn into an array\n */\nfunction asciiStringToUint8Array (string) {\n  const array = new Uint8Array(string.length)\n\n  for (let i = 0; i < string.length; i++) {\n    array[i] = string.charCodeAt(i)\n  }\n\n  return array\n}\n\n/**\n * Create a `Uint8Array` from the passed string\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {string} string\n * @param {BaseName | 'utf8' | 'utf-8' | 'ascii'} [encoding=utf8] - utf8, base16, base64, base64urlpad, etc\n * @returns {Uint8Array}\n */\nfunction fromString (string, encoding = 'utf8') {\n  if (encoding === 'utf8' || encoding === 'utf-8') {\n    return utf8Encoder.encode(string)\n  }\n\n  if (encoding === 'ascii') {\n    return asciiStringToUint8Array(string)\n  }\n\n  return getCodec(encoding).decode(string)\n}\n\nmodule.exports = fromString\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst utils_1 = require(\"./utils\");\n// The default Buffer size if one is not provided.\nconst DEFAULT_SMARTBUFFER_SIZE = 4096;\n// The default string encoding to use for reading/writing strings.\nconst DEFAULT_SMARTBUFFER_ENCODING = 'utf8';\nclass SmartBuffer {\n    /**\n     * Creates a new SmartBuffer instance.\n     *\n     * @param options { SmartBufferOptions } The SmartBufferOptions to apply to this instance.\n     */\n    constructor(options) {\n        this.length = 0;\n        this._encoding = DEFAULT_SMARTBUFFER_ENCODING;\n        this._writeOffset = 0;\n        this._readOffset = 0;\n        if (SmartBuffer.isSmartBufferOptions(options)) {\n            // Checks for encoding\n            if (options.encoding) {\n                utils_1.checkEncoding(options.encoding);\n                this._encoding = options.encoding;\n            }\n            // Checks for initial size length\n            if (options.size) {\n                if (utils_1.isFiniteInteger(options.size) && options.size > 0) {\n                    this._buff = Buffer.allocUnsafe(options.size);\n                }\n                else {\n                    throw new Error(utils_1.ERRORS.INVALID_SMARTBUFFER_SIZE);\n                }\n                // Check for initial Buffer\n            }\n            else if (options.buff) {\n                if (options.buff instanceof Buffer) {\n                    this._buff = options.buff;\n                    this.length = options.buff.length;\n                }\n                else {\n                    throw new Error(utils_1.ERRORS.INVALID_SMARTBUFFER_BUFFER);\n                }\n            }\n            else {\n                this._buff = Buffer.allocUnsafe(DEFAULT_SMARTBUFFER_SIZE);\n            }\n        }\n        else {\n            // If something was passed but it's not a SmartBufferOptions object\n            if (typeof options !== 'undefined') {\n                throw new Error(utils_1.ERRORS.INVALID_SMARTBUFFER_OBJECT);\n            }\n            // Otherwise default to sane options\n            this._buff = Buffer.allocUnsafe(DEFAULT_SMARTBUFFER_SIZE);\n        }\n    }\n    /**\n     * Creates a new SmartBuffer instance with the provided internal Buffer size and optional encoding.\n     *\n     * @param size { Number } The size of the internal Buffer.\n     * @param encoding { String } The BufferEncoding to use for strings.\n     *\n     * @return { SmartBuffer }\n     */\n    static fromSize(size, encoding) {\n        return new this({\n            size: size,\n            encoding: encoding\n        });\n    }\n    /**\n     * Creates a new SmartBuffer instance with the provided Buffer and optional encoding.\n     *\n     * @param buffer { Buffer } The Buffer to use as the internal Buffer value.\n     * @param encoding { String } The BufferEncoding to use for strings.\n     *\n     * @return { SmartBuffer }\n     */\n    static fromBuffer(buff, encoding) {\n        return new this({\n            buff: buff,\n            encoding: encoding\n        });\n    }\n    /**\n     * Creates a new SmartBuffer instance with the provided SmartBufferOptions options.\n     *\n     * @param options { SmartBufferOptions } The options to use when creating the SmartBuffer instance.\n     */\n    static fromOptions(options) {\n        return new this(options);\n    }\n    /**\n     * Type checking function that determines if an object is a SmartBufferOptions object.\n     */\n    static isSmartBufferOptions(options) {\n        const castOptions = options;\n        return (castOptions &&\n            (castOptions.encoding !== undefined || castOptions.size !== undefined || castOptions.buff !== undefined));\n    }\n    // Signed integers\n    /**\n     * Reads an Int8 value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readInt8(offset) {\n        return this._readNumberValue(Buffer.prototype.readInt8, 1, offset);\n    }\n    /**\n     * Reads an Int16BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readInt16BE(offset) {\n        return this._readNumberValue(Buffer.prototype.readInt16BE, 2, offset);\n    }\n    /**\n     * Reads an Int16LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readInt16LE(offset) {\n        return this._readNumberValue(Buffer.prototype.readInt16LE, 2, offset);\n    }\n    /**\n     * Reads an Int32BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readInt32BE(offset) {\n        return this._readNumberValue(Buffer.prototype.readInt32BE, 4, offset);\n    }\n    /**\n     * Reads an Int32LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readInt32LE(offset) {\n        return this._readNumberValue(Buffer.prototype.readInt32LE, 4, offset);\n    }\n    /**\n     * Reads a BigInt64BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { BigInt }\n     */\n    readBigInt64BE(offset) {\n        utils_1.bigIntAndBufferInt64Check('readBigInt64BE');\n        return this._readNumberValue(Buffer.prototype.readBigInt64BE, 8, offset);\n    }\n    /**\n     * Reads a BigInt64LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { BigInt }\n     */\n    readBigInt64LE(offset) {\n        utils_1.bigIntAndBufferInt64Check('readBigInt64LE');\n        return this._readNumberValue(Buffer.prototype.readBigInt64LE, 8, offset);\n    }\n    /**\n     * Writes an Int8 value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeInt8(value, offset) {\n        this._writeNumberValue(Buffer.prototype.writeInt8, 1, value, offset);\n        return this;\n    }\n    /**\n     * Inserts an Int8 value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertInt8(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeInt8, 1, value, offset);\n    }\n    /**\n     * Writes an Int16BE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeInt16BE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeInt16BE, 2, value, offset);\n    }\n    /**\n     * Inserts an Int16BE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertInt16BE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeInt16BE, 2, value, offset);\n    }\n    /**\n     * Writes an Int16LE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeInt16LE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeInt16LE, 2, value, offset);\n    }\n    /**\n     * Inserts an Int16LE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertInt16LE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeInt16LE, 2, value, offset);\n    }\n    /**\n     * Writes an Int32BE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeInt32BE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeInt32BE, 4, value, offset);\n    }\n    /**\n     * Inserts an Int32BE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertInt32BE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeInt32BE, 4, value, offset);\n    }\n    /**\n     * Writes an Int32LE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeInt32LE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeInt32LE, 4, value, offset);\n    }\n    /**\n     * Inserts an Int32LE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertInt32LE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeInt32LE, 4, value, offset);\n    }\n    /**\n     * Writes a BigInt64BE value to the current write position (or at optional offset).\n     *\n     * @param value { BigInt } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeBigInt64BE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigInt64BE');\n        return this._writeNumberValue(Buffer.prototype.writeBigInt64BE, 8, value, offset);\n    }\n    /**\n     * Inserts a BigInt64BE value at the given offset value.\n     *\n     * @param value { BigInt } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertBigInt64BE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigInt64BE');\n        return this._insertNumberValue(Buffer.prototype.writeBigInt64BE, 8, value, offset);\n    }\n    /**\n     * Writes a BigInt64LE value to the current write position (or at optional offset).\n     *\n     * @param value { BigInt } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeBigInt64LE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigInt64LE');\n        return this._writeNumberValue(Buffer.prototype.writeBigInt64LE, 8, value, offset);\n    }\n    /**\n     * Inserts a Int64LE value at the given offset value.\n     *\n     * @param value { BigInt } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertBigInt64LE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigInt64LE');\n        return this._insertNumberValue(Buffer.prototype.writeBigInt64LE, 8, value, offset);\n    }\n    // Unsigned Integers\n    /**\n     * Reads an UInt8 value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readUInt8(offset) {\n        return this._readNumberValue(Buffer.prototype.readUInt8, 1, offset);\n    }\n    /**\n     * Reads an UInt16BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readUInt16BE(offset) {\n        return this._readNumberValue(Buffer.prototype.readUInt16BE, 2, offset);\n    }\n    /**\n     * Reads an UInt16LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readUInt16LE(offset) {\n        return this._readNumberValue(Buffer.prototype.readUInt16LE, 2, offset);\n    }\n    /**\n     * Reads an UInt32BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readUInt32BE(offset) {\n        return this._readNumberValue(Buffer.prototype.readUInt32BE, 4, offset);\n    }\n    /**\n     * Reads an UInt32LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readUInt32LE(offset) {\n        return this._readNumberValue(Buffer.prototype.readUInt32LE, 4, offset);\n    }\n    /**\n     * Reads a BigUInt64BE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { BigInt }\n     */\n    readBigUInt64BE(offset) {\n        utils_1.bigIntAndBufferInt64Check('readBigUInt64BE');\n        return this._readNumberValue(Buffer.prototype.readBigUInt64BE, 8, offset);\n    }\n    /**\n     * Reads a BigUInt64LE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { BigInt }\n     */\n    readBigUInt64LE(offset) {\n        utils_1.bigIntAndBufferInt64Check('readBigUInt64LE');\n        return this._readNumberValue(Buffer.prototype.readBigUInt64LE, 8, offset);\n    }\n    /**\n     * Writes an UInt8 value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeUInt8(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeUInt8, 1, value, offset);\n    }\n    /**\n     * Inserts an UInt8 value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertUInt8(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeUInt8, 1, value, offset);\n    }\n    /**\n     * Writes an UInt16BE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeUInt16BE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeUInt16BE, 2, value, offset);\n    }\n    /**\n     * Inserts an UInt16BE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertUInt16BE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeUInt16BE, 2, value, offset);\n    }\n    /**\n     * Writes an UInt16LE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeUInt16LE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeUInt16LE, 2, value, offset);\n    }\n    /**\n     * Inserts an UInt16LE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertUInt16LE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeUInt16LE, 2, value, offset);\n    }\n    /**\n     * Writes an UInt32BE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeUInt32BE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeUInt32BE, 4, value, offset);\n    }\n    /**\n     * Inserts an UInt32BE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertUInt32BE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeUInt32BE, 4, value, offset);\n    }\n    /**\n     * Writes an UInt32LE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeUInt32LE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeUInt32LE, 4, value, offset);\n    }\n    /**\n     * Inserts an UInt32LE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertUInt32LE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeUInt32LE, 4, value, offset);\n    }\n    /**\n     * Writes a BigUInt64BE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeBigUInt64BE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigUInt64BE');\n        return this._writeNumberValue(Buffer.prototype.writeBigUInt64BE, 8, value, offset);\n    }\n    /**\n     * Inserts a BigUInt64BE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertBigUInt64BE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigUInt64BE');\n        return this._insertNumberValue(Buffer.prototype.writeBigUInt64BE, 8, value, offset);\n    }\n    /**\n     * Writes a BigUInt64LE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeBigUInt64LE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigUInt64LE');\n        return this._writeNumberValue(Buffer.prototype.writeBigUInt64LE, 8, value, offset);\n    }\n    /**\n     * Inserts a BigUInt64LE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertBigUInt64LE(value, offset) {\n        utils_1.bigIntAndBufferInt64Check('writeBigUInt64LE');\n        return this._insertNumberValue(Buffer.prototype.writeBigUInt64LE, 8, value, offset);\n    }\n    // Floating Point\n    /**\n     * Reads an FloatBE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readFloatBE(offset) {\n        return this._readNumberValue(Buffer.prototype.readFloatBE, 4, offset);\n    }\n    /**\n     * Reads an FloatLE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readFloatLE(offset) {\n        return this._readNumberValue(Buffer.prototype.readFloatLE, 4, offset);\n    }\n    /**\n     * Writes a FloatBE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeFloatBE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeFloatBE, 4, value, offset);\n    }\n    /**\n     * Inserts a FloatBE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertFloatBE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeFloatBE, 4, value, offset);\n    }\n    /**\n     * Writes a FloatLE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeFloatLE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeFloatLE, 4, value, offset);\n    }\n    /**\n     * Inserts a FloatLE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertFloatLE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeFloatLE, 4, value, offset);\n    }\n    // Double Floating Point\n    /**\n     * Reads an DoublEBE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readDoubleBE(offset) {\n        return this._readNumberValue(Buffer.prototype.readDoubleBE, 8, offset);\n    }\n    /**\n     * Reads an DoubleLE value from the current read position or an optionally provided offset.\n     *\n     * @param offset { Number } The offset to read data from (optional)\n     * @return { Number }\n     */\n    readDoubleLE(offset) {\n        return this._readNumberValue(Buffer.prototype.readDoubleLE, 8, offset);\n    }\n    /**\n     * Writes a DoubleBE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeDoubleBE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeDoubleBE, 8, value, offset);\n    }\n    /**\n     * Inserts a DoubleBE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertDoubleBE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeDoubleBE, 8, value, offset);\n    }\n    /**\n     * Writes a DoubleLE value to the current write position (or at optional offset).\n     *\n     * @param value { Number } The value to write.\n     * @param offset { Number } The offset to write the value at.\n     *\n     * @return this\n     */\n    writeDoubleLE(value, offset) {\n        return this._writeNumberValue(Buffer.prototype.writeDoubleLE, 8, value, offset);\n    }\n    /**\n     * Inserts a DoubleLE value at the given offset value.\n     *\n     * @param value { Number } The value to insert.\n     * @param offset { Number } The offset to insert the value at.\n     *\n     * @return this\n     */\n    insertDoubleLE(value, offset) {\n        return this._insertNumberValue(Buffer.prototype.writeDoubleLE, 8, value, offset);\n    }\n    // Strings\n    /**\n     * Reads a String from the current read position.\n     *\n     * @param arg1 { Number | String } The number of bytes to read as a String, or the BufferEncoding to use for\n     *             the string (Defaults to instance level encoding).\n     * @param encoding { String } The BufferEncoding to use for the string (Defaults to instance level encoding).\n     *\n     * @return { String }\n     */\n    readString(arg1, encoding) {\n        let lengthVal;\n        // Length provided\n        if (typeof arg1 === 'number') {\n            utils_1.checkLengthValue(arg1);\n            lengthVal = Math.min(arg1, this.length - this._readOffset);\n        }\n        else {\n            encoding = arg1;\n            lengthVal = this.length - this._readOffset;\n        }\n        // Check encoding\n        if (typeof encoding !== 'undefined') {\n            utils_1.checkEncoding(encoding);\n        }\n        const value = this._buff.slice(this._readOffset, this._readOffset + lengthVal).toString(encoding || this._encoding);\n        this._readOffset += lengthVal;\n        return value;\n    }\n    /**\n     * Inserts a String\n     *\n     * @param value { String } The String value to insert.\n     * @param offset { Number } The offset to insert the string at.\n     * @param encoding { String } The BufferEncoding to use for writing strings (defaults to instance encoding).\n     *\n     * @return this\n     */\n    insertString(value, offset, encoding) {\n        utils_1.checkOffsetValue(offset);\n        return this._handleString(value, true, offset, encoding);\n    }\n    /**\n     * Writes a String\n     *\n     * @param value { String } The String value to write.\n     * @param arg2 { Number | String } The offset to write the string at, or the BufferEncoding to use.\n     * @param encoding { String } The BufferEncoding to use for writing strings (defaults to instance encoding).\n     *\n     * @return this\n     */\n    writeString(value, arg2, encoding) {\n        return this._handleString(value, false, arg2, encoding);\n    }\n    /**\n     * Reads a null-terminated String from the current read position.\n     *\n     * @param encoding { String } The BufferEncoding to use for the string (Defaults to instance level encoding).\n     *\n     * @return { String }\n     */\n    readStringNT(encoding) {\n        if (typeof encoding !== 'undefined') {\n            utils_1.checkEncoding(encoding);\n        }\n        // Set null character position to the end SmartBuffer instance.\n        let nullPos = this.length;\n        // Find next null character (if one is not found, default from above is used)\n        for (let i = this._readOffset; i < this.length; i++) {\n            if (this._buff[i] === 0x00) {\n                nullPos = i;\n                break;\n            }\n        }\n        // Read string value\n        const value = this._buff.slice(this._readOffset, nullPos);\n        // Increment internal Buffer read offset\n        this._readOffset = nullPos + 1;\n        return value.toString(encoding || this._encoding);\n    }\n    /**\n     * Inserts a null-terminated String.\n     *\n     * @param value { String } The String value to write.\n     * @param arg2 { Number | String } The offset to write the string to, or the BufferEncoding to use.\n     * @param encoding { String } The BufferEncoding to use for writing strings (defaults to instance encoding).\n     *\n     * @return this\n     */\n    insertStringNT(value, offset, encoding) {\n        utils_1.checkOffsetValue(offset);\n        // Write Values\n        this.insertString(value, offset, encoding);\n        this.insertUInt8(0x00, offset + value.length);\n        return this;\n    }\n    /**\n     * Writes a null-terminated String.\n     *\n     * @param value { String } The String value to write.\n     * @param arg2 { Number | String } The offset to write the string to, or the BufferEncoding to use.\n     * @param encoding { String } The BufferEncoding to use for writing strings (defaults to instance encoding).\n     *\n     * @return this\n     */\n    writeStringNT(value, arg2, encoding) {\n        // Write Values\n        this.writeString(value, arg2, encoding);\n        this.writeUInt8(0x00, typeof arg2 === 'number' ? arg2 + value.length : this.writeOffset);\n        return this;\n    }\n    // Buffers\n    /**\n     * Reads a Buffer from the internal read position.\n     *\n     * @param length { Number } The length of data to read as a Buffer.\n     *\n     * @return { Buffer }\n     */\n    readBuffer(length) {\n        if (typeof length !== 'undefined') {\n            utils_1.checkLengthValue(length);\n        }\n        const lengthVal = typeof length === 'number' ? length : this.length;\n        const endPoint = Math.min(this.length, this._readOffset + lengthVal);\n        // Read buffer value\n        const value = this._buff.slice(this._readOffset, endPoint);\n        // Increment internal Buffer read offset\n        this._readOffset = endPoint;\n        return value;\n    }\n    /**\n     * Writes a Buffer to the current write position.\n     *\n     * @param value { Buffer } The Buffer to write.\n     * @param offset { Number } The offset to write the Buffer to.\n     *\n     * @return this\n     */\n    insertBuffer(value, offset) {\n        utils_1.checkOffsetValue(offset);\n        return this._handleBuffer(value, true, offset);\n    }\n    /**\n     * Writes a Buffer to the current write position.\n     *\n     * @param value { Buffer } The Buffer to write.\n     * @param offset { Number } The offset to write the Buffer to.\n     *\n     * @return this\n     */\n    writeBuffer(value, offset) {\n        return this._handleBuffer(value, false, offset);\n    }\n    /**\n     * Reads a null-terminated Buffer from the current read poisiton.\n     *\n     * @return { Buffer }\n     */\n    readBufferNT() {\n        // Set null character position to the end SmartBuffer instance.\n        let nullPos = this.length;\n        // Find next null character (if one is not found, default from above is used)\n        for (let i = this._readOffset; i < this.length; i++) {\n            if (this._buff[i] === 0x00) {\n                nullPos = i;\n                break;\n            }\n        }\n        // Read value\n        const value = this._buff.slice(this._readOffset, nullPos);\n        // Increment internal Buffer read offset\n        this._readOffset = nullPos + 1;\n        return value;\n    }\n    /**\n     * Inserts a null-terminated Buffer.\n     *\n     * @param value { Buffer } The Buffer to write.\n     * @param offset { Number } The offset to write the Buffer to.\n     *\n     * @return this\n     */\n    insertBufferNT(value, offset) {\n        utils_1.checkOffsetValue(offset);\n        // Write Values\n        this.insertBuffer(value, offset);\n        this.insertUInt8(0x00, offset + value.length);\n        return this;\n    }\n    /**\n     * Writes a null-terminated Buffer.\n     *\n     * @param value { Buffer } The Buffer to write.\n     * @param offset { Number } The offset to write the Buffer to.\n     *\n     * @return this\n     */\n    writeBufferNT(value, offset) {\n        // Checks for valid numberic value;\n        if (typeof offset !== 'undefined') {\n            utils_1.checkOffsetValue(offset);\n        }\n        // Write Values\n        this.writeBuffer(value, offset);\n        this.writeUInt8(0x00, typeof offset === 'number' ? offset + value.length : this._writeOffset);\n        return this;\n    }\n    /**\n     * Clears the SmartBuffer instance to its original empty state.\n     */\n    clear() {\n        this._writeOffset = 0;\n        this._readOffset = 0;\n        this.length = 0;\n        return this;\n    }\n    /**\n     * Gets the remaining data left to be read from the SmartBuffer instance.\n     *\n     * @return { Number }\n     */\n    remaining() {\n        return this.length - this._readOffset;\n    }\n    /**\n     * Gets the current read offset value of the SmartBuffer instance.\n     *\n     * @return { Number }\n     */\n    get readOffset() {\n        return this._readOffset;\n    }\n    /**\n     * Sets the read offset value of the SmartBuffer instance.\n     *\n     * @param offset { Number } - The offset value to set.\n     */\n    set readOffset(offset) {\n        utils_1.checkOffsetValue(offset);\n        // Check for bounds.\n        utils_1.checkTargetOffset(offset, this);\n        this._readOffset = offset;\n    }\n    /**\n     * Gets the current write offset value of the SmartBuffer instance.\n     *\n     * @return { Number }\n     */\n    get writeOffset() {\n        return this._writeOffset;\n    }\n    /**\n     * Sets the write offset value of the SmartBuffer instance.\n     *\n     * @param offset { Number } - The offset value to set.\n     */\n    set writeOffset(offset) {\n        utils_1.checkOffsetValue(offset);\n        // Check for bounds.\n        utils_1.checkTargetOffset(offset, this);\n        this._writeOffset = offset;\n    }\n    /**\n     * Gets the currently set string encoding of the SmartBuffer instance.\n     *\n     * @return { BufferEncoding } The string Buffer encoding currently set.\n     */\n    get encoding() {\n        return this._encoding;\n    }\n    /**\n     * Sets the string encoding of the SmartBuffer instance.\n     *\n     * @param encoding { BufferEncoding } The string Buffer encoding to set.\n     */\n    set encoding(encoding) {\n        utils_1.checkEncoding(encoding);\n        this._encoding = encoding;\n    }\n    /**\n     * Gets the underlying internal Buffer. (This includes unmanaged data in the Buffer)\n     *\n     * @return { Buffer } The Buffer value.\n     */\n    get internalBuffer() {\n        return this._buff;\n    }\n    /**\n     * Gets the value of the internal managed Buffer (Includes managed data only)\n     *\n     * @param { Buffer }\n     */\n    toBuffer() {\n        return this._buff.slice(0, this.length);\n    }\n    /**\n     * Gets the String value of the internal managed Buffer\n     *\n     * @param encoding { String } The BufferEncoding to display the Buffer as (defaults to instance level encoding).\n     */\n    toString(encoding) {\n        const encodingVal = typeof encoding === 'string' ? encoding : this._encoding;\n        // Check for invalid encoding.\n        utils_1.checkEncoding(encodingVal);\n        return this._buff.toString(encodingVal, 0, this.length);\n    }\n    /**\n     * Destroys the SmartBuffer instance.\n     */\n    destroy() {\n        this.clear();\n        return this;\n    }\n    /**\n     * Handles inserting and writing strings.\n     *\n     * @param value { String } The String value to insert.\n     * @param isInsert { Boolean } True if inserting a string, false if writing.\n     * @param arg2 { Number | String } The offset to insert the string at, or the BufferEncoding to use.\n     * @param encoding { String } The BufferEncoding to use for writing strings (defaults to instance encoding).\n     */\n    _handleString(value, isInsert, arg3, encoding) {\n        let offsetVal = this._writeOffset;\n        let encodingVal = this._encoding;\n        // Check for offset\n        if (typeof arg3 === 'number') {\n            offsetVal = arg3;\n            // Check for encoding\n        }\n        else if (typeof arg3 === 'string') {\n            utils_1.checkEncoding(arg3);\n            encodingVal = arg3;\n        }\n        // Check for encoding (third param)\n        if (typeof encoding === 'string') {\n            utils_1.checkEncoding(encoding);\n            encodingVal = encoding;\n        }\n        // Calculate bytelength of string.\n        const byteLength = Buffer.byteLength(value, encodingVal);\n        // Ensure there is enough internal Buffer capacity.\n        if (isInsert) {\n            this.ensureInsertable(byteLength, offsetVal);\n        }\n        else {\n            this._ensureWriteable(byteLength, offsetVal);\n        }\n        // Write value\n        this._buff.write(value, offsetVal, byteLength, encodingVal);\n        // Increment internal Buffer write offset;\n        if (isInsert) {\n            this._writeOffset += byteLength;\n        }\n        else {\n            // If an offset was given, check to see if we wrote beyond the current writeOffset.\n            if (typeof arg3 === 'number') {\n                this._writeOffset = Math.max(this._writeOffset, offsetVal + byteLength);\n            }\n            else {\n                // If no offset was given, we wrote to the end of the SmartBuffer so increment writeOffset.\n                this._writeOffset += byteLength;\n            }\n        }\n        return this;\n    }\n    /**\n     * Handles writing or insert of a Buffer.\n     *\n     * @param value { Buffer } The Buffer to write.\n     * @param offset { Number } The offset to write the Buffer to.\n     */\n    _handleBuffer(value, isInsert, offset) {\n        const offsetVal = typeof offset === 'number' ? offset : this._writeOffset;\n        // Ensure there is enough internal Buffer capacity.\n        if (isInsert) {\n            this.ensureInsertable(value.length, offsetVal);\n        }\n        else {\n            this._ensureWriteable(value.length, offsetVal);\n        }\n        // Write buffer value\n        value.copy(this._buff, offsetVal);\n        // Increment internal Buffer write offset;\n        if (isInsert) {\n            this._writeOffset += value.length;\n        }\n        else {\n            // If an offset was given, check to see if we wrote beyond the current writeOffset.\n            if (typeof offset === 'number') {\n                this._writeOffset = Math.max(this._writeOffset, offsetVal + value.length);\n            }\n            else {\n                // If no offset was given, we wrote to the end of the SmartBuffer so increment writeOffset.\n                this._writeOffset += value.length;\n            }\n        }\n        return this;\n    }\n    /**\n     * Ensures that the internal Buffer is large enough to read data.\n     *\n     * @param length { Number } The length of the data that needs to be read.\n     * @param offset { Number } The offset of the data that needs to be read.\n     */\n    ensureReadable(length, offset) {\n        // Offset value defaults to managed read offset.\n        let offsetVal = this._readOffset;\n        // If an offset was provided, use it.\n        if (typeof offset !== 'undefined') {\n            // Checks for valid numberic value;\n            utils_1.checkOffsetValue(offset);\n            // Overide with custom offset.\n            offsetVal = offset;\n        }\n        // Checks if offset is below zero, or the offset+length offset is beyond the total length of the managed data.\n        if (offsetVal < 0 || offsetVal + length > this.length) {\n            throw new Error(utils_1.ERRORS.INVALID_READ_BEYOND_BOUNDS);\n        }\n    }\n    /**\n     * Ensures that the internal Buffer is large enough to insert data.\n     *\n     * @param dataLength { Number } The length of the data that needs to be written.\n     * @param offset { Number } The offset of the data to be written.\n     */\n    ensureInsertable(dataLength, offset) {\n        // Checks for valid numberic value;\n        utils_1.checkOffsetValue(offset);\n        // Ensure there is enough internal Buffer capacity.\n        this._ensureCapacity(this.length + dataLength);\n        // If an offset was provided and its not the very end of the buffer, copy data into appropriate location in regards to the offset.\n        if (offset < this.length) {\n            this._buff.copy(this._buff, offset + dataLength, offset, this._buff.length);\n        }\n        // Adjust tracked smart buffer length\n        if (offset + dataLength > this.length) {\n            this.length = offset + dataLength;\n        }\n        else {\n            this.length += dataLength;\n        }\n    }\n    /**\n     * Ensures that the internal Buffer is large enough to write data.\n     *\n     * @param dataLength { Number } The length of the data that needs to be written.\n     * @param offset { Number } The offset of the data to be written (defaults to writeOffset).\n     */\n    _ensureWriteable(dataLength, offset) {\n        const offsetVal = typeof offset === 'number' ? offset : this._writeOffset;\n        // Ensure enough capacity to write data.\n        this._ensureCapacity(offsetVal + dataLength);\n        // Adjust SmartBuffer length (if offset + length is larger than managed length, adjust length)\n        if (offsetVal + dataLength > this.length) {\n            this.length = offsetVal + dataLength;\n        }\n    }\n    /**\n     * Ensures that the internal Buffer is large enough to write at least the given amount of data.\n     *\n     * @param minLength { Number } The minimum length of the data needs to be written.\n     */\n    _ensureCapacity(minLength) {\n        const oldLength = this._buff.length;\n        if (minLength > oldLength) {\n            let data = this._buff;\n            let newLength = (oldLength * 3) / 2 + 1;\n            if (newLength < minLength) {\n                newLength = minLength;\n            }\n            this._buff = Buffer.allocUnsafe(newLength);\n            data.copy(this._buff, 0, 0, oldLength);\n        }\n    }\n    /**\n     * Reads a numeric number value using the provided function.\n     *\n     * @typeparam T { number | bigint } The type of the value to be read\n     *\n     * @param func { Function(offset: number) => number } The function to read data on the internal Buffer with.\n     * @param byteSize { Number } The number of bytes read.\n     * @param offset { Number } The offset to read from (optional). When this is not provided, the managed readOffset is used instead.\n     *\n     * @returns { T } the number value\n     */\n    _readNumberValue(func, byteSize, offset) {\n        this.ensureReadable(byteSize, offset);\n        // Call Buffer.readXXXX();\n        const value = func.call(this._buff, typeof offset === 'number' ? offset : this._readOffset);\n        // Adjust internal read offset if an optional read offset was not provided.\n        if (typeof offset === 'undefined') {\n            this._readOffset += byteSize;\n        }\n        return value;\n    }\n    /**\n     * Inserts a numeric number value based on the given offset and value.\n     *\n     * @typeparam T { number | bigint } The type of the value to be written\n     *\n     * @param func { Function(offset: T, offset?) => number} The function to write data on the internal Buffer with.\n     * @param byteSize { Number } The number of bytes written.\n     * @param value { T } The number value to write.\n     * @param offset { Number } the offset to write the number at (REQUIRED).\n     *\n     * @returns SmartBuffer this buffer\n     */\n    _insertNumberValue(func, byteSize, value, offset) {\n        // Check for invalid offset values.\n        utils_1.checkOffsetValue(offset);\n        // Ensure there is enough internal Buffer capacity. (raw offset is passed)\n        this.ensureInsertable(byteSize, offset);\n        // Call buffer.writeXXXX();\n        func.call(this._buff, value, offset);\n        // Adjusts internally managed write offset.\n        this._writeOffset += byteSize;\n        return this;\n    }\n    /**\n     * Writes a numeric number value based on the given offset and value.\n     *\n     * @typeparam T { number | bigint } The type of the value to be written\n     *\n     * @param func { Function(offset: T, offset?) => number} The function to write data on the internal Buffer with.\n     * @param byteSize { Number } The number of bytes written.\n     * @param value { T } The number value to write.\n     * @param offset { Number } the offset to write the number at (REQUIRED).\n     *\n     * @returns SmartBuffer this buffer\n     */\n    _writeNumberValue(func, byteSize, value, offset) {\n        // If an offset was provided, validate it.\n        if (typeof offset === 'number') {\n            // Check if we're writing beyond the bounds of the managed data.\n            if (offset < 0) {\n                throw new Error(utils_1.ERRORS.INVALID_WRITE_BEYOND_BOUNDS);\n            }\n            utils_1.checkOffsetValue(offset);\n        }\n        // Default to writeOffset if no offset value was given.\n        const offsetVal = typeof offset === 'number' ? offset : this._writeOffset;\n        // Ensure there is enough internal Buffer capacity. (raw offset is passed)\n        this._ensureWriteable(byteSize, offsetVal);\n        func.call(this._buff, value, offsetVal);\n        // If an offset was given, check to see if we wrote beyond the current writeOffset.\n        if (typeof offset === 'number') {\n            this._writeOffset = Math.max(this._writeOffset, offsetVal + byteSize);\n        }\n        else {\n            // If no numeric offset was given, we wrote to the end of the SmartBuffer so increment writeOffset.\n            this._writeOffset += byteSize;\n        }\n        return this;\n    }\n}\nexports.SmartBuffer = SmartBuffer;\n//# sourceMappingURL=smartbuffer.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ecdhUnsafe = exports.ecdh = exports.recover = exports.verify = exports.sign = exports.signatureImportLax = exports.signatureImport = exports.signatureExport = exports.signatureNormalize = exports.publicKeyCombine = exports.publicKeyTweakMul = exports.publicKeyTweakAdd = exports.publicKeyVerify = exports.publicKeyConvert = exports.publicKeyCreate = exports.privateKeyTweakMul = exports.privateKeyTweakAdd = exports.privateKeyModInverse = exports.privateKeyNegate = exports.privateKeyImport = exports.privateKeyExport = exports.privateKeyVerify = void 0;\nvar secp256k1 = require('ethereum-cryptography/secp256k1');\nvar secp256k1v3 = require('./secp256k1v3-lib/index');\nvar der = require('./secp256k1v3-lib/der');\n/**\n * Verify an ECDSA privateKey\n * @method privateKeyVerify\n * @param {Buffer} privateKey\n * @return {boolean}\n */\nexports.privateKeyVerify = function (privateKey) {\n    // secp256k1 v4 version throws when privateKey length is not 32\n    if (privateKey.length !== 32) {\n        return false;\n    }\n    return secp256k1.privateKeyVerify(Uint8Array.from(privateKey));\n};\n/**\n * Export a privateKey in DER format\n * @method privateKeyExport\n * @param {Buffer} privateKey\n * @param {boolean} compressed\n * @return {boolean}\n */\nexports.privateKeyExport = function (privateKey, compressed) {\n    // secp256k1 v4 version throws when privateKey length is not 32\n    if (privateKey.length !== 32) {\n        throw new RangeError('private key length is invalid');\n    }\n    var publicKey = secp256k1v3.privateKeyExport(privateKey, compressed);\n    return der.privateKeyExport(privateKey, publicKey, compressed);\n};\n/**\n * Import a privateKey in DER format\n * @method privateKeyImport\n * @param {Buffer} privateKey\n * @return {Buffer}\n */\nexports.privateKeyImport = function (privateKey) {\n    // privateKeyImport method is not part of secp256k1 v4 package\n    // this implementation is based on v3\n    privateKey = der.privateKeyImport(privateKey);\n    if (privateKey !== null && privateKey.length === 32 && exports.privateKeyVerify(privateKey)) {\n        return privateKey;\n    }\n    throw new Error(\"couldn't import from DER format\");\n};\n/**\n * Negate a privateKey by subtracting it from the order of the curve's base point\n * @method privateKeyNegate\n * @param {Buffer} privateKey\n * @return {Buffer}\n */\nexports.privateKeyNegate = function (privateKey) {\n    return Buffer.from(secp256k1.privateKeyNegate(Uint8Array.from(privateKey)));\n};\n/**\n * Compute the inverse of a privateKey (modulo the order of the curve's base point).\n * @method privateKeyModInverse\n * @param {Buffer} privateKey\n * @return {Buffer}\n */\nexports.privateKeyModInverse = function (privateKey) {\n    if (privateKey.length !== 32) {\n        throw new Error('private key length is invalid');\n    }\n    return Buffer.from(secp256k1v3.privateKeyModInverse(Uint8Array.from(privateKey)));\n};\n/**\n * Tweak a privateKey by adding tweak to it.\n * @method privateKeyTweakAdd\n * @param {Buffer} privateKey\n * @param {Buffer} tweak\n * @return {Buffer}\n */\nexports.privateKeyTweakAdd = function (privateKey, tweak) {\n    return Buffer.from(secp256k1.privateKeyTweakAdd(Uint8Array.from(privateKey), tweak));\n};\n/**\n * Tweak a privateKey by multiplying it by a tweak.\n * @method privateKeyTweakMul\n * @param {Buffer} privateKey\n * @param {Buffer} tweak\n * @return {Buffer}\n */\nexports.privateKeyTweakMul = function (privateKey, tweak) {\n    return Buffer.from(secp256k1.privateKeyTweakMul(Uint8Array.from(privateKey), Uint8Array.from(tweak)));\n};\n/**\n * Compute the public key for a privateKey.\n * @method publicKeyCreate\n * @param {Buffer} privateKey\n * @param {boolean} compressed\n * @return {Buffer}\n */\nexports.publicKeyCreate = function (privateKey, compressed) {\n    return Buffer.from(secp256k1.publicKeyCreate(Uint8Array.from(privateKey), compressed));\n};\n/**\n * Convert a publicKey to compressed or uncompressed form.\n * @method publicKeyConvert\n * @param {Buffer} publicKey\n * @param {boolean} compressed\n * @return {Buffer}\n */\nexports.publicKeyConvert = function (publicKey, compressed) {\n    return Buffer.from(secp256k1.publicKeyConvert(Uint8Array.from(publicKey), compressed));\n};\n/**\n * Verify an ECDSA publicKey.\n * @method publicKeyVerify\n * @param {Buffer} publicKey\n * @return {boolean}\n */\nexports.publicKeyVerify = function (publicKey) {\n    // secp256k1 v4 version throws when publicKey length is not 33 or 65\n    if (publicKey.length !== 33 && publicKey.length !== 65) {\n        return false;\n    }\n    return secp256k1.publicKeyVerify(Uint8Array.from(publicKey));\n};\n/**\n * Tweak a publicKey by adding tweak times the generator to it.\n * @method publicKeyTweakAdd\n * @param {Buffer} publicKey\n * @param {Buffer} tweak\n * @param {boolean} compressed\n * @return {Buffer}\n */\nexports.publicKeyTweakAdd = function (publicKey, tweak, compressed) {\n    return Buffer.from(secp256k1.publicKeyTweakAdd(Uint8Array.from(publicKey), Uint8Array.from(tweak), compressed));\n};\n/**\n * Tweak a publicKey by multiplying it by a tweak value\n * @method publicKeyTweakMul\n * @param {Buffer} publicKey\n * @param {Buffer} tweak\n * @param {boolean} compressed\n * @return {Buffer}\n */\nexports.publicKeyTweakMul = function (publicKey, tweak, compressed) {\n    return Buffer.from(secp256k1.publicKeyTweakMul(Uint8Array.from(publicKey), Uint8Array.from(tweak), compressed));\n};\n/**\n * Add a given publicKeys together.\n * @method publicKeyCombine\n * @param {Array<Buffer>} publicKeys\n * @param {boolean} compressed\n * @return {Buffer}\n */\nexports.publicKeyCombine = function (publicKeys, compressed) {\n    var keys = [];\n    publicKeys.forEach(function (publicKey) {\n        keys.push(Uint8Array.from(publicKey));\n    });\n    return Buffer.from(secp256k1.publicKeyCombine(keys, compressed));\n};\n/**\n * Convert a signature to a normalized lower-S form.\n * @method signatureNormalize\n * @param {Buffer} signature\n * @return {Buffer}\n */\nexports.signatureNormalize = function (signature) {\n    return Buffer.from(secp256k1.signatureNormalize(Uint8Array.from(signature)));\n};\n/**\n * Serialize an ECDSA signature in DER format.\n * @method signatureExport\n * @param {Buffer} signature\n * @return {Buffer}\n */\nexports.signatureExport = function (signature) {\n    return Buffer.from(secp256k1.signatureExport(Uint8Array.from(signature)));\n};\n/**\n * Parse a DER ECDSA signature (follow by [BIP66](https://github.com/bitcoin/bips/blob/master/bip-0066.mediawiki)).\n * @method signatureImport\n * @param {Buffer} signature\n * @return {Buffer}\n */\nexports.signatureImport = function (signature) {\n    return Buffer.from(secp256k1.signatureImport(Uint8Array.from(signature)));\n};\n/**\n * Parse a DER ECDSA signature (not follow by [BIP66](https://github.com/bitcoin/bips/blob/master/bip-0066.mediawiki)).\n * @method signatureImportLax\n * @param {Buffer} signature\n * @return {Buffer}\n */\nexports.signatureImportLax = function (signature) {\n    // signatureImportLax method is not part of secp256k1 v4 package\n    // this implementation is based on v3\n    // ensure that signature is greater than 0\n    if (signature.length === 0) {\n        throw new RangeError('signature length is invalid');\n    }\n    var sigObj = der.signatureImportLax(signature);\n    if (sigObj === null) {\n        throw new Error(\"couldn't parse DER signature\");\n    }\n    return secp256k1v3.signatureImport(sigObj);\n};\n/**\n * Create an ECDSA signature. Always return low-S signature.\n * @method sign\n * @param {Buffer} message\n * @param {Buffer} privateKey\n * @param {Object} options\n * @return {Buffer}\n */\nexports.sign = function (message, privateKey, options) {\n    if (options === null) {\n        throw new TypeError('options should be an Object');\n    }\n    var signOptions = undefined;\n    if (options) {\n        signOptions = {};\n        if (options.data === null) {\n            // validate option.data length\n            throw new TypeError('options.data should be a Buffer');\n        }\n        if (options.data) {\n            if (options.data.length != 32) {\n                throw new RangeError('options.data length is invalid');\n            }\n            signOptions.data = new Uint8Array(options.data);\n        }\n        if (options.noncefn === null) {\n            throw new TypeError('options.noncefn should be a Function');\n        }\n        if (options.noncefn) {\n            // convert option.noncefn function signature\n            signOptions.noncefn = function (message, privateKey, algo, data, attempt) {\n                var bufferAlgo = algo != null ? Buffer.from(algo) : null;\n                var bufferData = data != null ? Buffer.from(data) : null;\n                var buffer = Buffer.from('');\n                if (options.noncefn) {\n                    buffer = options.noncefn(Buffer.from(message), Buffer.from(privateKey), bufferAlgo, bufferData, attempt);\n                }\n                return new Uint8Array(buffer);\n            };\n        }\n    }\n    var sig = secp256k1.ecdsaSign(Uint8Array.from(message), Uint8Array.from(privateKey), signOptions);\n    return {\n        signature: Buffer.from(sig.signature),\n        recovery: sig.recid,\n    };\n};\n/**\n * Verify an ECDSA signature.\n * @method verify\n * @param {Buffer} message\n * @param {Buffer} signature\n * @param {Buffer} publicKey\n * @return {boolean}\n */\nexports.verify = function (message, signature, publicKey) {\n    return secp256k1.ecdsaVerify(Uint8Array.from(signature), Uint8Array.from(message), publicKey);\n};\n/**\n * Recover an ECDSA public key from a signature.\n * @method recover\n * @param {Buffer} message\n * @param {Buffer} signature\n * @param {Number} recid\n * @param {boolean} compressed\n * @return {Buffer}\n */\nexports.recover = function (message, signature, recid, compressed) {\n    return Buffer.from(secp256k1.ecdsaRecover(Uint8Array.from(signature), recid, Uint8Array.from(message), compressed));\n};\n/**\n * Compute an EC Diffie-Hellman secret and applied sha256 to compressed public key.\n * @method ecdh\n * @param {Buffer} publicKey\n * @param {Buffer} privateKey\n * @return {Buffer}\n */\nexports.ecdh = function (publicKey, privateKey) {\n    // note: secp256k1 v3 doesn't allow optional parameter\n    return Buffer.from(secp256k1.ecdh(Uint8Array.from(publicKey), Uint8Array.from(privateKey), {}));\n};\nexports.ecdhUnsafe = function (publicKey, privateKey, compressed) {\n    // ecdhUnsafe method is not part of secp256k1 v4 package\n    // this implementation is based on v3\n    // ensure valid publicKey length\n    if (publicKey.length !== 33 && publicKey.length !== 65) {\n        throw new RangeError('public key length is invalid');\n    }\n    // ensure valid privateKey length\n    if (privateKey.length !== 32) {\n        throw new RangeError('private key length is invalid');\n    }\n    return Buffer.from(secp256k1v3.ecdhUnsafe(Uint8Array.from(publicKey), Uint8Array.from(privateKey), compressed));\n};\n//# sourceMappingURL=secp256k1v3-adapter.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nfunction __export(m) {\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\n}\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar secp256k1_1 = require(\"secp256k1\");\nvar random_1 = require(\"./random\");\nvar SECP256K1_PRIVATE_KEY_SIZE = 32;\nfunction createPrivateKey() {\n    return __awaiter(this, void 0, void 0, function () {\n        var pk;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    if (!true) return [3 /*break*/, 2];\n                    return [4 /*yield*/, random_1.getRandomBytes(SECP256K1_PRIVATE_KEY_SIZE)];\n                case 1:\n                    pk = _a.sent();\n                    if (secp256k1_1.privateKeyVerify(pk)) {\n                        return [2 /*return*/, pk];\n                    }\n                    return [3 /*break*/, 0];\n                case 2: return [2 /*return*/];\n            }\n        });\n    });\n}\nexports.createPrivateKey = createPrivateKey;\nfunction createPrivateKeySync() {\n    while (true) {\n        var pk = random_1.getRandomBytesSync(SECP256K1_PRIVATE_KEY_SIZE);\n        if (secp256k1_1.privateKeyVerify(pk)) {\n            return pk;\n        }\n    }\n}\nexports.createPrivateKeySync = createPrivateKeySync;\n__export(require(\"secp256k1\"));\n//# sourceMappingURL=secp256k1.js.map","'use strict';\n\nvar curves = exports;\n\nvar hash = require('hash.js');\nvar curve = require('./curve');\nvar utils = require('./utils');\n\nvar assert = utils.assert;\n\nfunction PresetCurve(options) {\n  if (options.type === 'short')\n    this.curve = new curve.short(options);\n  else if (options.type === 'edwards')\n    this.curve = new curve.edwards(options);\n  else\n    this.curve = new curve.mont(options);\n  this.g = this.curve.g;\n  this.n = this.curve.n;\n  this.hash = options.hash;\n\n  assert(this.g.validate(), 'Invalid curve');\n  assert(this.g.mul(this.n).isInfinity(), 'Invalid curve, G*N != O');\n}\ncurves.PresetCurve = PresetCurve;\n\nfunction defineCurve(name, options) {\n  Object.defineProperty(curves, name, {\n    configurable: true,\n    enumerable: true,\n    get: function() {\n      var curve = new PresetCurve(options);\n      Object.defineProperty(curves, name, {\n        configurable: true,\n        enumerable: true,\n        value: curve,\n      });\n      return curve;\n    },\n  });\n}\n\ndefineCurve('p192', {\n  type: 'short',\n  prime: 'p192',\n  p: 'ffffffff ffffffff ffffffff fffffffe ffffffff ffffffff',\n  a: 'ffffffff ffffffff ffffffff fffffffe ffffffff fffffffc',\n  b: '64210519 e59c80e7 0fa7e9ab 72243049 feb8deec c146b9b1',\n  n: 'ffffffff ffffffff ffffffff 99def836 146bc9b1 b4d22831',\n  hash: hash.sha256,\n  gRed: false,\n  g: [\n    '188da80e b03090f6 7cbf20eb 43a18800 f4ff0afd 82ff1012',\n    '07192b95 ffc8da78 631011ed 6b24cdd5 73f977a1 1e794811',\n  ],\n});\n\ndefineCurve('p224', {\n  type: 'short',\n  prime: 'p224',\n  p: 'ffffffff ffffffff ffffffff ffffffff 00000000 00000000 00000001',\n  a: 'ffffffff ffffffff ffffffff fffffffe ffffffff ffffffff fffffffe',\n  b: 'b4050a85 0c04b3ab f5413256 5044b0b7 d7bfd8ba 270b3943 2355ffb4',\n  n: 'ffffffff ffffffff ffffffff ffff16a2 e0b8f03e 13dd2945 5c5c2a3d',\n  hash: hash.sha256,\n  gRed: false,\n  g: [\n    'b70e0cbd 6bb4bf7f 321390b9 4a03c1d3 56c21122 343280d6 115c1d21',\n    'bd376388 b5f723fb 4c22dfe6 cd4375a0 5a074764 44d58199 85007e34',\n  ],\n});\n\ndefineCurve('p256', {\n  type: 'short',\n  prime: null,\n  p: 'ffffffff 00000001 00000000 00000000 00000000 ffffffff ffffffff ffffffff',\n  a: 'ffffffff 00000001 00000000 00000000 00000000 ffffffff ffffffff fffffffc',\n  b: '5ac635d8 aa3a93e7 b3ebbd55 769886bc 651d06b0 cc53b0f6 3bce3c3e 27d2604b',\n  n: 'ffffffff 00000000 ffffffff ffffffff bce6faad a7179e84 f3b9cac2 fc632551',\n  hash: hash.sha256,\n  gRed: false,\n  g: [\n    '6b17d1f2 e12c4247 f8bce6e5 63a440f2 77037d81 2deb33a0 f4a13945 d898c296',\n    '4fe342e2 fe1a7f9b 8ee7eb4a 7c0f9e16 2bce3357 6b315ece cbb64068 37bf51f5',\n  ],\n});\n\ndefineCurve('p384', {\n  type: 'short',\n  prime: null,\n  p: 'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ' +\n     'fffffffe ffffffff 00000000 00000000 ffffffff',\n  a: 'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ' +\n     'fffffffe ffffffff 00000000 00000000 fffffffc',\n  b: 'b3312fa7 e23ee7e4 988e056b e3f82d19 181d9c6e fe814112 0314088f ' +\n     '5013875a c656398d 8a2ed19d 2a85c8ed d3ec2aef',\n  n: 'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff c7634d81 ' +\n     'f4372ddf 581a0db2 48b0a77a ecec196a ccc52973',\n  hash: hash.sha384,\n  gRed: false,\n  g: [\n    'aa87ca22 be8b0537 8eb1c71e f320ad74 6e1d3b62 8ba79b98 59f741e0 82542a38 ' +\n    '5502f25d bf55296c 3a545e38 72760ab7',\n    '3617de4a 96262c6f 5d9e98bf 9292dc29 f8f41dbd 289a147c e9da3113 b5f0b8c0 ' +\n    '0a60b1ce 1d7e819d 7a431d7c 90ea0e5f',\n  ],\n});\n\ndefineCurve('p521', {\n  type: 'short',\n  prime: null,\n  p: '000001ff ffffffff ffffffff ffffffff ffffffff ffffffff ' +\n     'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ' +\n     'ffffffff ffffffff ffffffff ffffffff ffffffff',\n  a: '000001ff ffffffff ffffffff ffffffff ffffffff ffffffff ' +\n     'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ' +\n     'ffffffff ffffffff ffffffff ffffffff fffffffc',\n  b: '00000051 953eb961 8e1c9a1f 929a21a0 b68540ee a2da725b ' +\n     '99b315f3 b8b48991 8ef109e1 56193951 ec7e937b 1652c0bd ' +\n     '3bb1bf07 3573df88 3d2c34f1 ef451fd4 6b503f00',\n  n: '000001ff ffffffff ffffffff ffffffff ffffffff ffffffff ' +\n     'ffffffff ffffffff fffffffa 51868783 bf2f966b 7fcc0148 ' +\n     'f709a5d0 3bb5c9b8 899c47ae bb6fb71e 91386409',\n  hash: hash.sha512,\n  gRed: false,\n  g: [\n    '000000c6 858e06b7 0404e9cd 9e3ecb66 2395b442 9c648139 ' +\n    '053fb521 f828af60 6b4d3dba a14b5e77 efe75928 fe1dc127 ' +\n    'a2ffa8de 3348b3c1 856a429b f97e7e31 c2e5bd66',\n    '00000118 39296a78 9a3bc004 5c8a5fb4 2c7d1bd9 98f54449 ' +\n    '579b4468 17afbd17 273e662c 97ee7299 5ef42640 c550b901 ' +\n    '3fad0761 353c7086 a272c240 88be9476 9fd16650',\n  ],\n});\n\ndefineCurve('curve25519', {\n  type: 'mont',\n  prime: 'p25519',\n  p: '7fffffffffffffff ffffffffffffffff ffffffffffffffff ffffffffffffffed',\n  a: '76d06',\n  b: '1',\n  n: '1000000000000000 0000000000000000 14def9dea2f79cd6 5812631a5cf5d3ed',\n  hash: hash.sha256,\n  gRed: false,\n  g: [\n    '9',\n  ],\n});\n\ndefineCurve('ed25519', {\n  type: 'edwards',\n  prime: 'p25519',\n  p: '7fffffffffffffff ffffffffffffffff ffffffffffffffff ffffffffffffffed',\n  a: '-1',\n  c: '1',\n  // -121665 * (121666^(-1)) (mod P)\n  d: '52036cee2b6ffe73 8cc740797779e898 00700a4d4141d8ab 75eb4dca135978a3',\n  n: '1000000000000000 0000000000000000 14def9dea2f79cd6 5812631a5cf5d3ed',\n  hash: hash.sha256,\n  gRed: false,\n  g: [\n    '216936d3cd6e53fec0a4e231fdd6dc5c692cc7609525a7b2c9562d608f25d51a',\n\n    // 4/5\n    '6666666666666666666666666666666666666666666666666666666666666658',\n  ],\n});\n\nvar pre;\ntry {\n  pre = require('./precomputed/secp256k1');\n} catch (e) {\n  pre = undefined;\n}\n\ndefineCurve('secp256k1', {\n  type: 'short',\n  prime: 'k256',\n  p: 'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff fffffffe fffffc2f',\n  a: '0',\n  b: '7',\n  n: 'ffffffff ffffffff ffffffff fffffffe baaedce6 af48a03b bfd25e8c d0364141',\n  h: '1',\n  hash: hash.sha256,\n\n  // Precomputed endomorphism\n  beta: '7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee',\n  lambda: '5363ad4cc05c30e0a5261c028812645a122e22ea20816678df02967c1b23bd72',\n  basis: [\n    {\n      a: '3086d221a7d46bcde86c90e49284eb15',\n      b: '-e4437ed6010e88286f547fa90abfe4c3',\n    },\n    {\n      a: '114ca50f7a8e2f3f657c1108d9d44cfd8',\n      b: '3086d221a7d46bcde86c90e49284eb15',\n    },\n  ],\n\n  gRed: false,\n  g: [\n    '79be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798',\n    '483ada7726a3c4655da4fbfc0e1108a8fd17b448a68554199c47d08ffb10d4b8',\n    pre,\n  ],\n});\n","var hash = exports;\n\nhash.utils = require('./hash/utils');\nhash.common = require('./hash/common');\nhash.sha = require('./hash/sha');\nhash.ripemd = require('./hash/ripemd');\nhash.hmac = require('./hash/hmac');\n\n// Proxy hash functions to the main object\nhash.sha1 = hash.sha.sha1;\nhash.sha256 = hash.sha.sha256;\nhash.sha224 = hash.sha.sha224;\nhash.sha384 = hash.sha.sha384;\nhash.sha512 = hash.sha.sha512;\nhash.ripemd160 = hash.ripemd.ripemd160;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.rlphash = exports.ripemd160 = exports.sha256 = exports.keccak256 = exports.keccak = void 0;\nvar _a = require('ethereum-cryptography/keccak'), keccak224 = _a.keccak224, keccak384 = _a.keccak384, k256 = _a.keccak256, keccak512 = _a.keccak512;\nvar createHash = require('create-hash');\nvar ethjsUtil = require('ethjs-util');\nvar rlp = require(\"rlp\");\nvar bytes_1 = require(\"./bytes\");\n/**\n * Creates Keccak hash of the input\n * @param a The input data (Buffer|Array|String|Number) If the string is a 0x-prefixed hex value\n * it's interpreted as hexadecimal, otherwise as utf8.\n * @param bits The Keccak width\n */\nexports.keccak = function (a, bits) {\n    if (bits === void 0) { bits = 256; }\n    if (typeof a === 'string' && !ethjsUtil.isHexString(a)) {\n        a = Buffer.from(a, 'utf8');\n    }\n    else {\n        a = bytes_1.toBuffer(a);\n    }\n    if (!bits)\n        bits = 256;\n    switch (bits) {\n        case 224: {\n            return keccak224(a);\n        }\n        case 256: {\n            return k256(a);\n        }\n        case 384: {\n            return keccak384(a);\n        }\n        case 512: {\n            return keccak512(a);\n        }\n        default: {\n            throw new Error(\"Invald algorithm: keccak\" + bits);\n        }\n    }\n};\n/**\n * Creates Keccak-256 hash of the input, alias for keccak(a, 256).\n * @param a The input data (Buffer|Array|String|Number)\n */\nexports.keccak256 = function (a) {\n    return exports.keccak(a);\n};\n/**\n * Creates SHA256 hash of the input.\n * @param a The input data (Buffer|Array|String|Number)\n */\nexports.sha256 = function (a) {\n    a = bytes_1.toBuffer(a);\n    return createHash('sha256')\n        .update(a)\n        .digest();\n};\n/**\n * Creates RIPEMD160 hash of the input.\n * @param a The input data (Buffer|Array|String|Number)\n * @param padded Whether it should be padded to 256 bits or not\n */\nexports.ripemd160 = function (a, padded) {\n    a = bytes_1.toBuffer(a);\n    var hash = createHash('rmd160')\n        .update(a)\n        .digest();\n    if (padded === true) {\n        return bytes_1.setLength(hash, 32);\n    }\n    else {\n        return hash;\n    }\n};\n/**\n * Creates SHA-3 hash of the RLP encoded version of the input.\n * @param a The input data\n */\nexports.rlphash = function (a) {\n    return exports.keccak(rlp.encode(a));\n};\n//# sourceMappingURL=hash.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar hash_utils_1 = require(\"./hash-utils\");\nvar createKeccakHash = require(\"keccak\");\nexports.keccak224 = hash_utils_1.createHashFunction(function () {\n    return createKeccakHash(\"keccak224\");\n});\nexports.keccak256 = hash_utils_1.createHashFunction(function () {\n    return createKeccakHash(\"keccak256\");\n});\nexports.keccak384 = hash_utils_1.createHashFunction(function () {\n    return createKeccakHash(\"keccak384\");\n});\nexports.keccak512 = hash_utils_1.createHashFunction(function () {\n    return createKeccakHash(\"keccak512\");\n});\n//# sourceMappingURL=keccak.js.map","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nmodule.exports = Stream;\n\nvar EE = require('events').EventEmitter;\nvar inherits = require('inherits');\n\ninherits(Stream, EE);\nStream.Readable = require('readable-stream/readable.js');\nStream.Writable = require('readable-stream/writable.js');\nStream.Duplex = require('readable-stream/duplex.js');\nStream.Transform = require('readable-stream/transform.js');\nStream.PassThrough = require('readable-stream/passthrough.js');\n\n// Backwards-compat with node 0.4.x\nStream.Stream = Stream;\n\n\n\n// old-style streams.  Note that the pipe method (the only relevant\n// part of this class) is overridden in the Readable class.\n\nfunction Stream() {\n  EE.call(this);\n}\n\nStream.prototype.pipe = function(dest, options) {\n  var source = this;\n\n  function ondata(chunk) {\n    if (dest.writable) {\n      if (false === dest.write(chunk) && source.pause) {\n        source.pause();\n      }\n    }\n  }\n\n  source.on('data', ondata);\n\n  function ondrain() {\n    if (source.readable && source.resume) {\n      source.resume();\n    }\n  }\n\n  dest.on('drain', ondrain);\n\n  // If the 'end' option is not supplied, dest.end() will be called when\n  // source gets the 'end' or 'close' events.  Only dest.end() once.\n  if (!dest._isStdio && (!options || options.end !== false)) {\n    source.on('end', onend);\n    source.on('close', onclose);\n  }\n\n  var didOnEnd = false;\n  function onend() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    dest.end();\n  }\n\n\n  function onclose() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    if (typeof dest.destroy === 'function') dest.destroy();\n  }\n\n  // don't leave dangling pipes when there are errors.\n  function onerror(er) {\n    cleanup();\n    if (EE.listenerCount(this, 'error') === 0) {\n      throw er; // Unhandled stream error in pipe.\n    }\n  }\n\n  source.on('error', onerror);\n  dest.on('error', onerror);\n\n  // remove all the event listeners that were added.\n  function cleanup() {\n    source.removeListener('data', ondata);\n    dest.removeListener('drain', ondrain);\n\n    source.removeListener('end', onend);\n    source.removeListener('close', onclose);\n\n    source.removeListener('error', onerror);\n    dest.removeListener('error', onerror);\n\n    source.removeListener('end', cleanup);\n    source.removeListener('close', cleanup);\n\n    dest.removeListener('close', cleanup);\n  }\n\n  source.on('end', cleanup);\n  source.on('close', cleanup);\n\n  dest.on('close', cleanup);\n\n  dest.emit('pipe', source);\n\n  // Allow for unix-like usage: A.pipe(B).pipe(C)\n  return dest;\n};\n","exports = module.exports = require('./lib/_stream_readable.js');\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = require('./lib/_stream_writable.js');\nexports.Duplex = require('./lib/_stream_duplex.js');\nexports.Transform = require('./lib/_stream_transform.js');\nexports.PassThrough = require('./lib/_stream_passthrough.js');\n","/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};","'use strict'\nvar inherits = require('inherits')\nvar MD5 = require('md5.js')\nvar RIPEMD160 = require('ripemd160')\nvar sha = require('sha.js')\nvar Base = require('cipher-base')\n\nfunction Hash (hash) {\n  Base.call(this, 'digest')\n\n  this._hash = hash\n}\n\ninherits(Hash, Base)\n\nHash.prototype._update = function (data) {\n  this._hash.update(data)\n}\n\nHash.prototype._final = function () {\n  return this._hash.digest()\n}\n\nmodule.exports = function createHash (alg) {\n  alg = alg.toLowerCase()\n  if (alg === 'md5') return new MD5()\n  if (alg === 'rmd160' || alg === 'ripemd160') return new RIPEMD160()\n\n  return new Hash(sha(alg))\n}\n","// Ported from https://github.com/mafintosh/end-of-stream with\n// permission from the author, Mathias Buus (@mafintosh).\n'use strict';\n\nvar ERR_STREAM_PREMATURE_CLOSE = require('../../../errors').codes.ERR_STREAM_PREMATURE_CLOSE;\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    callback.apply(this, args);\n  };\n}\n\nfunction noop() {}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction eos(stream, opts, callback) {\n  if (typeof opts === 'function') return eos(stream, null, opts);\n  if (!opts) opts = {};\n  callback = once(callback || noop);\n  var readable = opts.readable || opts.readable !== false && stream.readable;\n  var writable = opts.writable || opts.writable !== false && stream.writable;\n\n  var onlegacyfinish = function onlegacyfinish() {\n    if (!stream.writable) onfinish();\n  };\n\n  var writableEnded = stream._writableState && stream._writableState.finished;\n\n  var onfinish = function onfinish() {\n    writable = false;\n    writableEnded = true;\n    if (!readable) callback.call(stream);\n  };\n\n  var readableEnded = stream._readableState && stream._readableState.endEmitted;\n\n  var onend = function onend() {\n    readable = false;\n    readableEnded = true;\n    if (!writable) callback.call(stream);\n  };\n\n  var onerror = function onerror(err) {\n    callback.call(stream, err);\n  };\n\n  var onclose = function onclose() {\n    var err;\n\n    if (readable && !readableEnded) {\n      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n\n    if (writable && !writableEnded) {\n      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n  };\n\n  var onrequest = function onrequest() {\n    stream.req.on('finish', onfinish);\n  };\n\n  if (isRequest(stream)) {\n    stream.on('complete', onfinish);\n    stream.on('abort', onclose);\n    if (stream.req) onrequest();else stream.on('request', onrequest);\n  } else if (writable && !stream._writableState) {\n    // legacy streams\n    stream.on('end', onlegacyfinish);\n    stream.on('close', onlegacyfinish);\n  }\n\n  stream.on('end', onend);\n  stream.on('finish', onfinish);\n  if (opts.error !== false) stream.on('error', onerror);\n  stream.on('close', onclose);\n  return function () {\n    stream.removeListener('complete', onfinish);\n    stream.removeListener('abort', onclose);\n    stream.removeListener('request', onrequest);\n    if (stream.req) stream.req.removeListener('finish', onfinish);\n    stream.removeListener('end', onlegacyfinish);\n    stream.removeListener('close', onlegacyfinish);\n    stream.removeListener('finish', onfinish);\n    stream.removeListener('end', onend);\n    stream.removeListener('error', onerror);\n    stream.removeListener('close', onclose);\n  };\n}\n\nmodule.exports = eos;","'use strict'\n\nconst CID = require('cids')\nconst multihashes = require('multihashes')\nconst multicodec = require('multicodec')\n\nmodule.exports = cidFromHash\n\nfunction cidFromHash (codec, rawhash, options) {\n  // `CID` expects a string for the multicodec\n  const codecName = multicodec.getNameFromCode(codec)\n  options = options || {}\n  const hashAlg = options.hashAlg || 'keccak-256'\n  const version = typeof options.version === 'undefined' ? 1 : options.version\n  const multihash = multihashes.encode(rawhash, hashAlg)\n  return new CID(version, codecName, multihash)\n}\n","'use strict'\nconst rlp = require('rlp')\nconst EthTrieNode = require('merkle-patricia-tree/trieNode')\nconst cidFromHash = require('./cidFromHash')\nconst createResolver = require('./createResolver')\n\n// A `nibble` is an array of nested keys. So for example `[2, 1, 3]` would\n// mean an item with value `\"foo\"` would be in an object like this:\n// {\n//   \"2\": {\n//     \"1\": {\n//       \"3\": \"foo\"\n//     }\n//   }\n// }\n// This function converts such a nibble together with a `value` into such an\n// object. As we want to combine multiple nibbles into a single object, we\n// also pass in a `target` object where the value should be stored in.\nconst addNibbleToObject = (target, nibble, value) => {\n  // Make a reference to the target object that can be changed in the course\n  // of the algorithm\n  let current = target\n  for (const [ii, entry] of nibble.entries()) {\n    // Get the key the value should be stored in\n    const key = entry.toString(16)\n\n    if (ii + 1 < nibble.length) {\n    // We haven't reached the last item yet\n      // There is no item with that key yet\n      if (!(key in current)) {\n        current[key] = {}\n      }\n      // Keep traversing deeper\n      current = current[key]\n    } else {\n    // Else we've reached the last item, hence adding the actual value\n      current[key] = value\n      return\n    }\n  }\n}\n\nconst getLeafValue = (trieNode, leafResolver) => {\n  let value = trieNode.getValue()\n\n  if (leafResolver !== undefined) {\n    value = leafResolver.util.deserialize(value)\n  }\n\n  return value\n}\n\n// create map from merkle-patricia-tree nodes\nconst mapFromBaseTrie = (codec, finalNode, trieNode, leafResolver) => {\n  if (trieNode.type === 'leaf') {\n    const value = getLeafValue(trieNode, leafResolver)\n    addNibbleToObject(finalNode, trieNode.getKey(), value)\n    return\n  }\n\n  trieNode.getChildren().forEach(([nibble, value]) => {\n    let valueToAdd\n    if (EthTrieNode.isRawNode(value)) {\n    // inline child root\n      const childNode = new EthTrieNode(value)\n\n      if (childNode.type === 'leaf') {\n        // Make sure the object is nested correctly\n        nibble.push(...childNode.getKey())\n        valueToAdd = getLeafValue(childNode, leafResolver)\n      } else {\n        valueToAdd = childNode\n      }\n    } else {\n    // other nodes link by hash\n      valueToAdd = cidFromHash(codec, value)\n    }\n    addNibbleToObject(finalNode, nibble, valueToAdd)\n  })\n}\n\n// The `createUtilResolver` expects a constructor with a single parameter,\n// hence wrap it in a creator function so that we can pass in the needed\n// context\nconst createCustomEthTrieNode = function (codec, leafResolver) {\n  return function (serialized) {\n    const rawNode = rlp.decode(serialized)\n    const trieNode = new EthTrieNode(rawNode)\n\n    const finalNode = {}\n    mapFromBaseTrie(codec, finalNode, trieNode, leafResolver)\n    return finalNode\n  }\n}\n\nconst createTrieResolver = (codec, leafResolver) => {\n  const customEthTrieNode = createCustomEthTrieNode(codec, leafResolver)\n  const baseTrie = createResolver(codec, customEthTrieNode)\n  return baseTrie\n}\n\nmodule.exports = createTrieResolver\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar token = require('./token.js');\nvar common = require('./common.js');\nvar _0uint = require('./0uint.js');\nvar byteUtils = require('./byte-utils.js');\n\nfunction toToken(data, pos, prefix, length) {\n  common.assertEnoughData(data, pos, prefix + length);\n  const buf = byteUtils.slice(data, pos + prefix, pos + prefix + length);\n  return new token.Token(token.Type.bytes, buf, prefix + length);\n}\nfunction decodeBytesCompact(data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor);\n}\nfunction decodeBytes8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, _0uint.readUint8(data, pos + 1, options));\n}\nfunction decodeBytes16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, _0uint.readUint16(data, pos + 1, options));\n}\nfunction decodeBytes32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, _0uint.readUint32(data, pos + 1, options));\n}\nfunction decodeBytes64(data, pos, _minor, options) {\n  const l = _0uint.readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${ common.decodeErrPrefix } 64-bit integer bytes lengths not supported`);\n  }\n  return toToken(data, pos, 9, l);\n}\nfunction tokenBytes(token$1) {\n  if (token$1.encodedBytes === undefined) {\n    token$1.encodedBytes = token$1.type === token.Type.string ? byteUtils.fromString(token$1.value) : token$1.value;\n  }\n  return token$1.encodedBytes;\n}\nfunction encodeBytes(buf, token) {\n  const bytes = tokenBytes(token);\n  _0uint.encodeUintValue(buf, token.type.majorEncoded, bytes.length);\n  buf.push(bytes);\n}\nencodeBytes.encodedSize = function encodedSize(token) {\n  const bytes = tokenBytes(token);\n  return _0uint.encodeUintValue.encodedSize(bytes.length) + bytes.length;\n};\nencodeBytes.compareTokens = function compareTokens(tok1, tok2) {\n  return compareBytes(tokenBytes(tok1), tokenBytes(tok2));\n};\nfunction compareBytes(b1, b2) {\n  return b1.length < b2.length ? -1 : b1.length > b2.length ? 1 : byteUtils.compare(b1, b2);\n}\n\nexports.compareBytes = compareBytes;\nexports.decodeBytes16 = decodeBytes16;\nexports.decodeBytes32 = decodeBytes32;\nexports.decodeBytes64 = decodeBytes64;\nexports.decodeBytes8 = decodeBytes8;\nexports.decodeBytesCompact = decodeBytesCompact;\nexports.encodeBytes = encodeBytes;\n","'use strict'\n\n// @ts-ignore TODO: switch to cborg\nconst cbor = require('borc')\nconst multicodec = require('multicodec')\nconst multihashing = require('multihashing-async')\nconst { multihash } = multihashing\nconst CID = require('cids')\n// @ts-ignore\nconst isCircular = require('is-circular')\nconst uint8ArrayConcat = require('uint8arrays/concat')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\n/**\n * @typedef {import('cids').CIDVersion} CIDVersion\n * @typedef {import('multihashing-async').multihash.HashCode} HashCode\n */\n\n// https://github.com/ipfs/go-ipfs/issues/3570#issuecomment-273931692\nconst CID_CBOR_TAG = 42\n\n/**\n * @param {CID | string} cid\n */\nfunction tagCID (cid) {\n  let buf\n\n  if (typeof cid === 'string') {\n    buf = new CID(cid).bytes\n  } else if (CID.isCID(cid)) {\n    buf = cid.bytes\n  } else {\n    throw new Error('Could not tag CID - was not string or CID')\n  }\n\n  return new cbor.Tagged(CID_CBOR_TAG, uint8ArrayConcat([\n    uint8ArrayFromString('00', 'base16'), // thanks jdag\n    buf\n  ], 1 + buf.length))\n}\n\n/**\n * @param {any} dagNode\n */\nfunction replaceCIDbyTAG (dagNode) {\n  let circular\n  try {\n    circular = isCircular(dagNode)\n  } catch (e) {\n    circular = false\n  }\n  if (circular) {\n    throw new Error('The object passed has circular references')\n  }\n\n  /**\n   * @param {any} obj\n   * @returns {any}\n   */\n  function transform (obj) {\n    if (!obj || obj instanceof Uint8Array || typeof obj === 'string') {\n      return obj\n    }\n\n    if (Array.isArray(obj)) {\n      return obj.map(transform)\n    }\n\n    if (CID.isCID(obj)) {\n      return tagCID(obj)\n    }\n\n    const keys = Object.keys(obj)\n\n    if (keys.length > 0) {\n      // Recursive transform\n      /** @type {Record<string, any>} */\n      const out = {}\n      keys.forEach((key) => {\n        if (typeof obj[key] === 'object') {\n          out[key] = transform(obj[key])\n        } else {\n          out[key] = obj[key]\n        }\n      })\n      return out\n    } else {\n      return obj\n    }\n  }\n\n  return transform(dagNode)\n}\n\nconst codec = multicodec.DAG_CBOR\nconst defaultHashAlg = multihash.names['sha2-256']\n\nconst defaultTags = {\n  /**\n   * @param {Uint8Array} val\n   */\n  [CID_CBOR_TAG]: (val) => {\n    // remove that 0\n    val = val.slice(1)\n    return new CID(val)\n  }\n}\nconst defaultSize = 64 * 1024 // current decoder heap size, 64 Kb\nlet currentSize = defaultSize\nconst defaultMaxSize = 64 * 1024 * 1024 // max heap size when auto-growing, 64 Mb\nlet maxSize = defaultMaxSize\n/** @type {cbor.Decoder} */\nlet decoder\n\n/**\n * Configure the underlying CBOR decoder.\n *\n * @param {Object} [options] - The options the decoder takes. The decoder will reset to the defaul values if no options are given.\n * @param {number} [options.size=65536] - The current heap size used in CBOR parsing, this may grow automatically as larger blocks are encountered up to `maxSize`\n * @param {number} [options.maxSize=67108864] - The maximum size the CBOR parsing heap is allowed to grow to before `dagCBOR.util.deserialize()` returns an error\n * @param {Object} [options.tags] - An object whose keys are CBOR tag numbers and values are transform functions that accept a `value` and return a decoded representation of that `value`\n */\nfunction configureDecoder (options) {\n  let tags = defaultTags\n\n  if (options) {\n    if (typeof options.size === 'number') {\n      currentSize = options.size\n    }\n    if (typeof options.maxSize === 'number') {\n      maxSize = options.maxSize\n    }\n    if (options.tags) {\n      tags = Object.assign({}, defaultTags, options && options.tags)\n    }\n  } else {\n    // no options, reset to defaults\n    currentSize = defaultSize\n    maxSize = defaultMaxSize\n  }\n\n  const decoderOptions = {\n    tags,\n    size: currentSize\n  }\n\n  decoder = new cbor.Decoder(decoderOptions)\n  // borc edits opts.size in-place so we can capture _actual_ size\n  currentSize = decoderOptions.size\n}\n\nconfigureDecoder() // Setup default cbor.Decoder\n\n/**\n * Serialize internal representation into a binary CBOR block.\n *\n * @param {Object} node - Internal representation of a CBOR block\n * @returns {Uint8Array} - The encoded binary representation\n */\nfunction serialize (node) {\n  const nodeTagged = replaceCIDbyTAG(node)\n  const serialized = cbor.encode(nodeTagged)\n\n  return serialized\n}\n\n/**\n * Deserialize CBOR block into the internal representation.\n *\n * @param {Uint8Array} data - Binary representation of a CBOR block\n * @returns {any} - An object that conforms to the IPLD Data Model\n */\nfunction deserialize (data) {\n  if (data.length > currentSize && data.length <= maxSize) {\n    configureDecoder({ size: data.length })\n  }\n\n  if (data.length > currentSize) {\n    throw new Error('Data is too large to deserialize with current decoder')\n  }\n\n  // borc will decode back-to-back objects into an implicit top-level array, we\n  // strictly want to only see a single explicit top-level object\n  const all = decoder.decodeAll(data)\n  if (all.length !== 1) {\n    throw new Error('Extraneous CBOR data found beyond initial top-level object')\n  }\n\n  return all[0]\n}\n\n/**\n * Calculate the CID of the binary blob.\n *\n * @param {Uint8Array} binaryBlob - Encoded IPLD Node\n * @param {Object} [userOptions] - Options to create the CID\n * @param {CIDVersion} [userOptions.cidVersion=1] - CID version number\n * @param {HashCode} [userOptions.hashAlg=multihash.names['sha2-256']] - Defaults to the defaultHashAlg of the format\n */\nasync function cid (binaryBlob, userOptions = {}) {\n  const options = {\n    cidVersion: userOptions.cidVersion == null ? 1 : userOptions.cidVersion,\n    hashAlg: userOptions.hashAlg == null ? module.exports.defaultHashAlg : userOptions.hashAlg\n  }\n\n  const hashName = multihash.codes[options.hashAlg]\n  const hash = await multihashing(binaryBlob, hashName)\n  const codecName = multicodec.getNameFromCode(module.exports.codec)\n  const cid = new CID(options.cidVersion, codecName, hash)\n\n  return cid\n}\n\nmodule.exports = {\n  codec,\n  defaultHashAlg,\n  configureDecoder,\n  serialize,\n  deserialize,\n  cid\n}\n","'use strict'\n\nconst varint = require('varint')\nconst uint8ArrayToString = require('uint8arrays/to-string')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\nmodule.exports = {\n  numberToUint8Array,\n  uint8ArrayToNumber,\n  varintUint8ArrayEncode,\n  varintEncode\n}\n\n/**\n * @param {Uint8Array} buf\n */\nfunction uint8ArrayToNumber (buf) {\n  return parseInt(uint8ArrayToString(buf, 'base16'), 16)\n}\n\n/**\n * @param {number} num\n */\nfunction numberToUint8Array (num) {\n  let hexString = num.toString(16)\n  if (hexString.length % 2 === 1) {\n    hexString = '0' + hexString\n  }\n  return uint8ArrayFromString(hexString, 'base16')\n}\n\n/**\n * @param {Uint8Array} input\n */\nfunction varintUint8ArrayEncode (input) {\n  return Uint8Array.from(varint.encode(uint8ArrayToNumber(input)))\n}\n\n/**\n * @param {number} num\n */\nfunction varintEncode (num) {\n  return Uint8Array.from(varint.encode(num))\n}\n","'use strict'\n\nconst errcode = require('err-code')\nconst multihash = require('multihashes')\nconst crypto = require('./crypto')\nconst equals = require('uint8arrays/equals')\n\n/**\n * @typedef {import(\"./types\").Digest} Digest\n * @typedef {import(\"multihashes\").HashName} HashName\n */\n\n/**\n * Hash the given `bytes` using the algorithm specified by `alg`.\n *\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nasync function Multihashing (bytes, alg, length) {\n  const digest = await Multihashing.digest(bytes, alg, length)\n  return multihash.encode(digest, alg, length)\n}\n\n/**\n * Expose multihash itself, to avoid silly double requires.\n */\nMultihashing.multihash = multihash\n\n/**\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nMultihashing.digest = async (bytes, alg, length) => {\n  const hash = Multihashing.createHash(alg)\n  const digest = await hash(bytes)\n  return length ? digest.slice(0, length) : digest\n}\n\n/**\n * Creates a function that hashes with the given algorithm\n *\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @returns {Digest} - The hash function corresponding to `alg`\n */\nMultihashing.createHash = function (alg) {\n  if (!alg) {\n    const e = errcode(new Error('hash algorithm must be specified'), 'ERR_HASH_ALGORITHM_NOT_SPECIFIED')\n    throw e\n  }\n\n  const code = multihash.coerceCode(alg)\n  if (!Multihashing.functions[code]) {\n    throw errcode(new Error(`multihash function '${alg}' not yet supported`), 'ERR_HASH_ALGORITHM_NOT_SUPPORTED')\n  }\n\n  return Multihashing.functions[code]\n}\n\n/**\n * Mapping of multihash codes to their hashing functions.\n *\n * @type {Record<number, Digest>}\n */\n// @ts-ignore - most of those functions aren't typed\nMultihashing.functions = {\n  // identity\n  0x00: crypto.identity,\n  // sha1\n  0x11: crypto.sha1,\n  // sha2-256\n  0x12: crypto.sha2256,\n  // sha2-512\n  0x13: crypto.sha2512,\n  // sha3-512\n  0x14: crypto.sha3512,\n  // sha3-384\n  0x15: crypto.sha3384,\n  // sha3-256\n  0x16: crypto.sha3256,\n  // sha3-224\n  0x17: crypto.sha3224,\n  // shake-128\n  0x18: crypto.shake128,\n  // shake-256\n  0x19: crypto.shake256,\n  // keccak-224\n  0x1A: crypto.keccak224,\n  // keccak-256\n  0x1B: crypto.keccak256,\n  // keccak-384\n  0x1C: crypto.keccak384,\n  // keccak-512\n  0x1D: crypto.keccak512,\n  // murmur3-128\n  0x22: crypto.murmur3128,\n  // murmur3-32\n  0x23: crypto.murmur332,\n  // dbl-sha2-256\n  0x56: crypto.dblSha2256\n}\n\n// add blake functions\ncrypto.addBlake(Multihashing.functions)\n\n/**\n * @param {Uint8Array} bytes\n * @param {Uint8Array} hash\n * @returns {Promise<boolean>}\n */\nMultihashing.validate = async (bytes, hash) => {\n  const newHash = await Multihashing(bytes, multihash.decode(hash).name)\n\n  return equals(hash, newHash)\n}\n\nmodule.exports = Multihashing\n","/**\n * Multihash implementation in JavaScript.\n */\n'use strict'\n\nconst multibase = require('multibase')\nconst varint = require('varint')\nconst { names } = require('./constants')\nconst uint8ArrayToString = require('uint8arrays/to-string')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\nconst uint8ArrayConcat = require('uint8arrays/concat')\n\nconst codes = /** @type {import('./types').CodeNameMap} */({})\n\n// eslint-disable-next-line guard-for-in\nfor (const key in names) {\n  const name = /** @type {HashName} */(key)\n  codes[names[name]] = name\n}\nObject.freeze(codes)\n\n/**\n * Convert the given multihash to a hex encoded string.\n *\n * @param {Uint8Array} hash\n * @returns {string}\n */\nfunction toHexString (hash) {\n  if (!(hash instanceof Uint8Array)) {\n    throw new Error('must be passed a Uint8Array')\n  }\n\n  return uint8ArrayToString(hash, 'base16')\n}\n\n/**\n * Convert the given hex encoded string to a multihash.\n *\n * @param {string} hash\n * @returns {Uint8Array}\n */\nfunction fromHexString (hash) {\n  return uint8ArrayFromString(hash, 'base16')\n}\n\n/**\n * Convert the given multihash to a base58 encoded string.\n *\n * @param {Uint8Array} hash\n * @returns {string}\n */\nfunction toB58String (hash) {\n  if (!(hash instanceof Uint8Array)) {\n    throw new Error('must be passed a Uint8Array')\n  }\n\n  return uint8ArrayToString(multibase.encode('base58btc', hash)).slice(1)\n}\n\n/**\n * Convert the given base58 encoded string to a multihash.\n *\n * @param {string|Uint8Array} hash\n * @returns {Uint8Array}\n */\nfunction fromB58String (hash) {\n  const encoded = hash instanceof Uint8Array\n    ? uint8ArrayToString(hash)\n    : hash\n\n  return multibase.decode('z' + encoded)\n}\n\n/**\n * Decode a hash from the given multihash.\n *\n * @param {Uint8Array} bytes\n * @returns {{code: HashCode, name: HashName, length: number, digest: Uint8Array}} result\n */\nfunction decode (bytes) {\n  if (!(bytes instanceof Uint8Array)) {\n    throw new Error('multihash must be a Uint8Array')\n  }\n\n  if (bytes.length < 2) {\n    throw new Error('multihash too short. must be > 2 bytes.')\n  }\n\n  const code = /** @type {HashCode} */(varint.decode(bytes))\n  if (!isValidCode(code)) {\n    throw new Error(`multihash unknown function code: 0x${code.toString(16)}`)\n  }\n  bytes = bytes.slice(varint.decode.bytes)\n\n  const len = varint.decode(bytes)\n  if (len < 0) {\n    throw new Error(`multihash invalid length: ${len}`)\n  }\n  bytes = bytes.slice(varint.decode.bytes)\n\n  if (bytes.length !== len) {\n    throw new Error(`multihash length inconsistent: 0x${uint8ArrayToString(bytes, 'base16')}`)\n  }\n\n  return {\n    code,\n    name: codes[code],\n    length: len,\n    digest: bytes\n  }\n}\n\n/**\n * Encode a hash digest along with the specified function code.\n *\n * > **Note:** the length is derived from the length of the digest itself.\n *\n * @param {Uint8Array} digest\n * @param {HashName | HashCode} code\n * @param {number} [length]\n * @returns {Uint8Array}\n */\nfunction encode (digest, code, length) {\n  if (!digest || code === undefined) {\n    throw new Error('multihash encode requires at least two args: digest, code')\n  }\n\n  // ensure it's a hashfunction code.\n  const hashfn = coerceCode(code)\n\n  if (!(digest instanceof Uint8Array)) {\n    throw new Error('digest should be a Uint8Array')\n  }\n\n  if (length == null) {\n    length = digest.length\n  }\n\n  if (length && digest.length !== length) {\n    throw new Error('digest length should be equal to specified length.')\n  }\n\n  const hash = varint.encode(hashfn)\n  const len = varint.encode(length)\n  return uint8ArrayConcat([hash, len, digest], hash.length + len.length + digest.length)\n}\n\n/**\n * Converts a hash function name into the matching code.\n * If passed a number it will return the number if it's a valid code.\n *\n * @param {HashName | number} name\n * @returns {number}\n */\nfunction coerceCode (name) {\n  let code = name\n\n  if (typeof name === 'string') {\n    if (names[name] === undefined) {\n      throw new Error(`Unrecognized hash function named: ${name}`)\n    }\n    code = names[name]\n  }\n\n  if (typeof code !== 'number') {\n    throw new Error(`Hash function code should be a number. Got: ${code}`)\n  }\n\n  // @ts-ignore\n  if (codes[code] === undefined && !isAppCode(code)) {\n    throw new Error(`Unrecognized function code: ${code}`)\n  }\n\n  return code\n}\n\n/**\n * Checks if a code is part of the app range\n *\n * @param {number} code\n * @returns {boolean}\n */\nfunction isAppCode (code) {\n  return code > 0 && code < 0x10\n}\n\n/**\n * Checks whether a multihash code is valid.\n *\n * @param {HashCode} code\n * @returns {boolean}\n */\nfunction isValidCode (code) {\n  if (isAppCode(code)) {\n    return true\n  }\n\n  if (codes[code]) {\n    return true\n  }\n\n  return false\n}\n\n/**\n * Check if the given buffer is a valid multihash. Throws an error if it is not valid.\n *\n * @param {Uint8Array} multihash\n * @returns {void}\n * @throws {Error}\n */\nfunction validate (multihash) {\n  decode(multihash) // throws if bad.\n}\n\n/**\n * Returns a prefix from a valid multihash. Throws an error if it is not valid.\n *\n * @param {Uint8Array} multihash\n * @returns {Uint8Array}\n * @throws {Error}\n */\nfunction prefix (multihash) {\n  validate(multihash)\n\n  return multihash.subarray(0, 2)\n}\n\nmodule.exports = {\n  names,\n  codes,\n  toHexString,\n  fromHexString,\n  toB58String,\n  fromB58String,\n  decode,\n  encode,\n  coerceCode,\n  isAppCode,\n  validate,\n  prefix,\n  isValidCode\n}\n\n/**\n * @typedef { import(\"./constants\").HashCode } HashCode\n * @typedef { import(\"./constants\").HashName } HashName\n */\n","'use strict'\n\n/**\n * Returns true if the two passed Uint8Arrays have the same content\n *\n * @param {Uint8Array} a\n * @param {Uint8Array} b\n */\nfunction equals (a, b) {\n  if (a === b) {\n    return true\n  }\n\n  if (a.byteLength !== b.byteLength) {\n    return false\n  }\n\n  for (let i = 0; i < a.byteLength; i++) {\n    if (a[i] !== b[i]) {\n      return false\n    }\n  }\n\n  return true\n}\n\nmodule.exports = equals\n","'use strict'\n\nconst {\n  PBNode\n} = require('./dag')\nconst DAGLink = require('./dag-link/dagLink')\nconst DAGNode = require('./dag-node/dagNode')\nconst { serializeDAGNode, serializeDAGNodeLike } = require('./serialize')\nconst genCid = require('./genCid')\n\n/**\n * @typedef {import('./types').DAGLinkLike} DAGLinkLike\n */\n\n/**\n * Calculate the CID of the binary blob\n *\n * @param {Uint8Array} binaryBlob - Encoded IPLD Node\n * @param {import('./genCid').GenCIDOptions} [userOptions] - Options to create the CID\n */\nconst cid = (binaryBlob, userOptions) => {\n  return genCid.cid(binaryBlob, userOptions)\n}\n\n/**\n * Serialize internal representation into a binary PB block\n *\n * @param {DAGNode | { Data?: Uint8Array, Links?: (DAGLink | DAGLinkLike)[]}} node\n */\nconst serialize = (node) => {\n  if (node instanceof DAGNode) {\n    return serializeDAGNode(node)\n  } else {\n    return serializeDAGNodeLike(node.Data, node.Links)\n  }\n}\n\n/**\n * Deserialize PB block into the internal representation.\n *\n * @param {Uint8Array} buffer - Binary representation of a PB block\n */\nconst deserialize = (buffer) => {\n  const message = PBNode.decode(buffer)\n  const pbn = PBNode.toObject(message, {\n    defaults: false,\n    arrays: true,\n    longs: Number,\n    objects: false\n  })\n\n  /** @type {DAGLink[]} */\n  const links = pbn.Links.map((/** @type {DAGLinkLike} */ link) => {\n    // @ts-ignore\n    return new DAGLink(link.Name, link.Tsize, link.Hash)\n  })\n\n  const data = pbn.Data == null ? new Uint8Array(0) : pbn.Data\n\n  return new DAGNode(data, links, buffer.byteLength)\n}\n\nmodule.exports = {\n  codec: genCid.codec,\n  defaultHashAlg: genCid.defaultHashAlg,\n  serialize,\n  deserialize,\n  cid\n}\n","/*eslint-disable*/\n\"use strict\";\n\nvar $protobuf = require(\"protobufjs/minimal\");\n\n// Common aliases\nvar $Reader = $protobuf.Reader, $Writer = $protobuf.Writer, $util = $protobuf.util;\n\n// Exported root namespace\nvar $root = $protobuf.roots[\"default\"] || ($protobuf.roots[\"default\"] = {});\n\n$root.PBLink = (function() {\n\n    /**\n     * Properties of a PBLink.\n     * @exports IPBLink\n     * @interface IPBLink\n     * @property {Uint8Array|null} [Hash] PBLink Hash\n     * @property {string|null} [Name] PBLink Name\n     * @property {number|null} [Tsize] PBLink Tsize\n     */\n\n    /**\n     * Constructs a new PBLink.\n     * @exports PBLink\n     * @classdesc Represents a PBLink.\n     * @implements IPBLink\n     * @constructor\n     * @param {IPBLink=} [p] Properties to set\n     */\n    function PBLink(p) {\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * PBLink Hash.\n     * @member {Uint8Array} Hash\n     * @memberof PBLink\n     * @instance\n     */\n    PBLink.prototype.Hash = $util.newBuffer([]);\n\n    /**\n     * PBLink Name.\n     * @member {string} Name\n     * @memberof PBLink\n     * @instance\n     */\n    PBLink.prototype.Name = \"\";\n\n    /**\n     * PBLink Tsize.\n     * @member {number} Tsize\n     * @memberof PBLink\n     * @instance\n     */\n    PBLink.prototype.Tsize = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Encodes the specified PBLink message. Does not implicitly {@link PBLink.verify|verify} messages.\n     * @function encode\n     * @memberof PBLink\n     * @static\n     * @param {IPBLink} m PBLink message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    PBLink.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        if (m.Hash != null && Object.hasOwnProperty.call(m, \"Hash\"))\n            w.uint32(10).bytes(m.Hash);\n        if (m.Name != null && Object.hasOwnProperty.call(m, \"Name\"))\n            w.uint32(18).string(m.Name);\n        if (m.Tsize != null && Object.hasOwnProperty.call(m, \"Tsize\"))\n            w.uint32(24).uint64(m.Tsize);\n        return w;\n    };\n\n    /**\n     * Decodes a PBLink message from the specified reader or buffer.\n     * @function decode\n     * @memberof PBLink\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {PBLink} PBLink\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    PBLink.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.PBLink();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.Hash = r.bytes();\n                break;\n            case 2:\n                m.Name = r.string();\n                break;\n            case 3:\n                m.Tsize = r.uint64();\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        return m;\n    };\n\n    /**\n     * Creates a PBLink message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof PBLink\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {PBLink} PBLink\n     */\n    PBLink.fromObject = function fromObject(d) {\n        if (d instanceof $root.PBLink)\n            return d;\n        var m = new $root.PBLink();\n        if (d.Hash != null) {\n            if (typeof d.Hash === \"string\")\n                $util.base64.decode(d.Hash, m.Hash = $util.newBuffer($util.base64.length(d.Hash)), 0);\n            else if (d.Hash.length)\n                m.Hash = d.Hash;\n        }\n        if (d.Name != null) {\n            m.Name = String(d.Name);\n        }\n        if (d.Tsize != null) {\n            if ($util.Long)\n                (m.Tsize = $util.Long.fromValue(d.Tsize)).unsigned = true;\n            else if (typeof d.Tsize === \"string\")\n                m.Tsize = parseInt(d.Tsize, 10);\n            else if (typeof d.Tsize === \"number\")\n                m.Tsize = d.Tsize;\n            else if (typeof d.Tsize === \"object\")\n                m.Tsize = new $util.LongBits(d.Tsize.low >>> 0, d.Tsize.high >>> 0).toNumber(true);\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from a PBLink message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof PBLink\n     * @static\n     * @param {PBLink} m PBLink\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    PBLink.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.defaults) {\n            if (o.bytes === String)\n                d.Hash = \"\";\n            else {\n                d.Hash = [];\n                if (o.bytes !== Array)\n                    d.Hash = $util.newBuffer(d.Hash);\n            }\n            d.Name = \"\";\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.Tsize = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.Tsize = o.longs === String ? \"0\" : 0;\n        }\n        if (m.Hash != null && m.hasOwnProperty(\"Hash\")) {\n            d.Hash = o.bytes === String ? $util.base64.encode(m.Hash, 0, m.Hash.length) : o.bytes === Array ? Array.prototype.slice.call(m.Hash) : m.Hash;\n        }\n        if (m.Name != null && m.hasOwnProperty(\"Name\")) {\n            d.Name = m.Name;\n        }\n        if (m.Tsize != null && m.hasOwnProperty(\"Tsize\")) {\n            if (typeof m.Tsize === \"number\")\n                d.Tsize = o.longs === String ? String(m.Tsize) : m.Tsize;\n            else\n                d.Tsize = o.longs === String ? $util.Long.prototype.toString.call(m.Tsize) : o.longs === Number ? new $util.LongBits(m.Tsize.low >>> 0, m.Tsize.high >>> 0).toNumber(true) : m.Tsize;\n        }\n        return d;\n    };\n\n    /**\n     * Converts this PBLink to JSON.\n     * @function toJSON\n     * @memberof PBLink\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    PBLink.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    return PBLink;\n})();\n\n$root.PBNode = (function() {\n\n    /**\n     * Properties of a PBNode.\n     * @exports IPBNode\n     * @interface IPBNode\n     * @property {Array.<IPBLink>|null} [Links] PBNode Links\n     * @property {Uint8Array|null} [Data] PBNode Data\n     */\n\n    /**\n     * Constructs a new PBNode.\n     * @exports PBNode\n     * @classdesc Represents a PBNode.\n     * @implements IPBNode\n     * @constructor\n     * @param {IPBNode=} [p] Properties to set\n     */\n    function PBNode(p) {\n        this.Links = [];\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * PBNode Links.\n     * @member {Array.<IPBLink>} Links\n     * @memberof PBNode\n     * @instance\n     */\n    PBNode.prototype.Links = $util.emptyArray;\n\n    /**\n     * PBNode Data.\n     * @member {Uint8Array} Data\n     * @memberof PBNode\n     * @instance\n     */\n    PBNode.prototype.Data = $util.newBuffer([]);\n\n    /**\n     * Encodes the specified PBNode message. Does not implicitly {@link PBNode.verify|verify} messages.\n     * @function encode\n     * @memberof PBNode\n     * @static\n     * @param {IPBNode} m PBNode message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    PBNode.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        if (m.Data != null && Object.hasOwnProperty.call(m, \"Data\"))\n            w.uint32(10).bytes(m.Data);\n        if (m.Links != null && m.Links.length) {\n            for (var i = 0; i < m.Links.length; ++i)\n                $root.PBLink.encode(m.Links[i], w.uint32(18).fork()).ldelim();\n        }\n        return w;\n    };\n\n    /**\n     * Decodes a PBNode message from the specified reader or buffer.\n     * @function decode\n     * @memberof PBNode\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {PBNode} PBNode\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    PBNode.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.PBNode();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 2:\n                if (!(m.Links && m.Links.length))\n                    m.Links = [];\n                m.Links.push($root.PBLink.decode(r, r.uint32()));\n                break;\n            case 1:\n                m.Data = r.bytes();\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        return m;\n    };\n\n    /**\n     * Creates a PBNode message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof PBNode\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {PBNode} PBNode\n     */\n    PBNode.fromObject = function fromObject(d) {\n        if (d instanceof $root.PBNode)\n            return d;\n        var m = new $root.PBNode();\n        if (d.Links) {\n            if (!Array.isArray(d.Links))\n                throw TypeError(\".PBNode.Links: array expected\");\n            m.Links = [];\n            for (var i = 0; i < d.Links.length; ++i) {\n                if (typeof d.Links[i] !== \"object\")\n                    throw TypeError(\".PBNode.Links: object expected\");\n                m.Links[i] = $root.PBLink.fromObject(d.Links[i]);\n            }\n        }\n        if (d.Data != null) {\n            if (typeof d.Data === \"string\")\n                $util.base64.decode(d.Data, m.Data = $util.newBuffer($util.base64.length(d.Data)), 0);\n            else if (d.Data.length)\n                m.Data = d.Data;\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from a PBNode message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof PBNode\n     * @static\n     * @param {PBNode} m PBNode\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    PBNode.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.arrays || o.defaults) {\n            d.Links = [];\n        }\n        if (o.defaults) {\n            if (o.bytes === String)\n                d.Data = \"\";\n            else {\n                d.Data = [];\n                if (o.bytes !== Array)\n                    d.Data = $util.newBuffer(d.Data);\n            }\n        }\n        if (m.Data != null && m.hasOwnProperty(\"Data\")) {\n            d.Data = o.bytes === String ? $util.base64.encode(m.Data, 0, m.Data.length) : o.bytes === Array ? Array.prototype.slice.call(m.Data) : m.Data;\n        }\n        if (m.Links && m.Links.length) {\n            d.Links = [];\n            for (var j = 0; j < m.Links.length; ++j) {\n                d.Links[j] = $root.PBLink.toObject(m.Links[j], o);\n            }\n        }\n        return d;\n    };\n\n    /**\n     * Converts this PBNode to JSON.\n     * @function toJSON\n     * @memberof PBNode\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    PBNode.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    return PBNode;\n})();\n\nmodule.exports = $root;\n","'use strict'\n\nconst sortLinks = require('./sortLinks')\nconst DAGLink = require('../dag-link/dagLink')\nconst { createDagLinkFromB58EncodedHash } = require('../dag-link/util')\nconst { serializeDAGNode } = require('../serialize')\nconst toDAGLink = require('./toDagLink')\nconst addLink = require('./addLink')\nconst rmLink = require('./rmLink')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\nconst uint8ArrayToString = require('uint8arrays/to-string')\n\n/**\n * @typedef {import('cids')} CID\n * @typedef {import('../types').DAGLinkLike} DAGLinkLike\n */\n\nclass DAGNode {\n  /**\n   *@param {Uint8Array | string} [data]\n   * @param {(DAGLink | DAGLinkLike)[]} links\n   * @param {number | null} [serializedSize]\n   */\n  constructor (data, links = [], serializedSize = null) {\n    if (!data) {\n      data = new Uint8Array(0)\n    }\n    if (typeof data === 'string') {\n      data = uint8ArrayFromString(data)\n    }\n\n    if (!(data instanceof Uint8Array)) {\n      throw new Error('Passed \\'data\\' is not a Uint8Array or a String!')\n    }\n\n    if (serializedSize !== null && typeof serializedSize !== 'number') {\n      throw new Error('Passed \\'serializedSize\\' must be a number!')\n    }\n\n    const sortedLinks = links.map((link) => {\n      return link instanceof DAGLink\n        ? link\n        : createDagLinkFromB58EncodedHash(link)\n    })\n    sortLinks(sortedLinks)\n\n    this.Data = data\n    this.Links = sortedLinks\n\n    Object.defineProperties(this, {\n      _serializedSize: { value: serializedSize, writable: true, enumerable: false },\n      _size: { value: null, writable: true, enumerable: false }\n    })\n  }\n\n  toJSON () {\n    if (!this._json) {\n      this._json = Object.freeze({\n        data: this.Data,\n        links: this.Links.map((l) => l.toJSON()),\n        size: this.size\n      })\n    }\n\n    return Object.assign({}, this._json)\n  }\n\n  toString () {\n    return `DAGNode <data: \"${uint8ArrayToString(this.Data, 'base64urlpad')}\", links: ${this.Links.length}, size: ${this.size}>`\n  }\n\n  _invalidateCached () {\n    this._serializedSize = null\n    this._size = null\n  }\n\n  /**\n   * @param {DAGLink | import('../types').DAGLinkLike} link\n   */\n  addLink (link) {\n    this._invalidateCached()\n    return addLink(this, link)\n  }\n\n  /**\n   * @param {DAGLink | string | CID} link\n   */\n  rmLink (link) {\n    this._invalidateCached()\n    return rmLink(this, link)\n  }\n\n  /**\n   * @param {import('./toDagLink').ToDagLinkOptions} [options]\n   */\n  toDAGLink (options) {\n    return toDAGLink(this, options)\n  }\n\n  serialize () {\n    const buf = serializeDAGNode(this)\n\n    this._serializedSize = buf.length\n\n    return buf\n  }\n\n  get size () {\n    if (this._size == null) {\n      let serializedSize\n\n      if (serializedSize == null) {\n        this._serializedSize = this.serialize().length\n        serializedSize = this._serializedSize\n      }\n\n      this._size = this.Links.reduce((sum, l) => sum + l.Tsize, serializedSize)\n    }\n\n    return this._size\n  }\n\n  set size (size) {\n    throw new Error(\"Can't set property: 'size' is immutable\")\n  }\n}\n\nmodule.exports = DAGNode\n","'use strict'\n\nconst sort = require('stable')\nconst uint8ArrayCompare = require('uint8arrays/compare')\n\n/**\n * @typedef {import('../dag-link/dagLink')} DAGLink\n */\n\n/**\n *\n * @param {DAGLink} a\n * @param {DAGLink} b\n */\nconst linkSort = (a, b) => {\n  const buf1 = a.nameAsBuffer\n  const buf2 = b.nameAsBuffer\n\n  return uint8ArrayCompare(buf1, buf2)\n}\n\n/**\n * Sorts links in place (mutating given array)\n *\n * @param {DAGLink[]} links\n * @returns {void}\n */\nconst sortLinks = (links) => {\n  sort.inplace(links, linkSort)\n}\n\nmodule.exports = sortLinks\n","'use strict'\n\nconst DAGLink = require('./dagLink')\n\n/**\n * @param {*} link\n */\nfunction createDagLinkFromB58EncodedHash (link) {\n  return new DAGLink(\n    link.Name || link.name || '',\n    link.Tsize || link.Size || link.size || 0,\n    link.Hash || link.hash || link.multihash || link.cid\n  )\n}\n\nmodule.exports = {\n  createDagLinkFromB58EncodedHash\n}\n","'use strict'\n\nconst protobuf = require('protobufjs/minimal')\nconst {\n  PBLink\n} = require('./dag')\n\nconst {\n  createDagLinkFromB58EncodedHash\n} = require('./dag-link/util')\n\n/**\n * @typedef {import('./dag-link/dagLink')} DAGLink\n * @typedef {import('./types').DAGLinkLike} DAGLinkLike\n * @typedef {import('./types').SerializableDAGNode} SerializableDAGNode\n * @typedef {import('cids')} CID\n */\n\n/**\n * @param { { Data?: Uint8Array, Links: (DAGLink | DAGLinkLike)[] }} node\n * @returns {SerializableDAGNode}\n */\nconst toProtoBuf = (node) => {\n  const pbn = {}\n\n  if (node.Data && node.Data.byteLength > 0) {\n    pbn.Data = node.Data\n  } else {\n    // NOTE: this has to be null in order to match go-ipfs serialization\n    // `null !== new Uint8Array(0)`\n    pbn.Data = null\n  }\n\n  if (node.Links && node.Links.length > 0) {\n    pbn.Links = node.Links\n      .map((link) => ({\n        Hash: link.Hash.bytes,\n        Name: link.Name,\n        Tsize: link.Tsize\n      }))\n  } else {\n    pbn.Links = null\n  }\n\n  return pbn\n}\n\n/**\n * Serialize internal representation into a binary PB block.\n *\n * @param {import('./dag-node/dagNode')} node - Internal representation of a PB block\n */\nconst serializeDAGNode = (node) => {\n  return encode(toProtoBuf(node))\n}\n\n/**\n * Serialize an object where the `Links` might not be a `DAGLink` instance yet\n *\n * @param {Uint8Array} [data]\n * @param {(DAGLink | string | DAGLinkLike)[]} [links]\n */\nconst serializeDAGNodeLike = (data, links = []) => {\n  const node = {\n    Data: data,\n    Links: links.map((link) => {\n      return createDagLinkFromB58EncodedHash(link)\n    })\n  }\n\n  return encode(toProtoBuf(node))\n}\n\nmodule.exports = {\n  serializeDAGNode,\n  serializeDAGNodeLike\n}\n\n/**\n * The fields in PBNode are the wrong way round - `id: 2` comes before\n * `id: 1`. protobufjs writes them out in id order but go-IPFS does not so\n * we have to use the protobuf.Writer interface directly to get the same\n * serialized form as go-IPFS\n *\n * @param {SerializableDAGNode} pbf\n */\nfunction encode (pbf) {\n  const writer = protobuf.Writer.create()\n\n  if (pbf.Links != null) {\n    for (let i = 0; i < pbf.Links.length; i++) {\n      PBLink.encode(pbf.Links[i], writer.uint32(18).fork()).ldelim()\n    }\n  }\n\n  if (pbf.Data != null) {\n    writer.uint32(10).bytes(pbf.Data)\n  }\n\n  return writer.finish()\n}\n","'use strict'\n\nconst CID = require('cids')\nconst multicodec = require('multicodec')\nconst multihashing = require('multihashing-async')\nconst { multihash } = multihashing\n\nconst codec = multicodec.DAG_PB\nconst defaultHashAlg = multihash.names['sha2-256']\n\n/**\n * @typedef {object} GenCIDOptions - Options to create the CID\n * @property {CID.CIDVersion} [cidVersion=1] - CID version number\n * @property {multihashing.multihash.HashCode} [hashAlg=multihash.names['sha2-256']] - Defaults to the defaultHashAlg of the format\n */\n\n/**\n * Calculate the CID of the binary blob.\n *\n * @param {Uint8Array} binaryBlob - Encoded IPLD Node\n * @param {GenCIDOptions} [userOptions] - Options to create the CID\n */\nconst cid = async (binaryBlob, userOptions = {}) => {\n  const options = {\n    cidVersion: userOptions.cidVersion == null ? 1 : userOptions.cidVersion,\n    hashAlg: userOptions.hashAlg == null ? defaultHashAlg : userOptions.hashAlg\n  }\n\n  const hashName = multihash.codes[options.hashAlg]\n  const hash = await multihashing(binaryBlob, hashName)\n  const codecName = multicodec.getNameFromCode(codec)\n  const cid = new CID(options.cidVersion, codecName, hash)\n\n  return cid\n}\n\nmodule.exports = {\n  codec,\n  defaultHashAlg,\n  cid\n}\n","/**\n * Multihash implementation in JavaScript.\n */\n'use strict'\n\nconst multibase = require('multibase')\nconst varint = require('varint')\nconst { names } = require('./constants')\nconst uint8ArrayToString = require('uint8arrays/to-string')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\nconst uint8ArrayConcat = require('uint8arrays/concat')\n\nconst codes = /** @type {import('./types').CodeNameMap} */({})\n\n// eslint-disable-next-line guard-for-in\nfor (const key in names) {\n  const name = /** @type {HashName} */(key)\n  codes[names[name]] = name\n}\nObject.freeze(codes)\n\n/**\n * Convert the given multihash to a hex encoded string.\n *\n * @param {Uint8Array} hash\n * @returns {string}\n */\nfunction toHexString (hash) {\n  if (!(hash instanceof Uint8Array)) {\n    throw new Error('must be passed a Uint8Array')\n  }\n\n  return uint8ArrayToString(hash, 'base16')\n}\n\n/**\n * Convert the given hex encoded string to a multihash.\n *\n * @param {string} hash\n * @returns {Uint8Array}\n */\nfunction fromHexString (hash) {\n  return uint8ArrayFromString(hash, 'base16')\n}\n\n/**\n * Convert the given multihash to a base58 encoded string.\n *\n * @param {Uint8Array} hash\n * @returns {string}\n */\nfunction toB58String (hash) {\n  if (!(hash instanceof Uint8Array)) {\n    throw new Error('must be passed a Uint8Array')\n  }\n\n  return uint8ArrayToString(multibase.encode('base58btc', hash)).slice(1)\n}\n\n/**\n * Convert the given base58 encoded string to a multihash.\n *\n * @param {string|Uint8Array} hash\n * @returns {Uint8Array}\n */\nfunction fromB58String (hash) {\n  const encoded = hash instanceof Uint8Array\n    ? uint8ArrayToString(hash)\n    : hash\n\n  return multibase.decode('z' + encoded)\n}\n\n/**\n * Decode a hash from the given multihash.\n *\n * @param {Uint8Array} bytes\n * @returns {{code: HashCode, name: HashName, length: number, digest: Uint8Array}} result\n */\nfunction decode (bytes) {\n  if (!(bytes instanceof Uint8Array)) {\n    throw new Error('multihash must be a Uint8Array')\n  }\n\n  if (bytes.length < 2) {\n    throw new Error('multihash too short. must be > 2 bytes.')\n  }\n\n  const code = /** @type {HashCode} */(varint.decode(bytes))\n  if (!isValidCode(code)) {\n    throw new Error(`multihash unknown function code: 0x${code.toString(16)}`)\n  }\n  bytes = bytes.slice(varint.decode.bytes)\n\n  const len = varint.decode(bytes)\n  if (len < 0) {\n    throw new Error(`multihash invalid length: ${len}`)\n  }\n  bytes = bytes.slice(varint.decode.bytes)\n\n  if (bytes.length !== len) {\n    throw new Error(`multihash length inconsistent: 0x${uint8ArrayToString(bytes, 'base16')}`)\n  }\n\n  return {\n    code,\n    name: codes[code],\n    length: len,\n    digest: bytes\n  }\n}\n\n/**\n * Encode a hash digest along with the specified function code.\n *\n * > **Note:** the length is derived from the length of the digest itself.\n *\n * @param {Uint8Array} digest\n * @param {HashName | HashCode} code\n * @param {number} [length]\n * @returns {Uint8Array}\n */\nfunction encode (digest, code, length) {\n  if (!digest || code === undefined) {\n    throw new Error('multihash encode requires at least two args: digest, code')\n  }\n\n  // ensure it's a hashfunction code.\n  const hashfn = coerceCode(code)\n\n  if (!(digest instanceof Uint8Array)) {\n    throw new Error('digest should be a Uint8Array')\n  }\n\n  if (length == null) {\n    length = digest.length\n  }\n\n  if (length && digest.length !== length) {\n    throw new Error('digest length should be equal to specified length.')\n  }\n\n  const hash = varint.encode(hashfn)\n  const len = varint.encode(length)\n  return uint8ArrayConcat([hash, len, digest], hash.length + len.length + digest.length)\n}\n\n/**\n * Converts a hash function name into the matching code.\n * If passed a number it will return the number if it's a valid code.\n *\n * @param {HashName | number} name\n * @returns {number}\n */\nfunction coerceCode (name) {\n  let code = name\n\n  if (typeof name === 'string') {\n    if (names[name] === undefined) {\n      throw new Error(`Unrecognized hash function named: ${name}`)\n    }\n    code = names[name]\n  }\n\n  if (typeof code !== 'number') {\n    throw new Error(`Hash function code should be a number. Got: ${code}`)\n  }\n\n  // @ts-ignore\n  if (codes[code] === undefined && !isAppCode(code)) {\n    throw new Error(`Unrecognized function code: ${code}`)\n  }\n\n  return code\n}\n\n/**\n * Checks if a code is part of the app range\n *\n * @param {number} code\n * @returns {boolean}\n */\nfunction isAppCode (code) {\n  return code > 0 && code < 0x10\n}\n\n/**\n * Checks whether a multihash code is valid.\n *\n * @param {HashCode} code\n * @returns {boolean}\n */\nfunction isValidCode (code) {\n  if (isAppCode(code)) {\n    return true\n  }\n\n  if (codes[code]) {\n    return true\n  }\n\n  return false\n}\n\n/**\n * Check if the given buffer is a valid multihash. Throws an error if it is not valid.\n *\n * @param {Uint8Array} multihash\n * @returns {void}\n * @throws {Error}\n */\nfunction validate (multihash) {\n  decode(multihash) // throws if bad.\n}\n\n/**\n * Returns a prefix from a valid multihash. Throws an error if it is not valid.\n *\n * @param {Uint8Array} multihash\n * @returns {Uint8Array}\n * @throws {Error}\n */\nfunction prefix (multihash) {\n  validate(multihash)\n\n  return multihash.subarray(0, 2)\n}\n\nmodule.exports = {\n  names,\n  codes,\n  toHexString,\n  fromHexString,\n  toB58String,\n  fromB58String,\n  decode,\n  encode,\n  coerceCode,\n  isAppCode,\n  validate,\n  prefix,\n  isValidCode\n}\n\n/**\n * @typedef { import(\"./constants\").HashCode } HashCode\n * @typedef { import(\"./constants\").HashName } HashName\n */\n","'use strict'\n\nconst { encoding: getCodec } = require('multibase')\nconst utf8Decoder = new TextDecoder('utf8')\n\n/**\n * @typedef {import('multibase/src/types').BaseName} BaseName\n */\n\n/**\n * Turns a Uint8Array of bytes into a string with each\n * character being the char code of the corresponding byte\n *\n * @param {Uint8Array} array - The array to turn into a string\n */\nfunction uint8ArrayToAsciiString (array) {\n  let string = ''\n\n  for (let i = 0; i < array.length; i++) {\n    string += String.fromCharCode(array[i])\n  }\n  return string\n}\n\n/**\n * Turns a `Uint8Array` into a string.\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {Uint8Array} array - The array to turn into a string\n * @param {BaseName | 'utf8' | 'utf-8' | 'ascii'} [encoding=utf8] - The encoding to use\n * @returns {string}\n */\nfunction toString (array, encoding = 'utf8') {\n  if (encoding === 'utf8' || encoding === 'utf-8') {\n    return utf8Decoder.decode(array)\n  }\n\n  if (encoding === 'ascii') {\n    return uint8ArrayToAsciiString(array)\n  }\n\n  return getCodec(encoding).encode(array)\n}\n\nmodule.exports = toString\n","'use strict'\n\n/**\n * Returns a new Uint8Array created by concatenating the passed ArrayLikes\n *\n * @param {Array<ArrayLike<number>>} arrays\n * @param {number} [length]\n */\nfunction concat (arrays, length) {\n  if (!length) {\n    length = arrays.reduce((acc, curr) => acc + curr.length, 0)\n  }\n\n  const output = new Uint8Array(length)\n  let offset = 0\n\n  for (const arr of arrays) {\n    output.set(arr, offset)\n    offset += arr.length\n  }\n\n  return output\n}\n\nmodule.exports = concat\n","'use strict'\n\nconst varint = require('varint')\nconst uint8ArrayToString = require('uint8arrays/to-string')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\nmodule.exports = {\n  numberToUint8Array,\n  uint8ArrayToNumber,\n  varintUint8ArrayEncode,\n  varintEncode\n}\n\n/**\n * @param {Uint8Array} buf\n */\nfunction uint8ArrayToNumber (buf) {\n  return parseInt(uint8ArrayToString(buf, 'base16'), 16)\n}\n\n/**\n * @param {number} num\n */\nfunction numberToUint8Array (num) {\n  let hexString = num.toString(16)\n  if (hexString.length % 2 === 1) {\n    hexString = '0' + hexString\n  }\n  return uint8ArrayFromString(hexString, 'base16')\n}\n\n/**\n * @param {Uint8Array} input\n */\nfunction varintUint8ArrayEncode (input) {\n  return Uint8Array.from(varint.encode(uint8ArrayToNumber(input)))\n}\n\n/**\n * @param {number} num\n */\nfunction varintEncode (num) {\n  return Uint8Array.from(varint.encode(num))\n}\n","'use strict'\n\n// @ts-ignore TODO: switch to cborg\nconst cbor = require('borc')\nconst multicodec = require('multicodec')\nconst multihashing = require('multihashing-async')\nconst { multihash } = multihashing\nconst CID = require('cids')\n// @ts-ignore\nconst isCircular = require('is-circular')\nconst uint8ArrayConcat = require('uint8arrays/concat')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\n/**\n * @typedef {import('cids').CIDVersion} CIDVersion\n * @typedef {import('multihashing-async').multihash.HashCode} HashCode\n */\n\n// https://github.com/ipfs/go-ipfs/issues/3570#issuecomment-273931692\nconst CID_CBOR_TAG = 42\n\n/**\n * @param {CID | string} cid\n */\nfunction tagCID (cid) {\n  let buf\n\n  if (typeof cid === 'string') {\n    buf = new CID(cid).bytes\n  } else if (CID.isCID(cid)) {\n    buf = cid.bytes\n  } else {\n    throw new Error('Could not tag CID - was not string or CID')\n  }\n\n  return new cbor.Tagged(CID_CBOR_TAG, uint8ArrayConcat([\n    uint8ArrayFromString('00', 'base16'), // thanks jdag\n    buf\n  ], 1 + buf.length))\n}\n\n/**\n * @param {any} dagNode\n */\nfunction replaceCIDbyTAG (dagNode) {\n  let circular\n  try {\n    circular = isCircular(dagNode)\n  } catch (e) {\n    circular = false\n  }\n  if (circular) {\n    throw new Error('The object passed has circular references')\n  }\n\n  /**\n   * @param {any} obj\n   * @returns {any}\n   */\n  function transform (obj) {\n    if (!obj || obj instanceof Uint8Array || typeof obj === 'string') {\n      return obj\n    }\n\n    if (Array.isArray(obj)) {\n      return obj.map(transform)\n    }\n\n    if (CID.isCID(obj)) {\n      return tagCID(obj)\n    }\n\n    const keys = Object.keys(obj)\n\n    if (keys.length > 0) {\n      // Recursive transform\n      /** @type {Record<string, any>} */\n      const out = {}\n      keys.forEach((key) => {\n        if (typeof obj[key] === 'object') {\n          out[key] = transform(obj[key])\n        } else {\n          out[key] = obj[key]\n        }\n      })\n      return out\n    } else {\n      return obj\n    }\n  }\n\n  return transform(dagNode)\n}\n\nconst codec = multicodec.DAG_CBOR\nconst defaultHashAlg = multihash.names['sha2-256']\n\nconst defaultTags = {\n  /**\n   * @param {Uint8Array} val\n   */\n  [CID_CBOR_TAG]: (val) => {\n    // remove that 0\n    val = val.slice(1)\n    return new CID(val)\n  }\n}\nconst defaultSize = 64 * 1024 // current decoder heap size, 64 Kb\nlet currentSize = defaultSize\nconst defaultMaxSize = 64 * 1024 * 1024 // max heap size when auto-growing, 64 Mb\nlet maxSize = defaultMaxSize\n/** @type {cbor.Decoder} */\nlet decoder\n\n/**\n * Configure the underlying CBOR decoder.\n *\n * @param {Object} [options] - The options the decoder takes. The decoder will reset to the defaul values if no options are given.\n * @param {number} [options.size=65536] - The current heap size used in CBOR parsing, this may grow automatically as larger blocks are encountered up to `maxSize`\n * @param {number} [options.maxSize=67108864] - The maximum size the CBOR parsing heap is allowed to grow to before `dagCBOR.util.deserialize()` returns an error\n * @param {Object} [options.tags] - An object whose keys are CBOR tag numbers and values are transform functions that accept a `value` and return a decoded representation of that `value`\n */\nfunction configureDecoder (options) {\n  let tags = defaultTags\n\n  if (options) {\n    if (typeof options.size === 'number') {\n      currentSize = options.size\n    }\n    if (typeof options.maxSize === 'number') {\n      maxSize = options.maxSize\n    }\n    if (options.tags) {\n      tags = Object.assign({}, defaultTags, options && options.tags)\n    }\n  } else {\n    // no options, reset to defaults\n    currentSize = defaultSize\n    maxSize = defaultMaxSize\n  }\n\n  const decoderOptions = {\n    tags,\n    size: currentSize\n  }\n\n  decoder = new cbor.Decoder(decoderOptions)\n  // borc edits opts.size in-place so we can capture _actual_ size\n  currentSize = decoderOptions.size\n}\n\nconfigureDecoder() // Setup default cbor.Decoder\n\n/**\n * Serialize internal representation into a binary CBOR block.\n *\n * @param {Object} node - Internal representation of a CBOR block\n * @returns {Uint8Array} - The encoded binary representation\n */\nfunction serialize (node) {\n  const nodeTagged = replaceCIDbyTAG(node)\n  const serialized = cbor.encode(nodeTagged)\n\n  return serialized\n}\n\n/**\n * Deserialize CBOR block into the internal representation.\n *\n * @param {Uint8Array} data - Binary representation of a CBOR block\n * @returns {any} - An object that conforms to the IPLD Data Model\n */\nfunction deserialize (data) {\n  if (data.length > currentSize && data.length <= maxSize) {\n    configureDecoder({ size: data.length })\n  }\n\n  if (data.length > currentSize) {\n    throw new Error('Data is too large to deserialize with current decoder')\n  }\n\n  // borc will decode back-to-back objects into an implicit top-level array, we\n  // strictly want to only see a single explicit top-level object\n  const all = decoder.decodeAll(data)\n  if (all.length !== 1) {\n    throw new Error('Extraneous CBOR data found beyond initial top-level object')\n  }\n\n  return all[0]\n}\n\n/**\n * Calculate the CID of the binary blob.\n *\n * @param {Uint8Array} binaryBlob - Encoded IPLD Node\n * @param {Object} [userOptions] - Options to create the CID\n * @param {CIDVersion} [userOptions.cidVersion=1] - CID version number\n * @param {HashCode} [userOptions.hashAlg=multihash.names['sha2-256']] - Defaults to the defaultHashAlg of the format\n */\nasync function cid (binaryBlob, userOptions = {}) {\n  const options = {\n    cidVersion: userOptions.cidVersion == null ? 1 : userOptions.cidVersion,\n    hashAlg: userOptions.hashAlg == null ? module.exports.defaultHashAlg : userOptions.hashAlg\n  }\n\n  const hashName = multihash.codes[options.hashAlg]\n  const hash = await multihashing(binaryBlob, hashName)\n  const codecName = multicodec.getNameFromCode(module.exports.codec)\n  const cid = new CID(options.cidVersion, codecName, hash)\n\n  return cid\n}\n\nmodule.exports = {\n  codec,\n  defaultHashAlg,\n  configureDecoder,\n  serialize,\n  deserialize,\n  cid\n}\n","'use strict'\n\nconst errcode = require('err-code')\nconst multihash = require('multihashes')\nconst crypto = require('./crypto')\nconst equals = require('uint8arrays/equals')\n\n/**\n * @typedef {import(\"./types\").Digest} Digest\n * @typedef {import(\"multihashes\").HashName} HashName\n */\n\n/**\n * Hash the given `bytes` using the algorithm specified by `alg`.\n *\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nasync function Multihashing (bytes, alg, length) {\n  const digest = await Multihashing.digest(bytes, alg, length)\n  return multihash.encode(digest, alg, length)\n}\n\n/**\n * Expose multihash itself, to avoid silly double requires.\n */\nMultihashing.multihash = multihash\n\n/**\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nMultihashing.digest = async (bytes, alg, length) => {\n  const hash = Multihashing.createHash(alg)\n  const digest = await hash(bytes)\n  return length ? digest.slice(0, length) : digest\n}\n\n/**\n * Creates a function that hashes with the given algorithm\n *\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @returns {Digest} - The hash function corresponding to `alg`\n */\nMultihashing.createHash = function (alg) {\n  if (!alg) {\n    const e = errcode(new Error('hash algorithm must be specified'), 'ERR_HASH_ALGORITHM_NOT_SPECIFIED')\n    throw e\n  }\n\n  const code = multihash.coerceCode(alg)\n  if (!Multihashing.functions[code]) {\n    throw errcode(new Error(`multihash function '${alg}' not yet supported`), 'ERR_HASH_ALGORITHM_NOT_SUPPORTED')\n  }\n\n  return Multihashing.functions[code]\n}\n\n/**\n * Mapping of multihash codes to their hashing functions.\n *\n * @type {Record<number, Digest>}\n */\n// @ts-ignore - most of those functions aren't typed\nMultihashing.functions = {\n  // identity\n  0x00: crypto.identity,\n  // sha1\n  0x11: crypto.sha1,\n  // sha2-256\n  0x12: crypto.sha2256,\n  // sha2-512\n  0x13: crypto.sha2512,\n  // sha3-512\n  0x14: crypto.sha3512,\n  // sha3-384\n  0x15: crypto.sha3384,\n  // sha3-256\n  0x16: crypto.sha3256,\n  // sha3-224\n  0x17: crypto.sha3224,\n  // shake-128\n  0x18: crypto.shake128,\n  // shake-256\n  0x19: crypto.shake256,\n  // keccak-224\n  0x1A: crypto.keccak224,\n  // keccak-256\n  0x1B: crypto.keccak256,\n  // keccak-384\n  0x1C: crypto.keccak384,\n  // keccak-512\n  0x1D: crypto.keccak512,\n  // murmur3-128\n  0x22: crypto.murmur3128,\n  // murmur3-32\n  0x23: crypto.murmur332,\n  // dbl-sha2-256\n  0x56: crypto.dblSha2256\n}\n\n// add blake functions\ncrypto.addBlake(Multihashing.functions)\n\n/**\n * @param {Uint8Array} bytes\n * @param {Uint8Array} hash\n * @returns {Promise<boolean>}\n */\nMultihashing.validate = async (bytes, hash) => {\n  const newHash = await Multihashing(bytes, multihash.decode(hash).name)\n\n  return equals(hash, newHash)\n}\n\nmodule.exports = Multihashing\n","'use strict'\n\nconst multihashing = require('multihashing-async')\nconst CID = require('cids')\nconst multicodec = require('multicodec')\nconst { Buffer } = require('buffer')\nconst uint8ArrayToString = require('uint8arrays/to-string')\n\nconst gitUtil = require('./util/util')\n\nconst commit = require('./util/commit')\nconst tag = require('./util/tag')\nconst tree = require('./util/tree')\n\nconst codec = multicodec.GIT_RAW\nconst defaultHashAlg = multicodec.SHA1\n\n/**\n * Serialize internal representation into a binary Git block.\n *\n * @param {GitBlock} dagNode - Internal representation of a Git block\n * @returns {Uint8Array}\n */\nfunction serialize (dagNode) {\n  if (dagNode === null) {\n    throw new Error('dagNode passed to serialize was null')\n  }\n\n  if (dagNode instanceof Uint8Array) {\n    if (uint8ArrayToString(dagNode.slice(0, 4)) === 'blob') {\n      return dagNode\n    } else {\n      throw new Error('unexpected dagNode passed to serialize')\n    }\n  }\n\n  switch (dagNode.gitType) {\n    case 'commit':\n      return commit.serialize(dagNode)\n    case 'tag':\n      return tag.serialize(dagNode)\n    default:\n      // assume tree as a file named 'type' is legal\n      return tree.serialize(dagNode)\n  }\n}\n\n/**\n * Deserialize Git block into the internal representation.\n *\n * @param {Uint8Array} data - Binary representation of a Git block.\n */\nfunction deserialize (data) {\n  if (!Buffer.isBuffer(data)) {\n    data = Buffer.from(data.buffer, data.byteOffset, data.byteLength)\n  }\n\n  const headLen = gitUtil.find(data, 0)\n  const head = data.slice(0, headLen).toString()\n  const typeLen = head.match(/([^ ]+) (\\d+)/)\n  if (!typeLen) {\n    throw new Error('invalid object header')\n  }\n\n  switch (typeLen[1]) {\n    case 'blob':\n      return data\n    case 'commit':\n      return commit.deserialize(data.slice(headLen + 1))\n    case 'tag':\n      return tag.deserialize(data.slice(headLen + 1))\n    case 'tree':\n      return tree.deserialize(data.slice(headLen + 1))\n    default:\n      throw new Error('unknown object type ' + typeLen[1])\n  }\n}\n\n/**\n * Calculate the CID of the binary blob.\n *\n * @param {Object} binaryBlob - Encoded IPLD Node\n * @param {Object} [userOptions] - Options to create the CID\n * @param {number} [userOptions.cidVersion=1] - CID version number\n * @param {string} [userOptions.hashAlg] - Defaults to the defaultHashAlg of the format\n */\nasync function cid (binaryBlob, userOptions) {\n  const defaultOptions = { cidVersion: 1, hashAlg: defaultHashAlg }\n  const options = Object.assign(defaultOptions, userOptions)\n\n  const multihash = await multihashing(binaryBlob, options.hashAlg)\n  const codecName = multicodec.getNameFromCode(codec)\n  const cid = new CID(options.cidVersion, codecName, multihash)\n\n  return cid\n}\n\nmodule.exports = {\n  codec,\n  defaultHashAlg,\n  serialize,\n  deserialize,\n  cid\n}\n","'use strict'\n\nconst errcode = require('err-code')\nconst multihash = require('multihashes')\nconst crypto = require('./crypto')\nconst equals = require('uint8arrays/equals')\n\n/**\n * @typedef {import(\"./types\").Digest} Digest\n * @typedef {import(\"multihashes\").HashName} HashName\n */\n\n/**\n * Hash the given `bytes` using the algorithm specified by `alg`.\n *\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nasync function Multihashing (bytes, alg, length) {\n  const digest = await Multihashing.digest(bytes, alg, length)\n  return multihash.encode(digest, alg, length)\n}\n\n/**\n * Expose multihash itself, to avoid silly double requires.\n */\nMultihashing.multihash = multihash\n\n/**\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nMultihashing.digest = async (bytes, alg, length) => {\n  const hash = Multihashing.createHash(alg)\n  const digest = await hash(bytes)\n  return length ? digest.slice(0, length) : digest\n}\n\n/**\n * Creates a function that hashes with the given algorithm\n *\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @returns {Digest} - The hash function corresponding to `alg`\n */\nMultihashing.createHash = function (alg) {\n  if (!alg) {\n    const e = errcode(new Error('hash algorithm must be specified'), 'ERR_HASH_ALGORITHM_NOT_SPECIFIED')\n    throw e\n  }\n\n  const code = multihash.coerceCode(alg)\n  if (!Multihashing.functions[code]) {\n    throw errcode(new Error(`multihash function '${alg}' not yet supported`), 'ERR_HASH_ALGORITHM_NOT_SUPPORTED')\n  }\n\n  return Multihashing.functions[code]\n}\n\n/**\n * Mapping of multihash codes to their hashing functions.\n *\n * @type {Record<number, Digest>}\n */\n// @ts-ignore - most of those functions aren't typed\nMultihashing.functions = {\n  // identity\n  0x00: crypto.identity,\n  // sha1\n  0x11: crypto.sha1,\n  // sha2-256\n  0x12: crypto.sha2256,\n  // sha2-512\n  0x13: crypto.sha2512,\n  // sha3-512\n  0x14: crypto.sha3512,\n  // sha3-384\n  0x15: crypto.sha3384,\n  // sha3-256\n  0x16: crypto.sha3256,\n  // sha3-224\n  0x17: crypto.sha3224,\n  // shake-128\n  0x18: crypto.shake128,\n  // shake-256\n  0x19: crypto.shake256,\n  // keccak-224\n  0x1A: crypto.keccak224,\n  // keccak-256\n  0x1B: crypto.keccak256,\n  // keccak-384\n  0x1C: crypto.keccak384,\n  // keccak-512\n  0x1D: crypto.keccak512,\n  // murmur3-128\n  0x22: crypto.murmur3128,\n  // murmur3-32\n  0x23: crypto.murmur332,\n  // dbl-sha2-256\n  0x56: crypto.dblSha2256\n}\n\n// add blake functions\ncrypto.addBlake(Multihashing.functions)\n\n/**\n * @param {Uint8Array} bytes\n * @param {Uint8Array} hash\n * @returns {Promise<boolean>}\n */\nMultihashing.validate = async (bytes, hash) => {\n  const newHash = await Multihashing(bytes, multihash.decode(hash).name)\n\n  return equals(hash, newHash)\n}\n\nmodule.exports = Multihashing\n","/**\n * Multihash implementation in JavaScript.\n */\n'use strict'\n\nconst multibase = require('multibase')\nconst varint = require('varint')\nconst { names } = require('./constants')\nconst uint8ArrayToString = require('uint8arrays/to-string')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\nconst uint8ArrayConcat = require('uint8arrays/concat')\n\nconst codes = /** @type {import('./types').CodeNameMap} */({})\n\n// eslint-disable-next-line guard-for-in\nfor (const key in names) {\n  const name = /** @type {HashName} */(key)\n  codes[names[name]] = name\n}\nObject.freeze(codes)\n\n/**\n * Convert the given multihash to a hex encoded string.\n *\n * @param {Uint8Array} hash\n * @returns {string}\n */\nfunction toHexString (hash) {\n  if (!(hash instanceof Uint8Array)) {\n    throw new Error('must be passed a Uint8Array')\n  }\n\n  return uint8ArrayToString(hash, 'base16')\n}\n\n/**\n * Convert the given hex encoded string to a multihash.\n *\n * @param {string} hash\n * @returns {Uint8Array}\n */\nfunction fromHexString (hash) {\n  return uint8ArrayFromString(hash, 'base16')\n}\n\n/**\n * Convert the given multihash to a base58 encoded string.\n *\n * @param {Uint8Array} hash\n * @returns {string}\n */\nfunction toB58String (hash) {\n  if (!(hash instanceof Uint8Array)) {\n    throw new Error('must be passed a Uint8Array')\n  }\n\n  return uint8ArrayToString(multibase.encode('base58btc', hash)).slice(1)\n}\n\n/**\n * Convert the given base58 encoded string to a multihash.\n *\n * @param {string|Uint8Array} hash\n * @returns {Uint8Array}\n */\nfunction fromB58String (hash) {\n  const encoded = hash instanceof Uint8Array\n    ? uint8ArrayToString(hash)\n    : hash\n\n  return multibase.decode('z' + encoded)\n}\n\n/**\n * Decode a hash from the given multihash.\n *\n * @param {Uint8Array} bytes\n * @returns {{code: HashCode, name: HashName, length: number, digest: Uint8Array}} result\n */\nfunction decode (bytes) {\n  if (!(bytes instanceof Uint8Array)) {\n    throw new Error('multihash must be a Uint8Array')\n  }\n\n  if (bytes.length < 2) {\n    throw new Error('multihash too short. must be > 2 bytes.')\n  }\n\n  const code = /** @type {HashCode} */(varint.decode(bytes))\n  if (!isValidCode(code)) {\n    throw new Error(`multihash unknown function code: 0x${code.toString(16)}`)\n  }\n  bytes = bytes.slice(varint.decode.bytes)\n\n  const len = varint.decode(bytes)\n  if (len < 0) {\n    throw new Error(`multihash invalid length: ${len}`)\n  }\n  bytes = bytes.slice(varint.decode.bytes)\n\n  if (bytes.length !== len) {\n    throw new Error(`multihash length inconsistent: 0x${uint8ArrayToString(bytes, 'base16')}`)\n  }\n\n  return {\n    code,\n    name: codes[code],\n    length: len,\n    digest: bytes\n  }\n}\n\n/**\n * Encode a hash digest along with the specified function code.\n *\n * > **Note:** the length is derived from the length of the digest itself.\n *\n * @param {Uint8Array} digest\n * @param {HashName | HashCode} code\n * @param {number} [length]\n * @returns {Uint8Array}\n */\nfunction encode (digest, code, length) {\n  if (!digest || code === undefined) {\n    throw new Error('multihash encode requires at least two args: digest, code')\n  }\n\n  // ensure it's a hashfunction code.\n  const hashfn = coerceCode(code)\n\n  if (!(digest instanceof Uint8Array)) {\n    throw new Error('digest should be a Uint8Array')\n  }\n\n  if (length == null) {\n    length = digest.length\n  }\n\n  if (length && digest.length !== length) {\n    throw new Error('digest length should be equal to spec